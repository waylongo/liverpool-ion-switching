{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:21.599697Z",
     "start_time": "2020-05-06T23:28:20.371818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, gc, random\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "import tensorflow_addons as tfa\n",
    "from tf_nn_utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# set gpu memory growth\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:21.602622Z",
     "start_time": "2020-05-06T23:28:21.600839Z"
    }
   },
   "outputs": [],
   "source": [
    "# configurations and main hyperparammeters\n",
    "nn_epochs = 100\n",
    "nn_batch_size = 16\n",
    "class_num = 2\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:22.212676Z",
     "start_time": "2020-05-06T23:28:21.603527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:(4500000, 17), test size:(2000000, 18)\n"
     ]
    }
   ],
   "source": [
    "df_train_raw = pd.read_pickle('../features/train_clean.pkl')\n",
    "df_test_raw = pd.read_pickle('../features/test_clean.pkl')\n",
    "TARGET = \"open_channels\"\n",
    "df_test_raw[TARGET] = 0\n",
    "\n",
    "# RFC features\n",
    "Y_train_proba = np.load(\"../features/Y_train_proba.npy\")\n",
    "Y_test_proba = np.load(\"../features/Y_test_proba.npy\")\n",
    "Y_train_proba = np.delete(Y_train_proba, list(range(3500000, 4000000)), 0)\n",
    "for i in range(11):\n",
    "    df_train_raw[f\"proba_{i}\"] = Y_train_proba[:, i]\n",
    "    df_test_raw[f\"proba_{i}\"] = Y_test_proba[:, i]\n",
    "\n",
    "print(f\"train size:{df_train_raw.shape}, test size:{df_test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:27.785980Z",
     "start_time": "2020-05-06T23:28:22.213659Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature engineering here\n",
    "def fe(df, is_train):\n",
    "\n",
    "    df[\"group\"] = df[\"batch\"].astype(\"str\") + \"_\" + df[\"mini_batch\"].astype(\"str\")\n",
    "    \n",
    "#     # shift features\n",
    "#     for shift_val in range(1, 4):\n",
    "#         group_on = \"batch\" if is_train else \"group\"\n",
    "#         df[f'shift+{shift_val}'] = df.groupby([group_on])['signal'].shift(shift_val).fillna(0)\n",
    "#         df[f'shift_{shift_val}'] = df.groupby([group_on])['signal'].shift(-shift_val).fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df_train_raw = fe(df_train_raw, is_train=1)\n",
    "df_test_raw = fe(df_test_raw, is_train=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:27.801870Z",
     "start_time": "2020-05-06T23:28:27.786879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>local_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>mini_batch</th>\n",
       "      <th>proba_0</th>\n",
       "      <th>proba_1</th>\n",
       "      <th>proba_2</th>\n",
       "      <th>proba_3</th>\n",
       "      <th>proba_4</th>\n",
       "      <th>proba_5</th>\n",
       "      <th>proba_6</th>\n",
       "      <th>proba_7</th>\n",
       "      <th>proba_8</th>\n",
       "      <th>proba_9</th>\n",
       "      <th>proba_10</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966731</td>\n",
       "      <td>0.028343</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996045</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996002</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  local_time  batch  mini_batch   proba_0  \\\n",
       "0  0.0001 -2.7600              0      0.0001      1           1  0.966731   \n",
       "1  0.0002 -2.8557              0      0.0002      1           1  0.996045   \n",
       "2  0.0003 -2.4074              0      0.0003      1           1  0.976313   \n",
       "3  0.0004 -3.1404              0      0.0004      1           1  0.996002   \n",
       "4  0.0005 -3.1525              0      0.0005      1           1  0.997465   \n",
       "\n",
       "    proba_1   proba_2   proba_3  proba_4  proba_5  proba_6  proba_7  proba_8  \\\n",
       "0  0.028343  0.004812  0.000114      0.0      0.0      0.0      0.0      0.0   \n",
       "1  0.003466  0.000426  0.000063      0.0      0.0      0.0      0.0      0.0   \n",
       "2  0.018989  0.004677  0.000021      0.0      0.0      0.0      0.0      0.0   \n",
       "3  0.003625  0.000326  0.000046      0.0      0.0      0.0      0.0      0.0   \n",
       "4  0.002335  0.000158  0.000042      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   proba_9  proba_10 group  \n",
       "0      0.0       0.0   1_1  \n",
       "1      0.0       0.0   1_1  \n",
       "2      0.0       0.0   1_1  \n",
       "3      0.0       0.0   1_1  \n",
       "4      0.0       0.0   1_1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:27.809059Z",
     "start_time": "2020-05-06T23:28:27.803177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used columns is ['signal', 'proba_0', 'proba_1', 'proba_2', 'proba_3', 'proba_4', 'proba_5', 'proba_6', 'proba_7', 'proba_8', 'proba_9', 'proba_10']\n"
     ]
    }
   ],
   "source": [
    "use_cols = [\n",
    "    col for col in df_train_raw.columns if col not in\n",
    "    [\"time\", \"local_time\", \"open_channels\", \"batch\", \"mini_batch\", \"group\"]\n",
    "]\n",
    "print(\"Used columns is\", use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:27.818902Z",
     "start_time": "2020-05-06T23:28:27.809910Z"
    }
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 500\n",
    "def chop_seq(df_batch_i, is_train):\n",
    "\n",
    "    df_batch_i_features = []\n",
    "    df_batch_i_y = []\n",
    "    df_batch_i_group = []\n",
    "    \n",
    "    WHOLE_LEN = 5e5 if is_train else 1e5\n",
    "    \n",
    "    for i in range(int(WHOLE_LEN/SEQ_LEN)):\n",
    "\n",
    "        # (SEQ_LEN, 5)\n",
    "        tmp = df_batch_i[(SEQ_LEN * i):(SEQ_LEN * (i + 1))]\n",
    "        df_batch_i_features.append(tmp[use_cols].values)\n",
    "        df_batch_i_y.append(tmp[TARGET].values)\n",
    "        df_batch_i_group.append(tmp[\"group\"].values)\n",
    "\n",
    "    return df_batch_i_features, df_batch_i_y, df_batch_i_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:29.428983Z",
     "start_time": "2020-05-06T23:28:27.819884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: (2000, 500, 12) (2000, 500)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "df_train = []\n",
    "df_train_y = []\n",
    "groups = []\n",
    "\n",
    "for batch_i in [3, 7]:\n",
    "    df_batch_i = df_train_raw[df_train_raw.batch == batch_i]\n",
    "    df_batch_i_features, df_batch_i_y, df_batch_i_group = chop_seq(df_batch_i, is_train=1)\n",
    "    df_train.append(df_batch_i_features)\n",
    "    df_train_y.append(df_batch_i_y)\n",
    "    groups.append(df_batch_i_group)\n",
    "\n",
    "df_train = np.array(df_train).reshape(\n",
    "    [-1, SEQ_LEN, np.array(df_train).shape[-1]])\n",
    "df_train_y = np.array(df_train_y).reshape([-1, SEQ_LEN])\n",
    "groups = np.array(groups).reshape([-1, SEQ_LEN])[:,0]\n",
    "\n",
    "print(\"TRAIN:\", df_train.shape, df_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:29.626700Z",
     "start_time": "2020-05-06T23:28:29.430001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: (200, 500, 12) (200, 500)\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "df_test = []\n",
    "df_test_y = []\n",
    "df_test_groups = []\n",
    "\n",
    "mini_batch_list = [[1,5]]\n",
    "for batch_i, mini_batch_i in mini_batch_list:\n",
    "    df_batch_i = df_test_raw[(df_test_raw.batch == batch_i) & (df_test_raw.mini_batch == mini_batch_i)]\n",
    "    df_batch_i_features, df_batch_i_y, df_test_batch_i_group = chop_seq(df_batch_i, is_train=0)\n",
    "    df_test.append(df_batch_i_features)\n",
    "    df_test_y.append(df_batch_i_y)\n",
    "    df_test_groups.append(df_test_batch_i_group)\n",
    "\n",
    "df_test = np.array(df_test).reshape(\n",
    "    [-1, SEQ_LEN, np.array(df_test).shape[-1]])\n",
    "df_test_y = np.array(df_test_y).reshape([-1, SEQ_LEN])\n",
    "df_test_groups = np.array(df_test_groups).reshape([-1, SEQ_LEN])[:,0]\n",
    "\n",
    "print(\"TEST:\", df_test.shape, df_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:29.637839Z",
     "start_time": "2020-05-06T23:28:29.627730Z"
    }
   },
   "outputs": [],
   "source": [
    "# model function (very important, you can try different arquitectures to get a better score. I believe that top public leaderboard is a 1D Conv + RNN style)\n",
    "def Classifier(shape_):\n",
    "    \n",
    "    def cbr(x, out_layer, kernel, stride, dilation):\n",
    "        x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    \n",
    "    def wave_block(x, filters, kernel_size, n):\n",
    "        dilation_rates = [2**i for i in range(n)]\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = x\n",
    "        for dilation_rate in dilation_rates:\n",
    "            tanh_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same', \n",
    "                              activation = 'tanh', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            sigm_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same',\n",
    "                              activation = 'sigmoid', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            x = Multiply()([tanh_out, sigm_out])\n",
    "            x = Conv1D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = Add()([res_x, x])\n",
    "        return res_x\n",
    "    \n",
    "    inp = Input(shape = (shape_))\n",
    "    x = cbr(inp, 64, 5, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 32, 3, 8)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = wave_block(x, 128, 3, 1)\n",
    "    x = cbr(x, 32, 5, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(class_num, activation = 'softmax', name = 'out')(x)\n",
    "    \n",
    "    model = models.Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    opt = Adam(lr = LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(loss = losses.CategoricalCrossentropy(), optimizer = opt, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:29.753956Z",
     "start_time": "2020-05-06T23:28:29.638842Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "oof_ = np.zeros([df_train.shape[0], df_train.shape[1], class_num])\n",
    "preds_ = np.zeros((df_test.shape[0] * df_test.shape[1], class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:28:29.769865Z",
     "start_time": "2020-05-06T23:28:29.754854Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_y = pd.get_dummies(df_train_y.reshape([-1])).values.reshape([-1, SEQ_LEN, class_num])\n",
    "df_test_y = np.zeros([df_train_y.shape[0], df_train_y.shape[1], class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:36:28.579204Z",
     "start_time": "2020-05-06T23:28:29.770734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running folder 0 : Evaluate on ['3_5' '7_5']\n",
      "Our training dataset shape is (1600, 500, 12)\n",
      "Our validation dataset shape is (400, 500, 12)\n",
      "WARNING:tensorflow:From /home/ww6p9/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Epoch 00016: early stopping\n",
      "Training fold 1 completed. macro f1 score : 0.99684\n",
      "Running folder 1 : Evaluate on ['3_4' '7_4']\n",
      "Our training dataset shape is (1600, 500, 12)\n",
      "Our validation dataset shape is (400, 500, 12)\n",
      "Epoch 00016: early stopping\n",
      "Training fold 2 completed. macro f1 score : 0.99694\n",
      "Running folder 2 : Evaluate on ['3_3' '7_3']\n",
      "Our training dataset shape is (1600, 500, 12)\n",
      "Our validation dataset shape is (400, 500, 12)\n",
      "Epoch 00016: early stopping\n",
      "Training fold 3 completed. macro f1 score : 0.99685\n",
      "Running folder 3 : Evaluate on ['3_2' '7_2']\n",
      "Our training dataset shape is (1600, 500, 12)\n",
      "Our validation dataset shape is (400, 500, 12)\n",
      "Epoch 00016: early stopping\n",
      "Training fold 4 completed. macro f1 score : 0.99709\n",
      "Running folder 4 : Evaluate on ['3_1' '7_1']\n",
      "Our training dataset shape is (1600, 500, 12)\n",
      "Our validation dataset shape is (400, 500, 12)\n",
      "Epoch 00016: early stopping\n",
      "Training fold 5 completed. macro f1 score : 0.99700\n"
     ]
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "for index, (tr_idx, val_idx) in enumerate(gkf.split(df_train, df_train_y, groups)):\n",
    "    train_x, train_y = df_train[tr_idx], df_train_y[tr_idx]\n",
    "    valid_x, valid_y = df_train[val_idx], df_train_y[val_idx]\n",
    "    print(\"Running folder\", index , \": Evaluate on\", np.unique(groups[val_idx]))\n",
    "    print(f'Our training dataset shape is {train_x.shape}')\n",
    "    print(f'Our validation dataset shape is {valid_x.shape}')\n",
    "    \n",
    "    shape_ = (None, train_x.shape[2])\n",
    "    model = Classifier(shape_)\n",
    "    cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "    model.fit(train_x,train_y,\n",
    "              epochs = nn_epochs,\n",
    "              callbacks = [cb_lr_schedule, early_stop], #MacroF1(model, valid_x, valid_y) \n",
    "              batch_size = nn_batch_size,verbose = 0,\n",
    "              validation_data = (valid_x,valid_y))\n",
    "    preds_f = model.predict(valid_x)\n",
    "    f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro') \n",
    "    print(f'Training fold {index + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
    "    oof_[val_idx] += preds_f\n",
    "    te_preds = model.predict(df_test)\n",
    "    te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n",
    "    preds_ += te_preds / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T07:24:17.131676Z",
     "start_time": "2020-05-04T07:24:17.125892Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:36:28.833961Z",
     "start_time": "2020-05-06T23:36:28.580200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof F1 score is 0.9969441493504583\n"
     ]
    }
   ],
   "source": [
    "# goal: 0.9969\n",
    "# for now: 0.9969\n",
    "print(\"oof F1 score is\", f1_score(oof_.reshape([-1,class_num]).argmax(axis=1), df_train_y.reshape([-1,class_num]).argmax(axis=1), average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T23:39:07.742630Z",
     "start_time": "2020-05-06T23:39:07.720975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof shape is (1000000,), test pred shape is (100000,)\n"
     ]
    }
   ],
   "source": [
    "oof_pred = oof_.reshape([-1,class_num]).argmax(axis=1)\n",
    "test_pred = preds_.argmax(axis=1)\n",
    "\n",
    "print(f\"oof shape is {oof_pred.shape}, test pred shape is {test_pred.shape}\")\n",
    "# # save oof and prediction\n",
    "# np.save('oof/oof_model_2.npy', oof_pred)\n",
    "# np.save('pred/pred_model_2.npy', test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
