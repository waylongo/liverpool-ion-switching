{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:05:53.974412Z",
     "start_time": "2020-05-03T01:05:53.498794Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:05:56.068039Z",
     "start_time": "2020-05-03T01:05:53.975413Z"
    }
   },
   "outputs": [],
   "source": [
    "# chris clean dataset\n",
    "df_train = pd.read_csv(\"../input/train_clean.csv\")\n",
    "df_test = pd.read_csv(\"../input/test_clean.csv\")\n",
    "\n",
    "TARGET = \"open_channels\"\n",
    "df_test[TARGET] = 0\n",
    "\n",
    "df_train[\"local_time\"] = df_train.time % 50\n",
    "df_train.loc[df_train.local_time == 0.0000, \"local_time\"] = 50\n",
    "\n",
    "df_test[\"local_time\"] = df_test.time % 50\n",
    "df_test.loc[df_test.local_time == 0.0000, \"local_time\"] = 50\n",
    "\n",
    "df_test[\"mini_local_time\"] = df_test.time % 10\n",
    "df_test.loc[df_test.local_time == 0.0000, \"mini_local_time\"] = 10\n",
    "\n",
    "BATCH_SIZE = 500000\n",
    "\n",
    "# train\n",
    "for batch_i in range(10):\n",
    "    df_train.loc[BATCH_SIZE * batch_i:BATCH_SIZE * batch_i + 500000, 'batch'] = batch_i + 1\n",
    "\n",
    "    df_train.loc[BATCH_SIZE * batch_i:BATCH_SIZE * batch_i + 100000, 'mini_batch'] = 1\n",
    "    df_train.loc[BATCH_SIZE * batch_i + 100000:BATCH_SIZE * batch_i + 200000, 'mini_batch'] = 2\n",
    "    df_train.loc[BATCH_SIZE * batch_i + 200000:BATCH_SIZE * batch_i + 300000, 'mini_batch'] = 3\n",
    "    df_train.loc[BATCH_SIZE * batch_i + 300000:BATCH_SIZE * batch_i + 400000, 'mini_batch'] = 4\n",
    "    df_train.loc[BATCH_SIZE * batch_i + 400000:BATCH_SIZE * batch_i + 500000, 'mini_batch'] = 5\n",
    "# test\n",
    "for batch_i in range(4):\n",
    "    df_test.loc[BATCH_SIZE * batch_i:BATCH_SIZE * batch_i + 500000, 'batch'] = batch_i + 1\n",
    "\n",
    "    df_test.loc[BATCH_SIZE * batch_i:BATCH_SIZE * batch_i + 100000, 'mini_batch'] = 1\n",
    "    df_test.loc[BATCH_SIZE * batch_i + 100000:BATCH_SIZE * batch_i + 200000, 'mini_batch'] = 2\n",
    "    df_test.loc[BATCH_SIZE * batch_i + 200000:BATCH_SIZE * batch_i + 300000, 'mini_batch'] = 3\n",
    "    df_test.loc[BATCH_SIZE * batch_i + 300000:BATCH_SIZE * batch_i + 400000, 'mini_batch'] = 4\n",
    "    df_test.loc[BATCH_SIZE * batch_i + 400000:BATCH_SIZE * batch_i + 500000, 'mini_batch'] = 5\n",
    "    \n",
    "df_train = df_train.drop(df_train[(df_train.batch.isin([8]))].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:05:56.115702Z",
     "start_time": "2020-05-03T01:05:56.069136Z"
    }
   },
   "outputs": [],
   "source": [
    "# channel 0 - batch 1\n",
    "channel_0_batch_1 = df_train[(df_train.batch == 1) & (df_train.open_channels == 0)]\n",
    "channel_0_batch_1_threshold = channel_0_batch_1.signal.quantile(0.99999)\n",
    "channel_0_batch_1.loc[channel_0_batch_1.signal > channel_0_batch_1_threshold, \"signal\"] = channel_0_batch_1_threshold\n",
    "df_train.loc[(df_train.batch == 1) & (df_train.open_channels == 0), \"signal\"] = channel_0_batch_1.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:05:56.162607Z",
     "start_time": "2020-05-03T01:05:56.116726Z"
    }
   },
   "outputs": [],
   "source": [
    "# channel 0 - batch 2\n",
    "channel_0_batch_2 = df_train[(df_train.batch == 2) & (df_train.open_channels == 0)]\n",
    "channel_0_batch_2_threshold = channel_0_batch_2.signal.quantile(0.99999)\n",
    "channel_0_batch_2.loc[channel_0_batch_2.signal > channel_0_batch_2_threshold, \"signal\"] = channel_0_batch_2_threshold\n",
    "df_train.loc[(df_train.batch == 2) & (df_train.open_channels == 0), \"signal\"] = channel_0_batch_2.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:06:04.873196Z",
     "start_time": "2020-05-03T01:05:56.163494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500000, 6) (2000000, 7) (2000000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>local_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>mini_batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  local_time  batch  mini_batch\n",
       "0  0.0001 -2.7600              0      0.0001    1.0         1.0\n",
       "1  0.0002 -2.8557              0      0.0002    1.0         1.0\n",
       "2  0.0003 -2.4074              0      0.0003    1.0         1.0\n",
       "3  0.0004 -3.1404              0      0.0004    1.0         1.0\n",
       "4  0.0005 -3.1525              0      0.0005    1.0         1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub['time'] = [format(sub.time.values[x], '.4f') for x in range(2000000)]\n",
    "\n",
    "print(df_train.shape, df_test.shape, sub.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:06:04.886177Z",
     "start_time": "2020-05-03T01:06:04.874014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test shape is: (4500000, 6) (2000000, 7)\n",
      "features used # is 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.4074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.1525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal\n",
       "0 -2.7600\n",
       "1 -2.8557\n",
       "2 -2.4074\n",
       "3 -3.1404\n",
       "4 -3.1525"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_list = [\n",
    "    \"b\", \"g\", \"r\", \"c\", \"m\", \"k\", \"y\", '#0000FF', '#8A2BE2', '#A52A2A',\n",
    "    '#DEB887', '#5F9EA0'\n",
    "]\n",
    "\n",
    "# drop useless features\n",
    "drop_features = [\n",
    "    \"time\",\n",
    "    \"open_channels\",\n",
    "    \"local_time\",\n",
    "    \"batch\",\n",
    "    \"mini_batch\",\n",
    "]\n",
    "all_features = [col for col in df_train.columns if col not in drop_features]\n",
    "\n",
    "print(\"train/test shape is:\", df_train.shape, df_test.shape)\n",
    "print(\"features used # is\", len(all_features))\n",
    "df_train[all_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:06:04.909307Z",
     "start_time": "2020-05-03T01:06:04.887050Z"
    }
   },
   "outputs": [],
   "source": [
    "class ViterbiClassifier:\n",
    "    def __init__(self):\n",
    "        self._p_trans = None\n",
    "        self._p_signal = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._states = np.unique(y)\n",
    "        self._n_states = len(self._states)\n",
    "        \n",
    "        self._p_trans = self.markov_p_trans(y)\n",
    "        \n",
    "        self._dists = []\n",
    "        for s in np.arange(y.min(), y.max() + 1):\n",
    "            self._dists.append((np.mean(x[y == s]), np.std(x[y == s])))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x, p_signal=None, proba=False):\n",
    "        if p_signal is None:\n",
    "            p_signal = self.markov_p_signal(x)\n",
    "\n",
    "        preds, probs = self.viterbi(self._p_trans, p_signal[self._states], x)\n",
    "        \n",
    "        if proba:\n",
    "            return probs\n",
    "        else:\n",
    "            return preds\n",
    "    \n",
    "    def markov_p_signal(self, signal):\n",
    "        p_signal = np.zeros((self._n_states, len(signal)))\n",
    "        for k, dist in enumerate(self._dists):\n",
    "            p_signal[k, :] = norm.pdf(signal, *dist)\n",
    "            \n",
    "        return p_signal\n",
    "    \n",
    "    def markov_p_trans(self, states):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        max_state = np.max(states)\n",
    "        states_next = np.roll(states, -1)\n",
    "        matrix = []\n",
    "        for i in range(max_state + 1):\n",
    "            current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "            if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "                current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "            else:\n",
    "                current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "            matrix.append(current_row)\n",
    "        return np.array(matrix)\n",
    "    \n",
    "    def viterbi(self, p_trans, p_signal, signal):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        offset = 10**(-20) # added to values to avoid problems with log2(0)\n",
    "\n",
    "        p_trans_tlog  = np.transpose(np.log2(p_trans  + offset)) # p_trans, logarithm + transposed\n",
    "        p_signal_tlog = np.transpose(np.log2(p_signal + offset)) # p_signal, logarithm + transposed\n",
    "        \n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T2 = np.zeros(p_signal.shape)\n",
    "\n",
    "        T1[:, 0] = p_signal_tlog[0, :]\n",
    "        T2[:, 0] = 0\n",
    "\n",
    "        for j in range(1, p_signal.shape[1]):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = np.max(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "                T2[i, j] = np.argmax(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "        \n",
    "        x = np.empty(p_signal.shape[1], 'B')\n",
    "        x[-1] = np.argmax(T1[:, p_signal.shape[1] - 1])\n",
    "        for i in reversed(range(1, p_signal.shape[1])):\n",
    "            x[i - 1] = T2[x[i], i]\n",
    "    \n",
    "        return x, T1\n",
    "    \n",
    "class PosteriorDecoder:\n",
    "    def __init__(self):\n",
    "        self._p_trans = None\n",
    "        self._p_signal = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._states = np.unique(y)\n",
    "        self._n_states = len(self._states)\n",
    "        \n",
    "        self._dists = []\n",
    "        for s in np.arange(y.min(), y.max() + 1):\n",
    "            self._dists.append((np.mean(x[y == s]), np.std(x[y == s])))\n",
    "        \n",
    "        self._p_trans = self.markov_p_trans(y)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x, p_signal=None, proba=False):\n",
    "        if p_signal is None:\n",
    "            p_signal = self.markov_p_signal(x)\n",
    "        preds = self.posterior_decoding(self._p_trans, p_signal[self._states])\n",
    "        \n",
    "        if proba:\n",
    "            return probs\n",
    "        else:\n",
    "            return preds\n",
    "    \n",
    "    def markov_p_signal(self, signal):\n",
    "        p_signal = np.zeros((self._n_states, len(signal)))\n",
    "        for k, dist in enumerate(self._dists):\n",
    "            p_signal[k, :] = norm.pdf(signal, *dist)\n",
    "            \n",
    "        return p_signal\n",
    "    \n",
    "    def markov_p_trans(self, states):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        max_state = np.max(states)\n",
    "        states_next = np.roll(states, -1)\n",
    "        matrix = []\n",
    "        for i in range(max_state + 1):\n",
    "            current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "            if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "                current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "            else:\n",
    "                current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "            matrix.append(current_row)\n",
    "        return np.array(matrix)\n",
    "    \n",
    "    def forward(self, p_trans, p_signal):\n",
    "        \"\"\"Calculate the probability of being in state `k` at time `t`, \n",
    "           given all previous observations `x_1 ... x_t`\"\"\"\n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T1[:, 0] = p_signal[:, 0]\n",
    "        T1[:, 0] /= np.sum(T1[:, 0])\n",
    "\n",
    "        for j in range(1, p_signal.shape[1]):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = p_signal[i, j] * np.sum(T1[:, j - 1] * p_trans[i, :])\n",
    "            T1[:, j] /= np.sum(T1[:, j])\n",
    "\n",
    "        return T1\n",
    "\n",
    "    def backward(self, p_trans, p_signal):\n",
    "        \"\"\"Calculate the probability of observing `x_{t + 1} ... x_n` if we \n",
    "           start in state `k` at time `t`.\"\"\"\n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T1[:, -1] = p_signal[:, -1]\n",
    "        T1[:, -1] /= np.sum(T1[:, -1])\n",
    "\n",
    "        for j in range(p_signal.shape[1] - 2, -1, -1):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = np.sum(T1[:, j + 1] * p_trans[:, i] * p_signal[:, j + 1])\n",
    "            T1[:, j] /= np.sum(T1[:, j])\n",
    "\n",
    "        return T1\n",
    "    \n",
    "    def posterior_decoding(self, p_trans, p_signal):\n",
    "        fwd = self.forward(p_trans, p_signal)\n",
    "        bwd = self.backward(p_trans, p_signal)\n",
    "\n",
    "        x = np.empty(p_signal.shape[1], 'B')\n",
    "        for i in range(p_signal.shape[1]):\n",
    "            x[i] = np.argmax(fwd[:, i] * bwd[:, i])\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 5 - batch 5&10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:06:05.499840Z",
     "start_time": "2020-05-03T01:06:04.910516Z"
    }
   },
   "outputs": [],
   "source": [
    "# model 5: batch 5&10\n",
    "BATCH_GROUP_5 = [5,10]\n",
    "df_train_5 = df_train[df_train.batch.isin(BATCH_GROUP_5)]\n",
    "df_train_5.loc[df_train_5.open_channels==0, \"open_channels\"] = 1\n",
    "\n",
    "oof_pred = np.zeros(df_train_5.shape[0])\n",
    "\n",
    "df_train_5[\"group\"] = df_train_5[\"batch\"].astype(\"str\") + df_train_5[\"mini_batch\"].astype(\"str\")\n",
    "df_train_5 = df_train_5.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:22:09.420644Z",
     "start_time": "2020-05-03T01:06:05.500877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid viterbi F1 is 0.8581854159277574\n",
      "Valid viterbi F1 is 0.8603880916175708\n",
      "Valid viterbi F1 is 0.853435986000602\n",
      "Valid viterbi F1 is 0.8560073081305587\n",
      "Valid viterbi F1 is 0.8562576978136631\n",
      "Valid viterbi F1 is 0.8504030989665043\n",
      "Valid viterbi F1 is 0.8420419526835901\n",
      "Valid viterbi F1 is 0.8584857603035709\n",
      "Valid viterbi F1 is 0.85221220156568\n",
      "Valid viterbi F1 is 0.8398913201530519\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=10)\n",
    "for train_index, valid_index in group_kfold.split(df_train_5, df_train_5[TARGET], df_train_5[\"group\"]):\n",
    "    valid_pred = pd.DataFrame()\n",
    "\n",
    "    for col in df_train_5.loc[train_index][\"group\"].unique():\n",
    "\n",
    "        tmp = df_train_5[df_train_5.group == col]\n",
    "\n",
    "        viterbi = ViterbiClassifier().fit(tmp[\"signal\"], tmp[TARGET] - 1)\n",
    "        valid_pred[col] = viterbi.predict(df_train_5.loc[valid_index][\"signal\"])\n",
    "\n",
    "#         print(col, \"viterbi F1 is\", f1_score(y_pred=valid_pred[col], y_true=df_train_5.loc[valid_index][TARGET] - 1, average='macro'))\n",
    "    valid_pred[\"avg\"] = (valid_pred.sum(axis=1)/9).astype(\"int\")\n",
    "    \n",
    "    print(\"Valid viterbi F1 is\", f1_score(y_pred=valid_pred[\"avg\"], y_true=df_train_5.loc[valid_index][TARGET] - 1, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
