{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior Decoding (Forward-Backward Algorithm).\n",
    "\n",
    "In this notebook, I will implement the [Forward-Backward Algorithm](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm) (which is sometimes called Posterior Decoding as well), which is very similar to the [Viterbi Algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm), but it performs two passes. In a first, forward pass we try to estimate the probability of ending up in any particular state given the first t observations, $F_t = P(X_t\\ |\\ o_{1:t})$. In a second, backward pass we try to estimate the probability of observing the remaining observations, given a starting state, $B_t = P(o_{t+1:T}\\ |\\ X_t)$. We then calculate $P_t = F_tB_t,\\ \\forall t \\in \\{ 1, \\ldots, T \\}$. While Viterbi gives you the most likely sequence, posterior (Forward-Backward) gives most likely state at each position ([source](https://stats.stackexchange.com/questions/31119/posterior-probability-vs-viterbi-algorithm)), which is closer related to the competition objective. I got the implementation details from this [source](https://cran.r-project.org/web/packages/seqHMM/vignettes/seqHMM_algorithms.pdf).\n",
    "\n",
    "The difference in performance with Viterbi is rather marginal, and the algorithm is a bit slower. I just share it here for completeness. Moreover, now you have two matrices of probabilities (`fwd` and `bwd`, as opposed to only `T1` of Viterbi). This could be even more features for your feature set.\n",
    "\n",
    "\n",
    "**Another very interesting idea that I have been experimenten with is not estimating `p_signal`, but instead using out-of-fold predictions of strong public notebooks. Unfortunately, I've had no luck with that approach so far. Let me know if you manage to get it working! Moreover, if you manage to improve my implementation either in terms of predictive performance or speed, I would love to hear how!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:11:52.110243Z",
     "start_time": "2020-05-02T23:11:51.603644Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:11:53.089155Z",
     "start_time": "2020-05-02T23:11:52.111369Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train_clean.csv')\n",
    "test  = pd.read_csv('../input/test_clean.csv')\n",
    "# orig_train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi & Posterior Decoding (collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:11:53.112320Z",
     "start_time": "2020-05-02T23:11:53.090167Z"
    },
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "class ViterbiClassifier:\n",
    "    def __init__(self):\n",
    "        self._p_trans = None\n",
    "        self._p_signal = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._states = np.unique(y)\n",
    "        self._n_states = len(self._states)\n",
    "        \n",
    "        self._p_trans = self.markov_p_trans(y)\n",
    "        \n",
    "        self._dists = []\n",
    "        for s in np.arange(y.min(), y.max() + 1):\n",
    "            self._dists.append((np.mean(x[y == s]), np.std(x[y == s])))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x, p_signal=None, proba=False):\n",
    "        if p_signal is None:\n",
    "            p_signal = self.markov_p_signal(x)\n",
    "\n",
    "        preds, probs = self.viterbi(self._p_trans, p_signal[self._states], x)\n",
    "        \n",
    "        if proba:\n",
    "            return probs\n",
    "        else:\n",
    "            return preds\n",
    "    \n",
    "    def markov_p_signal(self, signal):\n",
    "        p_signal = np.zeros((self._n_states, len(signal)))\n",
    "        for k, dist in enumerate(self._dists):\n",
    "            p_signal[k, :] = norm.pdf(signal, *dist)\n",
    "            \n",
    "        return p_signal\n",
    "    \n",
    "    def markov_p_trans(self, states):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        max_state = np.max(states)\n",
    "        states_next = np.roll(states, -1)\n",
    "        matrix = []\n",
    "        for i in range(max_state + 1):\n",
    "            current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "            if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "                current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "            else:\n",
    "                current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "            matrix.append(current_row)\n",
    "        return np.array(matrix)\n",
    "    \n",
    "    def viterbi(self, p_trans, p_signal, signal):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        offset = 10**(-20) # added to values to avoid problems with log2(0)\n",
    "\n",
    "        p_trans_tlog  = np.transpose(np.log2(p_trans  + offset)) # p_trans, logarithm + transposed\n",
    "        p_signal_tlog = np.transpose(np.log2(p_signal + offset)) # p_signal, logarithm + transposed\n",
    "        \n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T2 = np.zeros(p_signal.shape)\n",
    "\n",
    "        T1[:, 0] = p_signal_tlog[0, :]\n",
    "        T2[:, 0] = 0\n",
    "\n",
    "        for j in range(1, p_signal.shape[1]):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = np.max(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "                T2[i, j] = np.argmax(T1[:, j - 1] + p_trans_tlog[:, i] + p_signal_tlog[j, i])\n",
    "        \n",
    "        x = np.empty(p_signal.shape[1], 'B')\n",
    "        x[-1] = np.argmax(T1[:, p_signal.shape[1] - 1])\n",
    "        for i in reversed(range(1, p_signal.shape[1])):\n",
    "            x[i - 1] = T2[x[i], i]\n",
    "    \n",
    "        return x, T1\n",
    "    \n",
    "class PosteriorDecoder:\n",
    "    def __init__(self):\n",
    "        self._p_trans = None\n",
    "        self._p_signal = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self._states = np.unique(y)\n",
    "        self._n_states = len(self._states)\n",
    "        \n",
    "        self._dists = []\n",
    "        for s in np.arange(y.min(), y.max() + 1):\n",
    "            self._dists.append((np.mean(x[y == s]), np.std(x[y == s])))\n",
    "        \n",
    "        self._p_trans = self.markov_p_trans(y)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, x, p_signal=None, proba=False):\n",
    "        if p_signal is None:\n",
    "            p_signal = self.markov_p_signal(x)\n",
    "        preds = self.posterior_decoding(self._p_trans, p_signal[self._states])\n",
    "        \n",
    "        if proba:\n",
    "            return probs\n",
    "        else:\n",
    "            return preds\n",
    "    \n",
    "    def markov_p_signal(self, signal):\n",
    "        p_signal = np.zeros((self._n_states, len(signal)))\n",
    "        for k, dist in enumerate(self._dists):\n",
    "            p_signal[k, :] = norm.pdf(signal, *dist)\n",
    "            \n",
    "        return p_signal\n",
    "    \n",
    "    def markov_p_trans(self, states):\n",
    "        # https://www.kaggle.com/friedchips/the-viterbi-algorithm-a-complete-solution\n",
    "        max_state = np.max(states)\n",
    "        states_next = np.roll(states, -1)\n",
    "        matrix = []\n",
    "        for i in range(max_state + 1):\n",
    "            current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "            if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "                current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "            else:\n",
    "                current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "            matrix.append(current_row)\n",
    "        return np.array(matrix)\n",
    "    \n",
    "    def forward(self, p_trans, p_signal):\n",
    "        \"\"\"Calculate the probability of being in state `k` at time `t`, \n",
    "           given all previous observations `x_1 ... x_t`\"\"\"\n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T1[:, 0] = p_signal[:, 0]\n",
    "        T1[:, 0] /= np.sum(T1[:, 0])\n",
    "\n",
    "        for j in range(1, p_signal.shape[1]):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = p_signal[i, j] * np.sum(T1[:, j - 1] * p_trans[i, :])\n",
    "            T1[:, j] /= np.sum(T1[:, j])\n",
    "\n",
    "        return T1\n",
    "\n",
    "    def backward(self, p_trans, p_signal):\n",
    "        \"\"\"Calculate the probability of observing `x_{t + 1} ... x_n` if we \n",
    "           start in state `k` at time `t`.\"\"\"\n",
    "        T1 = np.zeros(p_signal.shape)\n",
    "        T1[:, -1] = p_signal[:, -1]\n",
    "        T1[:, -1] /= np.sum(T1[:, -1])\n",
    "\n",
    "        for j in range(p_signal.shape[1] - 2, -1, -1):\n",
    "            for i in range(len(p_trans)):\n",
    "                T1[i, j] = np.sum(T1[:, j + 1] * p_trans[:, i] * p_signal[:, j + 1])\n",
    "            T1[:, j] /= np.sum(T1[:, j])\n",
    "\n",
    "        return T1\n",
    "    \n",
    "    def posterior_decoding(self, p_trans, p_signal):\n",
    "        fwd = self.forward(p_trans, p_signal)\n",
    "        bwd = self.backward(p_trans, p_signal)\n",
    "\n",
    "        x = np.empty(p_signal.shape[1], 'B')\n",
    "        for i in range(p_signal.shape[1]):\n",
    "            x[i] = np.argmax(fwd[:, i] * bwd[:, i])\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:11:53.415615Z",
     "start_time": "2020-05-02T23:11:53.113200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000000, 1000000, 1000000, 1000000, 1000000]\n"
     ]
    }
   ],
   "source": [
    "train['batch'] = (train['time'] - 0.0001) // 50\n",
    "counts = train.groupby('batch').count()['time'].values\n",
    "models = [0, 0, 1, 2, 4, 3, 1, 2, 3, 4]\n",
    "blocks = [[], [], [], [], []]\n",
    "total = 0\n",
    "for model, count in zip(models, counts):\n",
    "    blocks[model].extend(list(range(total, total + count)))\n",
    "    total += count\n",
    "print([len(x) for x in blocks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T00:06:53.608654Z",
     "start_time": "2020-05-03T00:06:53.603751Z"
    }
   },
   "outputs": [],
   "source": [
    "# train['block'] = np.NaN\n",
    "# for model, ix in enumerate(blocks):\n",
    "#     train.loc[ix, 'block'] = model\n",
    "# distributions = train.groupby(['block', 'open_channels'])['signal'].agg(['mean', 'std'])\n",
    "# distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:11:53.429873Z",
     "start_time": "2020-05-02T23:11:53.418702Z"
    }
   },
   "outputs": [],
   "source": [
    "true_state = train.open_channels.values\n",
    "signal = train.signal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:16:50.294447Z",
     "start_time": "2020-05-02T23:11:53.431115Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model #0] || viterbi: F1 = 0.9943615410326818 || Pos. Dec.: F1 = 0.9943616947073695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    964796\n",
      "           1       0.99      0.99      0.99     35204\n",
      "\n",
      "    accuracy                           1.00   1000000\n",
      "   macro avg       0.99      1.00      0.99   1000000\n",
      "weighted avg       1.00      1.00      1.00   1000000\n",
      "\n",
      "[Model #1] || viterbi: F1 = 0.9959355327196735 || Pos. Dec.: F1 = 0.9959609135251812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    249199\n",
      "           1       1.00      1.00      1.00    750801\n",
      "\n",
      "    accuracy                           1.00   1000000\n",
      "   macro avg       1.00      1.00      1.00   1000000\n",
      "weighted avg       1.00      1.00      1.00   1000000\n",
      "\n",
      "[Model #2] || viterbi: F1 = 0.9058142944104927 || Pos. Dec.: F1 = 0.912763224394722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82     24232\n",
      "           1       0.93      0.92      0.93    176123\n",
      "           2       0.94      0.95      0.94    433542\n",
      "           3       0.97      0.95      0.96    366103\n",
      "\n",
      "    accuracy                           0.94   1000000\n",
      "   macro avg       0.91      0.92      0.91   1000000\n",
      "weighted avg       0.94      0.94      0.94   1000000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-64f4ae873427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPosteriorDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpos_dec_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d3ca6496c311>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, p_signal, proba)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp_signal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mp_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkov_p_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_p_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d3ca6496c311>\u001b[0m in \u001b[0;36mposterior_decoding\u001b[0;34m(self, p_trans, p_signal)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mposterior_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mfwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mbwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d3ca6496c311>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, p_trans, p_signal)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mT1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_signal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_trans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mT1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2166\u001b[0m     \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m     \"\"\"\n\u001b[0;32m-> 2168\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gentype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2169\u001b[0m         \u001b[0;31m# 2018-02-25, 1.15.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         warnings.warn(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "viterbi_predictions = np.zeros(len(signal))\n",
    "pos_dec_predictions = np.zeros(len(signal))\n",
    "for i, ix in enumerate(blocks):\n",
    "    sub_signal = signal[ix]\n",
    "    \n",
    "    viterbi = ViterbiClassifier().fit(sub_signal, true_state[ix])\n",
    "    viterbi_predictions[ix] = viterbi.predict(sub_signal)\n",
    "    \n",
    "    decoder = PosteriorDecoder().fit(sub_signal, true_state[ix])\n",
    "    pos_dec_predictions[ix] = decoder.predict(sub_signal)\n",
    "    models.append(decoder)\n",
    "    \n",
    "    print('[Model #{}] || viterbi: F1 = {} || Pos. Dec.: F1 = {}'.format(\n",
    "        i, \n",
    "        f1_score(y_pred=viterbi_predictions[ix], y_true=true_state[ix], average='macro'),\n",
    "        f1_score(y_pred=pos_dec_predictions[ix], y_true=true_state[ix], average='macro')\n",
    "    ))\n",
    "    \n",
    "    print(classification_report(y_pred=pos_dec_predictions[ix], y_true=true_state[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:16:50.295444Z",
     "start_time": "2020-05-02T23:11:51.614Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[Viterbi] Total Accuracy =\", accuracy_score(y_pred=viterbi_predictions, y_true=true_state))\n",
    "print(\"[Viterbi] Total F1 (macro) =\", f1_score(y_pred=viterbi_predictions, y_true=true_state, average='macro'))\n",
    "\n",
    "print(\"[Posterior Decoding] Total Accuracy =\", accuracy_score(y_pred=pos_dec_predictions, y_true=true_state))\n",
    "print(\"[Posterior Decoding] Total F1 (macro) =\", f1_score(y_pred=pos_dec_predictions, y_true=true_state, average='macro'))\n",
    "\n",
    "print(classification_report(y_pred=pos_dec_predictions, y_true=true_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:16:50.296071Z",
     "start_time": "2020-05-02T23:11:51.615Z"
    }
   },
   "outputs": [],
   "source": [
    "test_blocks = [\n",
    "    list(range(0, 100000)) + list(range(300000, 400000)) + list(range(800000, 900000)) + list(range(1000000, 2000000)),\n",
    "    list(range(400000, 500000)),\n",
    "    list(range(100000, 200000)) + list(range(900000, 1000000)),\n",
    "    list(range(200000, 300000)) + list(range(600000, 700000)),\n",
    "    list(range(500000, 600000)) + list(range(700000, 800000))\n",
    "]\n",
    "\n",
    "# Sanity check\n",
    "assert sum([len(x) for x in test_blocks]) == 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:16:50.296530Z",
     "start_time": "2020-05-02T23:11:51.616Z"
    }
   },
   "outputs": [],
   "source": [
    "df_subm = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "for i, ix in enumerate(test_blocks):\n",
    "    df_subm.loc[ix, 'open_channels'] = models[i].predict(test.signal.values[ix])\n",
    "df_subm.to_csv(\"../submissions/forward_backward.csv\", float_format='%.4f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:16:50.297150Z",
     "start_time": "2020-05-02T23:11:51.618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "# https://www.kaggle.com/cdeotte/one-feature-model-0-930\n",
    "plt.figure(figsize=(20,5))\n",
    "res = 1000; let = ['A','B','C','D','E','F','G','H','I','J']\n",
    "plt.plot(range(0,test.shape[0],res),df_subm.open_channels[0::res])\n",
    "for i in range(5): plt.plot([i*500000,i*500000],[-5,12.5],'r')\n",
    "for i in range(21): plt.plot([i*100000,i*100000],[-5,12.5],'r:')\n",
    "for k in range(4): plt.text(k*500000+250000,10,str(k+1),size=20)\n",
    "for k in range(10): plt.text(k*100000+40000,7.5,let[k],size=16)\n",
    "plt.title('Test Data Predictions',size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
