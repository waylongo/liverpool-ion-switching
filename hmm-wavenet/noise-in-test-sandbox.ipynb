{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:36.081545Z",
     "start_time": "2020-05-22T20:41:33.256613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, gc, random\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "import tensorflow_addons as tfa\n",
    "from tf_nn_utils import *\n",
    "from viterbi_utils_sandbox import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy.fft as fft\n",
    "from scipy import signal as scisig\n",
    "from viterbi_utils import *\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "# set gpu memory growth\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:41.988002Z",
     "start_time": "2020-05-22T20:41:36.083776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:(4500000, 8), test size:(2000000, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>local_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>mini_batch</th>\n",
       "      <th>group</th>\n",
       "      <th>signal_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-2.7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-2.8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-2.4074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-3.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "      <td>-3.1525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  local_time  batch  mini_batch group  \\\n",
       "0  0.0001 -2.7600              0      0.0001      1           1   1_1   \n",
       "1  0.0002 -2.8557              0      0.0002      1           1   1_1   \n",
       "2  0.0003 -2.4074              0      0.0003      1           1   1_1   \n",
       "3  0.0004 -3.1404              0      0.0004      1           1   1_1   \n",
       "4  0.0005 -3.1525              0      0.0005      1           1   1_1   \n",
       "\n",
       "   signal_original  \n",
       "0          -2.7600  \n",
       "1          -2.8557  \n",
       "2          -2.4074  \n",
       "3          -3.1404  \n",
       "4          -3.1525  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle('../features/train_clean.pkl')\n",
    "df_test = pd.read_pickle('../features/test_clean.pkl')\n",
    "TARGET = \"open_channels\"\n",
    "df_test[TARGET] = 0\n",
    "\n",
    "df_train[\"group\"] = df_train[\"batch\"].astype(\"str\") + \"_\" + df_train[\"mini_batch\"].astype(\"str\")\n",
    "df_test[\"group\"] = df_test[\"batch\"].astype(\"str\") + \"_\" + df_test[\"mini_batch\"].astype(\"str\")\n",
    "\n",
    "df_train[\"signal_original\"] = df_train[\"signal\"].copy()\n",
    "df_test[\"signal_original\"] = df_test[\"signal\"].copy()\n",
    "\n",
    "print(f\"train size:{df_train.shape}, test size:{df_test.shape}\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:41.990999Z",
     "start_time": "2020-05-22T20:41:41.989122Z"
    }
   },
   "outputs": [],
   "source": [
    "# configurations and main hyperparammeters\n",
    "shft = 1\n",
    "nn_epochs = 100\n",
    "nn_batch_size = 16\n",
    "class_num = 11 - shft\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.295672Z",
     "start_time": "2020-05-22T20:41:41.991925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:(1000000, 8), test size:(200000, 9)\n"
     ]
    }
   ],
   "source": [
    "# reduce batch 5&10 open_channels from 11 to 10 (class 1-10)\n",
    "df_train.loc[df_train.batch.isin([5,10]) & (df_train.open_channels < shft), \"open_channels\"] = shft\n",
    "df_train[TARGET] = df_train[TARGET] - shft\n",
    "\n",
    "# mini model\n",
    "BATCH_GROUP = [5, 10]\n",
    "df_train = df_train[df_train.batch.isin(BATCH_GROUP)].reset_index(drop=True)\n",
    "TEST_GROUP = [\"2_1\", \"2_3\"]\n",
    "df_test = df_test[df_test.group.isin(TEST_GROUP)].reset_index(drop=True)\n",
    "\n",
    "print(f\"train size:{df_train.shape}, test size:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.297988Z",
     "start_time": "2020-05-22T20:41:42.296557Z"
    }
   },
   "outputs": [],
   "source": [
    "# # remove the 50 hz noise using bandstop filter (group)\n",
    "# for group_i in df_train.group.unique():\n",
    "\n",
    "#     batch_i = df_train[df_train.group.isin([group_i])]\n",
    "#     signal_recovered = rm_noise(batch_i)\n",
    "#     df_train.loc[df_train.group.isin([group_i]), \"signal\"] = signal_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.382211Z",
     "start_time": "2020-05-22T20:41:42.298816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.218 -2.969 -1.768 -0.526  0.71   1.941  3.175  4.409  5.641  6.875]\n"
     ]
    }
   ],
   "source": [
    "sig_mean = get_mean(df_train)\n",
    "print(np.array(sig_mean).round(3))\n",
    "# sig_mean = [-4.255, -3.017, -1.779, -0.541, 0.697, 1.935, 3.173, 4.411, 5.649, 6.887]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.537745Z",
     "start_time": "2020-05-22T20:41:42.383081Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove the 50 hz noise using bandstop filter (batch)\n",
    "for batch_idx in df_train.batch.unique():\n",
    "\n",
    "    batch_i = df_train[df_train.batch.isin([batch_idx])]\n",
    "    signal_recovered = rm_noise(batch_i, sig_mean=sig_mean)\n",
    "    df_train.loc[df_train.batch.isin([batch_idx]), \"signal\"] = signal_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.612691Z",
     "start_time": "2020-05-22T20:41:42.539120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.212 -2.959 -1.766 -0.523  0.71   1.941  3.175  4.409  5.641  6.875]\n"
     ]
    }
   ],
   "source": [
    "sig_mean = get_mean(df_train)\n",
    "print(np.array(sig_mean).round(3))\n",
    "# sig_mean = [-4.255, -3.017, -1.779, -0.541, 0.697, 1.935, 3.173, 4.411, 5.649, 6.887]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.674239Z",
     "start_time": "2020-05-22T20:41:42.613911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used columns is ['signal', 'shift']\n"
     ]
    }
   ],
   "source": [
    "# feature engineering here\n",
    "def fe(df, is_train):\n",
    "\n",
    "    # shift features\n",
    "    for shift_val in range(1, 2):\n",
    "        group_on = \"group\"\n",
    "        df['shift'] = df.groupby([group_on])['signal'].shift(shift_val).fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = fe(df_train, is_train=1)\n",
    "df_test = fe(df_test, is_train=0)\n",
    "\n",
    "use_cols = [\n",
    "    col for col in df_train.columns if col not in\n",
    "    [\"time\", \"local_time\", \"open_channels\", \"batch\", \"mini_batch\", \"group\", \"oof\", \"signal_original\"]\n",
    "]\n",
    "print(\"Used columns is\", use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.777793Z",
     "start_time": "2020-05-22T20:41:42.675092Z"
    }
   },
   "outputs": [],
   "source": [
    "viterbi_cols = [\"viterbi_\" + str(i) for i in range(df_train[TARGET].nunique())]\n",
    "use_cols = use_cols + viterbi_cols\n",
    "\n",
    "for col in viterbi_cols:\n",
    "    df_train[col] = 0\n",
    "    df_test[col] = 0\n",
    "    \n",
    "# see performance in each group\n",
    "cols = [\"signal\", \"shift\"]\n",
    "signals = df_train.loc[df_train.batch.isin(BATCH_GROUP), cols].values#.reshape([-1, 1])\n",
    "state = df_train.loc[df_train.batch.isin(BATCH_GROUP), TARGET].values\n",
    "init_prob = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "ghmm = GaussHMM(init_prob)\n",
    "# ghmm.fit(signals, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.781219Z",
     "start_time": "2020-05-22T20:41:42.778662Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cov(signals, channels):\n",
    "\n",
    "    sig_cov = []\n",
    "    for chan_i in range(len(np.unique(channels))):\n",
    "        sig_cov.append(np.cov(signals[channels == chan_i].reshape([-1, 2]).T))\n",
    "\n",
    "    return np.array(sig_cov).reshape([-1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.790736Z",
     "start_time": "2020-05-22T20:41:42.782077Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean(signals, channels):\n",
    "\n",
    "    sig_mean = []\n",
    "    for chan_i in range(len(np.unique(channels))):\n",
    "        sig_mean.append(signals[channels == chan_i].mean())\n",
    "\n",
    "    return np.array(sig_mean).reshape([-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:42.800088Z",
     "start_time": "2020-05-22T20:41:42.791589Z"
    }
   },
   "outputs": [],
   "source": [
    "def markov_p_trans(states):\n",
    "    max_state = np.max(states)\n",
    "    states_next = np.roll(states, -1)\n",
    "    matrix = []\n",
    "    for i in range(max_state + 1):\n",
    "        current_row = np.histogram(states_next[states == i], bins=np.arange(max_state + 2))[0]\n",
    "        if np.sum(current_row) == 0: # if a state doesn't appear in states...\n",
    "            current_row = np.ones(max_state + 1) / (max_state + 1) # ...use uniform probability\n",
    "        else:\n",
    "            current_row = current_row / np.sum(current_row) # normalize to 1\n",
    "        matrix.append(current_row)\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.132193Z",
     "start_time": "2020-05-22T20:41:42.800907Z"
    }
   },
   "outputs": [],
   "source": [
    "hmm = GaussianHMM(n_components=len(init_prob), covariance_type=\"full\", n_iter=100)\n",
    "hmm.fit(np.array(signals).reshape([-1, 2])[:200])\n",
    "hmm.means_ = get_mean(signals, state)\n",
    "hmm.covars_ = get_cov(signals, state)\n",
    "hmm.startprob_ = init_prob\n",
    "hmm.transmat_ = markov_p_trans(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:42:49.119387Z",
     "start_time": "2020-05-22T20:42:47.840552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_1 F1 macro = 2.4e-05\n",
      "5_2 F1 macro = 8e-06\n",
      "5_3 F1 macro = 1e-05\n",
      "5_4 F1 macro = 5.4e-05\n",
      "5_5 F1 macro = 2.2e-05\n",
      "10_1 F1 macro = 2e-05\n",
      "10_2 F1 macro = 2.6e-05\n",
      "10_3 F1 macro = 2.8e-05\n",
      "10_4 F1 macro = 2.2e-05\n",
      "10_5 F1 macro = 4.2e-05\n",
      "==> OOF F1 macro = 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for group_i in df_train.group.unique():\n",
    "    batch_i = df_train[df_train.group.isin([group_i])]\n",
    "    signal_i = df_train.loc[df_train.group.isin([group_i]), cols].values\n",
    "    state_i = df_train.loc[df_train.group.isin([group_i]), TARGET].values\n",
    "    df_train.loc[df_train.group.isin([group_i]), \"oof\"] = hmm.predict(signal_i)\n",
    "#     df_train.loc[df_train.group.isin([group_i]), viterbi_cols] = hmm.predict_proba(signal_i)\n",
    "    print(group_i, \"F1 macro =\", f1_score(y_pred=df_train.loc[df_train.group.isin([group_i]), \"oof\"], y_true=state_i, average='macro').round(6))\n",
    "\n",
    "print(\"==> OOF F1 macro =\", f1_score(y_pred=df_train[\"oof\"].values, y_true=df_train[TARGET].values, average='macro').round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:43:11.913763Z",
     "start_time": "2020-05-22T20:43:11.910442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "999995    0.0\n",
       "999996    0.0\n",
       "999997    0.0\n",
       "999998    0.0\n",
       "999999    0.0\n",
       "Name: oof, Length: 1000000, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"oof\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.474024Z",
     "start_time": "2020-05-22T20:41:33.299Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.474586Z",
     "start_time": "2020-05-22T20:41:33.302Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_noise(batch, sig_mean, col=\"open_channels\"):\n",
    "    \"\"\"\n",
    "    input: batch df\n",
    "    output: recovered signal\n",
    "    \"\"\"\n",
    "    signal = batch.signal_original.values\n",
    "    channels = batch[col].values\n",
    "    # sig_mean = get_mean(batch, col=col)\n",
    "    sig_noise = Arrange_mean(signal, channels, sig_mean, len(sig_mean))\n",
    "\n",
    "    return sig_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.475170Z",
     "start_time": "2020-05-22T20:41:33.304Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict the test\n",
    "df_test[\"noise\"] = 0\n",
    "for col in TEST_GROUP:\n",
    "    df_test.loc[df_test.group == col, \"oof\"] = ghmm.predict(df_test.loc[df_test.group == col, \"signal\"].values)\n",
    "    df_test.loc[df_test.group == col, viterbi_cols] = ghmm.predict_proba(df_test.loc[df_test.group == col, \"signal\"].values)\n",
    "    df_test.loc[df_test.group == col, \"noise\"] = get_noise(df_test[df_test.group == col], sig_mean, col=\"oof\")\n",
    "    \n",
    "df_test[\"max_typicality\"] = df_test[viterbi_cols].values.max(axis=1)\n",
    "\n",
    "# for i in range(5):\n",
    "#     # remove test signal noise here using oof\n",
    "#     for group_i in TEST_GROUP:\n",
    "#         batch_test_i = df_test[df_test.group.isin([group_i])].copy()\n",
    "#         signal_test_recovered = rm_noise(batch_test_i, col=\"oof\", sig_mean=sig_mean)\n",
    "#         df_test.loc[df_test.group.isin([group_i]), \"signal\"] = signal_test_recovered\n",
    "\n",
    "#     # re-predict test \n",
    "#     for col in TEST_GROUP:\n",
    "#         df_test.loc[df_test.group == col, \"oof\"] = ghmm.predict(df_test.loc[df_test.group == col, \"signal\"].values)\n",
    "#         df_test.loc[df_test.group == col, viterbi_cols] = ghmm.predict_proba(df_test.loc[df_test.group == col, \"signal\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.475840Z",
     "start_time": "2020-05-22T20:41:33.306Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_cut = 0.8\n",
    "plt.plot(df_test[df_test.max_typicality > alpha_cut].noise, \".b\", alpha=0.1)\n",
    "# plt.plot(df_test[df_test.max_typicality < alpha_cut].noise, \".r\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.476266Z",
     "start_time": "2020-05-22T20:41:33.308Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.loc[df_test.max_typicality < alpha_cut, \"noise\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.476856Z",
     "start_time": "2020-05-22T20:41:33.311Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test[\"noise\"] = df_test[\"noise\"].interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.477553Z",
     "start_time": "2020-05-22T20:41:33.313Z"
    }
   },
   "outputs": [],
   "source": [
    "fs = 10000\n",
    "nperseg = 10000\n",
    "f, t, Zxx = scisig.stft(df_test.noise, fs=fs, nperseg=nperseg)\n",
    "Zxx[49:52,:] = Zxx[49:52,:] * 0.02\n",
    "plt.figure()\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), vmin=0, vmax=0.02)\n",
    "plt.ylim([f[1], f[-1]])\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.477999Z",
     "start_time": "2020-05-22T20:41:33.315Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot((df_test[\"noise\"]).values )\n",
    "plt.plot((df_test[\"noise\"]).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.478659Z",
     "start_time": "2020-05-22T20:41:33.317Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fs=10000\n",
    "fft = np.fft.fft(df_test.noise)\n",
    "psd = np.abs(fft) ** 2\n",
    "fftfreq = np.fft.fftfreq(len(psd),1/fs)\n",
    "\n",
    "i = abs(fftfreq) < 200\n",
    "plt.grid()\n",
    "plt.plot(fftfreq[i], 20*np.log10(psd[i]), linewidth=.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.479202Z",
     "start_time": "2020-05-22T20:41:33.322Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot((df_train[\"signal_original\"] - df_train[\"signal\"]).values)\n",
    "# plt.plot((df_train[\"signal_original\"] - df_train[\"signal\"]).rolling(100).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.479796Z",
     "start_time": "2020-05-22T20:41:33.324Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fs=10000\n",
    "fft = np.fft.fft((df_train[\"signal_original\"] - df_train[\"signal\"]).values)\n",
    "psd = np.abs(fft) ** 2\n",
    "fftfreq = np.fft.fftfreq(len(psd),1/fs)\n",
    "\n",
    "i = abs(fftfreq) < 200\n",
    "plt.grid()\n",
    "plt.plot(fftfreq[i], 20*np.log10(psd[i]), linewidth=.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.480380Z",
     "start_time": "2020-05-22T20:41:33.326Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot((df_test[\"signal_original\"] - df_test[\"signal\"]).values )\n",
    "plt.plot((df_test[\"signal_original\"] - df_test[\"signal\"]).rolling(100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.480990Z",
     "start_time": "2020-05-22T20:41:33.328Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "fs=10000\n",
    "fft = np.fft.fft((df_test[\"signal_original\"] - df_test[\"signal\"]).values)\n",
    "psd = np.abs(fft) ** 2\n",
    "fftfreq = np.fft.fftfreq(len(psd),1/fs)\n",
    "\n",
    "i = abs(fftfreq) < 200\n",
    "plt.grid()\n",
    "plt.plot(fftfreq[i], 20*np.log10(psd[i]), linewidth=.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.481502Z",
     "start_time": "2020-05-22T20:41:33.340Z"
    }
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.482027Z",
     "start_time": "2020-05-22T20:41:33.342Z"
    }
   },
   "outputs": [],
   "source": [
    "print(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.482595Z",
     "start_time": "2020-05-22T20:41:33.344Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale back\n",
    "df_train.loc[:,\"oof\"] = df_train.loc[:,\"oof\"] + shft\n",
    "df_test.loc[:,\"oof\"] = df_test.loc[:,\"oof\"] + shft\n",
    "df_train.loc[:,TARGET] = df_train.loc[:,TARGET] + shft\n",
    "df_test.loc[:,TARGET] = df_test.loc[:,TARGET] + shft\n",
    "\n",
    "# # save train/test oof and prediction\n",
    "# np.save('hmm_oof/train_oof_model5.npy', df_train[\"oof\"])\n",
    "# np.save('hmm_oof/test_oof_model5.npy', df_test[\"oof\"])\n",
    "# # np.save('hmm_pred/test_pred_model5.npy', df_test[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.483180Z",
     "start_time": "2020-05-22T20:41:33.346Z"
    }
   },
   "outputs": [],
   "source": [
    "shft2 = 2\n",
    "class_num = 11 - shft2\n",
    "# reduce batch 5&10 open_channels from 11 to 9 (class 2-10) for nn training\n",
    "df_train.loc[df_train.batch.isin([5,10]) & (df_train.open_channels < shft2), \"open_channels\"] = shft2\n",
    "df_train[TARGET] = df_train[TARGET] - shft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.483799Z",
     "start_time": "2020-05-22T20:41:33.348Z"
    }
   },
   "outputs": [],
   "source": [
    "# cut the signal into sequences\n",
    "SEQ_LEN = 400\n",
    "def chop_seq(df_batch_i, is_train):\n",
    "\n",
    "    df_batch_i_features = []\n",
    "    df_batch_i_y = []\n",
    "    df_batch_i_group = []\n",
    "    \n",
    "    WHOLE_LEN = 5e5 if is_train else 1e5\n",
    "    \n",
    "    for i in range(int(WHOLE_LEN/SEQ_LEN)):\n",
    "\n",
    "        # (SEQ_LEN, 5)\n",
    "        tmp = df_batch_i[(SEQ_LEN * i):(SEQ_LEN * (i + 1))]\n",
    "        df_batch_i_features.append(tmp[use_cols].values)\n",
    "        df_batch_i_y.append(tmp[TARGET].values)\n",
    "        df_batch_i_group.append(tmp[\"group\"].values)\n",
    "\n",
    "    return df_batch_i_features, df_batch_i_y, df_batch_i_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.484386Z",
     "start_time": "2020-05-22T20:41:33.350Z"
    }
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "df_train_seq = []\n",
    "df_train_y = []\n",
    "groups = []\n",
    "\n",
    "for batch_i in BATCH_GROUP:\n",
    "    df_batch_i = df_train[df_train.batch == batch_i]\n",
    "    df_batch_i_features, df_batch_i_y, df_batch_i_group = chop_seq(df_batch_i, is_train=1)\n",
    "    df_train_seq.append(df_batch_i_features)\n",
    "    df_train_y.append(df_batch_i_y)\n",
    "    groups.append(df_batch_i_group)\n",
    "\n",
    "df_train_seq = np.array(df_train_seq).reshape(\n",
    "    [-1, SEQ_LEN, np.array(df_train_seq).shape[-1]])\n",
    "df_train_y = np.array(df_train_y).reshape([-1, SEQ_LEN])\n",
    "groups = np.array(groups).reshape([-1, SEQ_LEN])[:,0]\n",
    "\n",
    "print(\"TRAIN:\", df_train_seq.shape, df_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.484968Z",
     "start_time": "2020-05-22T20:41:33.352Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "df_test_seq = []\n",
    "df_test_y = []\n",
    "df_test_groups = []\n",
    "\n",
    "mini_batch_list = [[2,1], [2,3]]\n",
    "for batch_i, mini_batch_i in mini_batch_list:\n",
    "    df_batch_i = df_test[(df_test.batch == batch_i) & (df_test.mini_batch == mini_batch_i)]\n",
    "    df_batch_i_features, df_batch_i_y, df_test_batch_i_group = chop_seq(df_batch_i, is_train=0)\n",
    "    df_test_seq.append(df_batch_i_features)\n",
    "    df_test_y.append(df_batch_i_y)\n",
    "    df_test_groups.append(df_test_batch_i_group)\n",
    "\n",
    "df_test_seq = np.array(df_test_seq).reshape(\n",
    "    [-1, SEQ_LEN, np.array(df_test_seq).shape[-1]])\n",
    "df_test_y = np.array(df_test_y).reshape([-1, SEQ_LEN])\n",
    "df_test_groups = np.array(df_test_groups).reshape([-1, SEQ_LEN])[:,0]\n",
    "\n",
    "print(\"TEST:\", df_test_seq.shape, df_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.485561Z",
     "start_time": "2020-05-22T20:41:33.354Z"
    }
   },
   "outputs": [],
   "source": [
    "def Classifier(shape_):\n",
    "    \n",
    "    def cbr(x, out_layer, kernel, stride, dilation):\n",
    "        x = Conv1D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        return x\n",
    "    \n",
    "    def wave_block(x, filters, kernel_size, n):\n",
    "        dilation_rates = [2**i for i in range(n)]\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = x\n",
    "        for dilation_rate in dilation_rates:\n",
    "            tanh_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same', \n",
    "                              activation = 'tanh', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            sigm_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same',\n",
    "                              activation = 'sigmoid', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            x = Multiply()([tanh_out, sigm_out])\n",
    "            x = Conv1D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = Add()([res_x, x])\n",
    "        return res_x\n",
    "    \n",
    "    inp = Input(shape = (shape_))\n",
    "    x = cbr(inp, 64, 5, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = wave_block(x, 64, 3, 8)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = wave_block(x, 64, 3, 4)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = wave_block(x, 128, 3, 1)\n",
    "    x = cbr(x, 32, 5, 1, 1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(class_num, activation = 'softmax', name = 'out')(x)\n",
    "    \n",
    "    model = models.Model(inputs = inp, outputs = out)\n",
    "    \n",
    "    opt = Adam(lr = LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(loss = losses.CategoricalCrossentropy(), optimizer = opt, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.486169Z",
     "start_time": "2020-05-22T20:41:33.356Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "oof_ = np.zeros([df_train_seq.shape[0], df_train_seq.shape[1], class_num])\n",
    "preds_ = np.zeros((df_test_seq.shape[0] * df_test_seq.shape[1], class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.486746Z",
     "start_time": "2020-05-22T20:41:33.358Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_y = pd.get_dummies(df_train_y.reshape([-1])).values.reshape([-1, SEQ_LEN, class_num])\n",
    "df_test_y = np.zeros([df_train_y.shape[0], df_train_y.shape[1], class_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.487268Z",
     "start_time": "2020-05-22T20:41:33.361Z"
    }
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "for index, (tr_idx, val_idx) in enumerate(gkf.split(df_train_seq, df_train_y, groups)):\n",
    "    train_x, train_y = df_train_seq[tr_idx], df_train_y[tr_idx]\n",
    "    valid_x, valid_y = df_train_seq[val_idx], df_train_y[val_idx]\n",
    "    print(\"Running folder\", index + 1, \": Evaluate on\", np.unique(groups[val_idx]))\n",
    "    print(f'Our training dataset shape is {train_x.shape}')\n",
    "    print(f'Our validation dataset shape is {valid_x.shape}')\n",
    "    \n",
    "    shape_ = (None, train_x.shape[2])\n",
    "    model = Classifier(shape_)\n",
    "    cb_lr_schedule = LearningRateScheduler(lr_schedule)\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "    checkpoint_filepath = 'best_model.h5'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    model.fit(train_x,train_y,\n",
    "              epochs = nn_epochs,\n",
    "              callbacks = [cb_lr_schedule, early_stop, model_checkpoint_callback], \n",
    "              batch_size = nn_batch_size, verbose = 0,\n",
    "              validation_data = (valid_x,valid_y))\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    preds_f = model.predict(valid_x)\n",
    "    f1_score_ = f1_score(np.argmax(valid_y, axis=2).reshape(-1),  np.argmax(preds_f, axis=2).reshape(-1), average = 'macro') \n",
    "    print(f'Training fold {index + 1} completed. macro f1 score : {f1_score_ :1.5f}')\n",
    "    oof_[val_idx] += preds_f\n",
    "    te_preds = model.predict(df_test_seq)\n",
    "    te_preds = te_preds.reshape(-1, te_preds.shape[-1])           \n",
    "    preds_ += te_preds / gkf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.487855Z",
     "start_time": "2020-05-22T20:41:33.362Z"
    }
   },
   "outputs": [],
   "source": [
    "# 0.88612 (class2-10)\n",
    "print(\"NN oof F1 score is\", f1_score(df_train_y.reshape([-1,class_num]).argmax(axis=1), oof_.reshape([-1,class_num]).argmax(axis=1), average = 'macro').round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.488513Z",
     "start_time": "2020-05-22T20:41:33.364Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_pred = oof_.reshape([-1,class_num]).argmax(axis=1) + shft2\n",
    "df_train[\"nn_oof\"] = oof_pred\n",
    "df_train.loc[:,TARGET] = df_train.loc[:,TARGET] + shft2\n",
    "\n",
    "test_pred = preds_.argmax(axis=1) + shft2\n",
    "df_test.loc[df_test.group.isin(TEST_GROUP), TARGET] = test_pred\n",
    "df_test.loc[df_test.oof == 1, TARGET] = 1 # fix class 1 problem\n",
    "print(f\"oof shape is {oof_pred.shape}, test pred shape is {test_pred.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.489082Z",
     "start_time": "2020-05-22T20:41:33.366Z"
    }
   },
   "outputs": [],
   "source": [
    "# # save oof and prediction\n",
    "# np.save('hmm_oof/train_nn_oof_model5.npy', oof_pred)\n",
    "# np.save('hmm_pred/test_nn_oof_model5.npy', df_test[TARGET].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.489568Z",
     "start_time": "2020-05-22T20:41:33.369Z"
    }
   },
   "outputs": [],
   "source": [
    "# train target plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "for channel_i in range(11):\n",
    "    plt.plot(df_train[df_train.open_channels == channel_i].signal_original,\n",
    "             \".\",\n",
    "             color=color_list[channel_i],\n",
    "             alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.490071Z",
     "start_time": "2020-05-22T20:41:33.370Z"
    }
   },
   "outputs": [],
   "source": [
    "# train oof plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "for channel_i in range(11):\n",
    "    plt.plot(df_train[df_train.nn_oof == channel_i].signal_original,\n",
    "             \".\",\n",
    "             color=color_list[channel_i],\n",
    "             alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.490603Z",
     "start_time": "2020-05-22T20:41:33.372Z"
    }
   },
   "outputs": [],
   "source": [
    "# test oof plot - hmm prediction\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "for channel_i in range(11):\n",
    "    plt.plot(df_test[(df_test.oof == channel_i)  & (df_test.group.isin(TEST_GROUP))].signal_original,\n",
    "             \".\",\n",
    "             color=color_list[channel_i],\n",
    "             alpha=0.5)\n",
    "# plt.xlim([0,50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T20:41:43.491327Z",
     "start_time": "2020-05-22T20:41:33.375Z"
    }
   },
   "outputs": [],
   "source": [
    "# test predict plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "for channel_i in range(11):\n",
    "    plt.plot(df_test[(df_test.open_channels == channel_i)  & (df_test.group.isin(TEST_GROUP))].signal_original,\n",
    "             \".\",\n",
    "             color=color_list[channel_i],\n",
    "             alpha=0.5)\n",
    "# plt.xlim([0,50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
