{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:01.717650Z",
     "start_time": "2020-04-12T05:12:01.129083Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, time\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_toolbelt import losses as L\n",
    "from nn_utils import *\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:01.933060Z",
     "start_time": "2020-04-12T05:12:01.718663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500000, 6) (2000000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>local_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>mini_batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  local_time  batch  mini_batch\n",
       "0  0.0001 -2.7600              0      0.0001    1.0         1.0\n",
       "1  0.0002 -2.8557              0      0.0002    1.0         1.0\n",
       "2  0.0003 -2.4074              0      0.0003    1.0         1.0\n",
       "3  0.0004 -3.1404              0      0.0004    1.0         1.0\n",
       "4  0.0005 -3.1525              0      0.0005    1.0         1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw = pd.read_pickle('../features/train_clean.pkl')\n",
    "df_test_raw = pd.read_pickle('../features/test_clean.pkl')\n",
    "TARGET = \"open_channels\"\n",
    "df_test_raw[TARGET] = 0\n",
    "\n",
    "print(df_train_raw.shape, df_test_raw.shape)\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:01.949389Z",
     "start_time": "2020-04-12T05:12:01.934070Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_raw[\"signal_pow_2\"] = df_train_raw[\"signal\"] ** 2\n",
    "df_test_raw[\"signal_pow_2\"] = df_test_raw[\"signal\"] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:01.952775Z",
     "start_time": "2020-04-12T05:12:01.950434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signal', 'signal_pow_2']\n"
     ]
    }
   ],
   "source": [
    "use_cols = [\n",
    "    col for col in df_train_raw.columns if col not in\n",
    "    [\"time\", \"local_time\", \"open_channels\", \"batch\", \"mini_batch\"]\n",
    "]\n",
    "print(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:01.962002Z",
     "start_time": "2020-04-12T05:12:01.953641Z"
    }
   },
   "outputs": [],
   "source": [
    "def chop_seq(df_batch_i):\n",
    "\n",
    "    df_batch_i_features = []\n",
    "    df_batch_i_y = []\n",
    "\n",
    "    for i in range(200):\n",
    "\n",
    "        # (2500, 5)\n",
    "        tmp = df_batch_i[(2500 * i):(2500 * (i + 1))]\n",
    "        df_batch_i_features.append(tmp[use_cols].values)\n",
    "        df_batch_i_y.append(tmp[TARGET].values)\n",
    "\n",
    "    return df_batch_i_features, df_batch_i_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.227614Z",
     "start_time": "2020-04-12T05:12:01.962866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: (1800, 2, 2500) (1800, 2500)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "df_train = []\n",
    "df_train_y = []\n",
    "\n",
    "for batch_i in [1, 2, 3, 4, 5, 6, 7, 9, 10]:\n",
    "    df_batch_i = df_train_raw[df_train_raw.batch == batch_i]\n",
    "    df_batch_i_features, df_batch_i_y = chop_seq(df_batch_i)\n",
    "    df_train.append(df_batch_i_features)\n",
    "    df_train_y.append(df_batch_i_y)\n",
    "\n",
    "df_train = np.array(df_train).reshape([-1, 2500, np.array(df_train).shape[-1]]).transpose([0, 2, 1])\n",
    "df_train_y = np.array(df_train_y).reshape([-1, 2500])\n",
    "\n",
    "print(\"TRAIN:\", df_train.shape, df_train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.783324Z",
     "start_time": "2020-04-12T05:12:03.228544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: (800, 2, 2500) (800, 2500)\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "df_test = []\n",
    "df_test_y = []\n",
    "\n",
    "for batch_i in [1, 2, 3, 4]:\n",
    "    df_batch_i = df_test_raw[df_test_raw.batch == batch_i]\n",
    "    df_batch_i_features, df_batch_i_y = chop_seq(df_batch_i)\n",
    "    df_test.append(df_batch_i_features)\n",
    "    df_test_y.append(df_batch_i_y)\n",
    "\n",
    "df_test = np.array(df_test).reshape([-1, 2500, np.array(df_test).shape[-1]]).transpose([0, 2, 1])\n",
    "df_test_y = np.array(df_test_y).reshape([-1, 2500])\n",
    "\n",
    "print(\"TEST:\", df_test.shape, df_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.786598Z",
     "start_time": "2020-04-12T05:12:03.784673Z"
    }
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "group = list(range(df_train.shape[0]))\n",
    "skf = GroupKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.799605Z",
     "start_time": "2020-04-12T05:12:03.787560Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRnn(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, output_size, num_layers=1, bidirectional=False, dropout=.3,\n",
    "            hidden_layers = [100, 200]):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.bidirectional=bidirectional\n",
    "        self.output_size=output_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, batch_first=True,dropout=0.3)\n",
    "         # Input Layer\n",
    "        if hidden_layers and len(hidden_layers):\n",
    "            first_layer  = nn.Linear(hidden_size*2 if bidirectional else hidden_size, hidden_layers[0])\n",
    "\n",
    "            # Hidden Layers\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [first_layer]+[nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers) - 1)]\n",
    "            )\n",
    "            for layer in self.hidden_layers: nn.init.kaiming_normal_(layer.weight.data)   \n",
    "\n",
    "            self.intermediate_layer = nn.Linear(hidden_layers[-1], self.input_size)\n",
    "            # output layers\n",
    "            self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "           \n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "            self.intermediate_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_siz, self.input_size)\n",
    "            self.output_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_size, output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "\n",
    "        self.activation_fn = torch.relu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        outputs, hidden = self.rnn(x)        \n",
    "\n",
    "        x = self.dropout(self.activation_fn(outputs))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fn(hidden_layer(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.841097Z",
     "start_time": "2020-04-12T05:12:03.800494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 2, 2500]) torch.Size([800, 2, 2500])\n"
     ]
    }
   ],
   "source": [
    "df_train = torch.Tensor(df_train)\n",
    "df_test = torch.Tensor(df_test)\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:12:03.844265Z",
     "start_time": "2020-04-12T05:12:03.841957Z"
    }
   },
   "outputs": [],
   "source": [
    "val_preds_all = np.zeros((df_train_raw.shape[0], 11))\n",
    "test_preds_all = np.zeros((df_test_raw.shape[0], 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T05:56:16.129879Z",
     "start_time": "2020-04-12T05:12:03.845444Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "TRAIN: (1200,) TEST: (600,)\n",
      "Epoch : 0\n",
      "learning_rate: 0.000010000\n",
      "train_loss: 2.348066, valid_loss: 1.647776\n",
      "train_f1: 0.079300, valid_f1: 0.088224\n",
      "--- 8.420817136764526 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000020962\n",
      "train_loss: 2.138751, valid_loss: 1.464072\n",
      "train_f1: 0.080650, valid_f1: 0.083408\n",
      "--- 8.05654239654541 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000053363\n",
      "train_loss: 1.830200, valid_loss: 1.268299\n",
      "train_f1: 0.082924, valid_f1: 0.083895\n",
      "--- 8.63381838798523 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000105767\n",
      "train_loss: 1.537680, valid_loss: 1.097071\n",
      "train_f1: 0.089340, valid_f1: 0.107533\n",
      "--- 9.029078722000122 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000175854\n",
      "train_loss: 1.315390, valid_loss: 0.896831\n",
      "train_f1: 0.101633, valid_f1: 0.185827\n",
      "--- 8.251904010772705 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000260519\n",
      "train_loss: 1.129189, valid_loss: 0.755838\n",
      "train_f1: 0.120186, valid_f1: 0.211913\n",
      "--- 8.396852731704712 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000356012\n",
      "train_loss: 0.984500, valid_loss: 0.668981\n",
      "train_f1: 0.143563, valid_f1: 0.193072\n",
      "--- 8.48237919807434 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000458105\n",
      "train_loss: 0.871133, valid_loss: 0.598607\n",
      "train_f1: 0.177040, valid_f1: 0.224542\n",
      "--- 8.665557622909546 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000562274\n",
      "train_loss: 0.762671, valid_loss: 0.509675\n",
      "train_f1: 0.225971, valid_f1: 0.403272\n",
      "--- 8.56634521484375 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000663907\n",
      "train_loss: 0.657956, valid_loss: 0.409980\n",
      "train_f1: 0.292252, valid_f1: 0.448149\n",
      "--- 8.073363065719604 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000758501\n",
      "train_loss: 0.550510, valid_loss: 0.332934\n",
      "train_f1: 0.358179, valid_f1: 0.480411\n",
      "--- 7.974561929702759 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000841868\n",
      "train_loss: 0.456166, valid_loss: 0.275212\n",
      "train_f1: 0.422220, valid_f1: 0.520172\n",
      "--- 7.964698314666748 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000910314\n",
      "train_loss: 0.385773, valid_loss: 0.231001\n",
      "train_f1: 0.483062, valid_f1: 0.574399\n",
      "--- 7.972308874130249 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000960808\n",
      "train_loss: 0.332600, valid_loss: 0.196353\n",
      "train_f1: 0.538802, valid_f1: 0.735233\n",
      "--- 7.9274420738220215 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000991114\n",
      "train_loss: 0.290826, valid_loss: 0.169194\n",
      "train_f1: 0.585286, valid_f1: 0.775167\n",
      "--- 7.936993598937988 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.000999999\n",
      "train_loss: 0.260764, valid_loss: 0.145423\n",
      "train_f1: 0.624496, valid_f1: 0.805372\n",
      "--- 7.947880029678345 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999836\n",
      "train_loss: 0.235471, valid_loss: 0.125991\n",
      "train_f1: 0.657867, valid_f1: 0.829490\n",
      "--- 7.93292498588562 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999403\n",
      "train_loss: 0.210798, valid_loss: 0.110722\n",
      "train_f1: 0.688869, valid_f1: 0.840583\n",
      "--- 7.954138994216919 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998700\n",
      "train_loss: 0.186185, valid_loss: 0.100461\n",
      "train_f1: 0.715042, valid_f1: 0.841791\n",
      "--- 7.943441152572632 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997726\n",
      "train_loss: 0.173280, valid_loss: 0.091700\n",
      "train_f1: 0.735973, valid_f1: 0.845747\n",
      "--- 7.888502836227417 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996483\n",
      "train_loss: 0.160052, valid_loss: 0.087001\n",
      "train_f1: 0.753246, valid_f1: 0.845280\n",
      "--- 7.921745777130127 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000994971\n",
      "train_loss: 0.150026, valid_loss: 0.082620\n",
      "train_f1: 0.766481, valid_f1: 0.846895\n",
      "--- 7.9885101318359375 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993191\n",
      "train_loss: 0.144049, valid_loss: 0.079704\n",
      "train_f1: 0.778049, valid_f1: 0.847864\n",
      "--- 7.97266411781311 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991144\n",
      "train_loss: 0.136498, valid_loss: 0.078065\n",
      "train_f1: 0.787033, valid_f1: 0.846348\n",
      "--- 7.93065071105957 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000988831\n",
      "train_loss: 0.129491, valid_loss: 0.075544\n",
      "train_f1: 0.794725, valid_f1: 0.847605\n",
      "--- 7.917567491531372 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986253\n",
      "train_loss: 0.125584, valid_loss: 0.072989\n",
      "train_f1: 0.800894, valid_f1: 0.848544\n",
      "--- 7.977452516555786 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983412\n",
      "train_loss: 0.121058, valid_loss: 0.072077\n",
      "train_f1: 0.806457, valid_f1: 0.848494\n",
      "--- 7.9726479053497314 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980309\n",
      "train_loss: 0.117331, valid_loss: 0.070715\n",
      "train_f1: 0.811312, valid_f1: 0.848497\n",
      "--- 7.977664947509766 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000976946\n",
      "train_loss: 0.114994, valid_loss: 0.069656\n",
      "train_f1: 0.815385, valid_f1: 0.848922\n",
      "--- 7.912817001342773 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973325\n",
      "train_loss: 0.112984, valid_loss: 0.069520\n",
      "train_f1: 0.819125, valid_f1: 0.848377\n",
      "--- 7.924010515213013 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969447\n",
      "train_loss: 0.112358, valid_loss: 0.068462\n",
      "train_f1: 0.821714, valid_f1: 0.849088\n",
      "--- 7.933623552322388 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965315\n",
      "train_loss: 0.108050, valid_loss: 0.067802\n",
      "train_f1: 0.824914, valid_f1: 0.849216\n",
      "--- 7.956818103790283 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000960932\n",
      "train_loss: 0.104189, valid_loss: 0.067560\n",
      "train_f1: 0.827433, valid_f1: 0.848892\n",
      "--- 8.088316202163696 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956298\n",
      "train_loss: 0.104185, valid_loss: 0.067343\n",
      "train_f1: 0.829871, valid_f1: 0.849014\n",
      "--- 8.261712312698364 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951418\n",
      "train_loss: 0.102348, valid_loss: 0.067054\n",
      "train_f1: 0.831667, valid_f1: 0.849399\n",
      "--- 7.9401843547821045 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946293\n",
      "train_loss: 0.101598, valid_loss: 0.066633\n",
      "train_f1: 0.833796, valid_f1: 0.849320\n",
      "--- 7.946991205215454 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000940926\n",
      "train_loss: 0.101076, valid_loss: 0.066344\n",
      "train_f1: 0.835477, valid_f1: 0.849210\n",
      "--- 7.918820142745972 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935321\n",
      "train_loss: 0.099801, valid_loss: 0.065796\n",
      "train_f1: 0.837212, valid_f1: 0.849358\n",
      "--- 7.9376914501190186 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929480\n",
      "train_loss: 0.096256, valid_loss: 0.065434\n",
      "train_f1: 0.840165, valid_f1: 0.849643\n",
      "--- 7.961496353149414 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923406\n",
      "train_loss: 0.095227, valid_loss: 0.065370\n",
      "train_f1: 0.841805, valid_f1: 0.849516\n",
      "--- 7.8968281745910645 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917103\n",
      "train_loss: 0.093661, valid_loss: 0.064874\n",
      "train_f1: 0.844496, valid_f1: 0.849383\n",
      "--- 7.976378917694092 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000910575\n",
      "train_loss: 0.094138, valid_loss: 0.064557\n",
      "train_f1: 0.846224, valid_f1: 0.849332\n",
      "--- 7.949121952056885 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000903824\n",
      "train_loss: 0.093304, valid_loss: 0.063849\n",
      "train_f1: 0.849023, valid_f1: 0.849516\n",
      "--- 7.949412107467651 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000896854\n",
      "train_loss: 0.092316, valid_loss: 0.063312\n",
      "train_f1: 0.853287, valid_f1: 0.849641\n",
      "--- 7.928762435913086 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000889669\n",
      "train_loss: 0.090655, valid_loss: 0.062493\n",
      "train_f1: 0.856321, valid_f1: 0.849452\n",
      "--- 8.118004083633423 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882273\n",
      "train_loss: 0.091357, valid_loss: 0.062126\n",
      "train_f1: 0.859237, valid_f1: 0.849392\n",
      "--- 8.408937215805054 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000874671\n",
      "train_loss: 0.088888, valid_loss: 0.061654\n",
      "train_f1: 0.863904, valid_f1: 0.857719\n",
      "--- 7.9675612449646 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000866865\n",
      "train_loss: 0.089427, valid_loss: 0.061093\n",
      "train_f1: 0.867738, valid_f1: 0.893722\n",
      "--- 7.922845363616943 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000858861\n",
      "train_loss: 0.088014, valid_loss: 0.060909\n",
      "train_f1: 0.870652, valid_f1: 0.913677\n",
      "--- 7.900396108627319 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000850662\n",
      "train_loss: 0.088113, valid_loss: 0.060031\n",
      "train_f1: 0.874326, valid_f1: 0.921625\n",
      "--- 7.9048097133636475 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842274\n",
      "train_loss: 0.085532, valid_loss: 0.060070\n",
      "train_f1: 0.877667, valid_f1: 0.929457\n",
      "--- 7.940688610076904 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000833700\n",
      "train_loss: 0.084554, valid_loss: 0.059613\n",
      "train_f1: 0.880450, valid_f1: 0.932161\n",
      "--- 7.943689346313477 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000824945\n",
      "train_loss: 0.084557, valid_loss: 0.059076\n",
      "train_f1: 0.884498, valid_f1: 0.931966\n",
      "--- 7.9505980014801025 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.083771, valid_loss: 0.058769\n",
      "train_f1: 0.887007, valid_f1: 0.935496\n",
      "--- 7.917997121810913 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000806913\n",
      "train_loss: 0.082773, valid_loss: 0.058649\n",
      "train_f1: 0.889142, valid_f1: 0.934656\n",
      "--- 7.913301467895508 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000797645\n",
      "train_loss: 0.082462, valid_loss: 0.057966\n",
      "train_f1: 0.892104, valid_f1: 0.936421\n",
      "--- 7.957485914230347 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000788216\n",
      "train_loss: 0.082270, valid_loss: 0.057880\n",
      "train_f1: 0.893846, valid_f1: 0.935901\n",
      "--- 7.915422677993774 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000778631\n",
      "train_loss: 0.081519, valid_loss: 0.057414\n",
      "train_f1: 0.895648, valid_f1: 0.937288\n",
      "--- 7.9619176387786865 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000768895\n",
      "train_loss: 0.082085, valid_loss: 0.057229\n",
      "train_f1: 0.897612, valid_f1: 0.937634\n",
      "--- 7.923636198043823 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759014\n",
      "train_loss: 0.080718, valid_loss: 0.057302\n",
      "train_f1: 0.898577, valid_f1: 0.936493\n",
      "--- 7.913801431655884 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000748992\n",
      "train_loss: 0.081433, valid_loss: 0.056604\n",
      "train_f1: 0.900279, valid_f1: 0.937802\n",
      "--- 7.916230201721191 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000738835\n",
      "train_loss: 0.080042, valid_loss: 0.056725\n",
      "train_f1: 0.901681, valid_f1: 0.937860\n",
      "--- 7.9448628425598145 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000728549\n",
      "train_loss: 0.079253, valid_loss: 0.056335\n",
      "train_f1: 0.903205, valid_f1: 0.938005\n",
      "--- 7.942831516265869 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000718139\n",
      "train_loss: 0.079053, valid_loss: 0.056460\n",
      "train_f1: 0.904426, valid_f1: 0.937732\n",
      "--- 7.910685777664185 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000707612\n",
      "train_loss: 0.078059, valid_loss: 0.056356\n",
      "train_f1: 0.905759, valid_f1: 0.937769\n",
      "--- 7.902737617492676 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000696971\n",
      "train_loss: 0.079333, valid_loss: 0.056311\n",
      "train_f1: 0.905454, valid_f1: 0.936843\n",
      "--- 7.913568019866943 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000686224\n",
      "train_loss: 0.077721, valid_loss: 0.056272\n",
      "train_f1: 0.907199, valid_f1: 0.937781\n",
      "--- 7.982867002487183 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000675376\n",
      "train_loss: 0.077337, valid_loss: 0.055543\n",
      "train_f1: 0.908396, valid_f1: 0.938212\n",
      "--- 7.937469720840454 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000664434\n",
      "train_loss: 0.078403, valid_loss: 0.055693\n",
      "train_f1: 0.909061, valid_f1: 0.938095\n",
      "--- 7.911459445953369 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000653402\n",
      "train_loss: 0.075516, valid_loss: 0.055664\n",
      "train_f1: 0.909538, valid_f1: 0.937799\n",
      "--- 7.914736032485962 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000642287\n",
      "train_loss: 0.076656, valid_loss: 0.055332\n",
      "train_f1: 0.910280, valid_f1: 0.938493\n",
      "--- 8.036159038543701 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000631095\n",
      "train_loss: 0.077276, valid_loss: 0.055311\n",
      "train_f1: 0.910747, valid_f1: 0.938450\n",
      "--- 7.934678554534912 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000619832\n",
      "train_loss: 0.076918, valid_loss: 0.055289\n",
      "train_f1: 0.911598, valid_f1: 0.938268\n",
      "--- 8.892920017242432 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000608504\n",
      "train_loss: 0.075667, valid_loss: 0.055187\n",
      "train_f1: 0.911835, valid_f1: 0.938317\n",
      "--- 8.988618850708008 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000597118\n",
      "train_loss: 0.074136, valid_loss: 0.055200\n",
      "train_f1: 0.912466, valid_f1: 0.938064\n",
      "--- 8.866872310638428 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000585678\n",
      "train_loss: 0.073486, valid_loss: 0.055112\n",
      "train_f1: 0.913446, valid_f1: 0.938190\n",
      "--- 8.543431520462036 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000574193\n",
      "train_loss: 0.074469, valid_loss: 0.055029\n",
      "train_f1: 0.913575, valid_f1: 0.937679\n",
      "--- 8.06221890449524 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000562667\n",
      "train_loss: 0.074340, valid_loss: 0.054808\n",
      "train_f1: 0.913970, valid_f1: 0.937916\n",
      "--- 7.960294246673584 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000551107\n",
      "train_loss: 0.073207, valid_loss: 0.054902\n",
      "train_f1: 0.914197, valid_f1: 0.937698\n",
      "--- 7.928725719451904 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000539520\n",
      "train_loss: 0.072116, valid_loss: 0.054671\n",
      "train_f1: 0.914400, valid_f1: 0.938103\n",
      "--- 7.909796953201294 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000527911\n",
      "train_loss: 0.073368, valid_loss: 0.054630\n",
      "train_f1: 0.915010, valid_f1: 0.938086\n",
      "--- 7.9273436069488525 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000516287\n",
      "train_loss: 0.071591, valid_loss: 0.054616\n",
      "train_f1: 0.915250, valid_f1: 0.938443\n",
      "--- 7.940070867538452 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000504655\n",
      "train_loss: 0.072924, valid_loss: 0.054459\n",
      "train_f1: 0.916051, valid_f1: 0.938512\n",
      "--- 7.9589197635650635 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493019\n",
      "train_loss: 0.074075, valid_loss: 0.054446\n",
      "train_f1: 0.915969, valid_f1: 0.938242\n",
      "--- 7.917543649673462 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000481388\n",
      "train_loss: 0.072294, valid_loss: 0.054482\n",
      "train_f1: 0.916212, valid_f1: 0.937639\n",
      "--- 7.930954933166504 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000469767\n",
      "train_loss: 0.072911, valid_loss: 0.054421\n",
      "train_f1: 0.916089, valid_f1: 0.938071\n",
      "--- 7.920077323913574 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000458162\n",
      "train_loss: 0.073238, valid_loss: 0.054399\n",
      "train_f1: 0.917082, valid_f1: 0.938196\n",
      "--- 7.942886590957642 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000446579\n",
      "train_loss: 0.073038, valid_loss: 0.054206\n",
      "train_f1: 0.916992, valid_f1: 0.938671\n",
      "--- 7.928731441497803 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435026\n",
      "train_loss: 0.072741, valid_loss: 0.054140\n",
      "train_f1: 0.917132, valid_f1: 0.938252\n",
      "--- 7.956475257873535 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000423508\n",
      "train_loss: 0.071367, valid_loss: 0.054166\n",
      "train_f1: 0.917682, valid_f1: 0.938335\n",
      "--- 7.903772592544556 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412031\n",
      "train_loss: 0.072056, valid_loss: 0.054126\n",
      "train_f1: 0.917546, valid_f1: 0.937909\n",
      "--- 7.916820287704468 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000400602\n",
      "train_loss: 0.071934, valid_loss: 0.054193\n",
      "train_f1: 0.917800, valid_f1: 0.938668\n",
      "--- 7.909548282623291 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000389226\n",
      "train_loss: 0.071635, valid_loss: 0.053972\n",
      "train_f1: 0.917989, valid_f1: 0.938527\n",
      "--- 7.94668984413147 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000377911\n",
      "train_loss: 0.070002, valid_loss: 0.054028\n",
      "train_f1: 0.918586, valid_f1: 0.938200\n",
      "--- 7.939711809158325 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000366662\n",
      "train_loss: 0.070760, valid_loss: 0.053965\n",
      "train_f1: 0.918480, valid_f1: 0.938595\n",
      "--- 7.889165163040161 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000355485\n",
      "train_loss: 0.071476, valid_loss: 0.054009\n",
      "train_f1: 0.918518, valid_f1: 0.937952\n",
      "--- 7.926228761672974 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000344386\n",
      "train_loss: 0.071699, valid_loss: 0.054244\n",
      "train_f1: 0.918835, valid_f1: 0.937007\n",
      "--- 7.950349569320679 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000333371\n",
      "train_loss: 0.071325, valid_loss: 0.053822\n",
      "train_f1: 0.918618, valid_f1: 0.937980\n",
      "--- 7.959885358810425 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000322447\n",
      "train_loss: 0.070593, valid_loss: 0.053782\n",
      "train_f1: 0.918315, valid_f1: 0.938625\n",
      "--- 7.903154134750366 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000311619\n",
      "train_loss: 0.071991, valid_loss: 0.053908\n",
      "train_f1: 0.919140, valid_f1: 0.938568\n",
      "--- 7.916370868682861 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000300893\n",
      "train_loss: 0.071564, valid_loss: 0.053781\n",
      "train_f1: 0.919273, valid_f1: 0.938467\n",
      "--- 7.959091663360596 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000290275\n",
      "train_loss: 0.070806, valid_loss: 0.053655\n",
      "train_f1: 0.918718, valid_f1: 0.938557\n",
      "--- 7.934929847717285 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000279770\n",
      "train_loss: 0.068804, valid_loss: 0.053785\n",
      "train_f1: 0.919859, valid_f1: 0.937713\n",
      "--- 8.22765588760376 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000269384\n",
      "train_loss: 0.070339, valid_loss: 0.053772\n",
      "train_f1: 0.919221, valid_f1: 0.937638\n",
      "--- 7.924512147903442 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259124\n",
      "train_loss: 0.070691, valid_loss: 0.053742\n",
      "train_f1: 0.918994, valid_f1: 0.938343\n",
      "--- 7.891880512237549 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000248994\n",
      "train_loss: 0.070422, valid_loss: 0.053651\n",
      "train_f1: 0.919606, valid_f1: 0.938178\n",
      "--- 7.956728935241699 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239000\n",
      "train_loss: 0.070299, valid_loss: 0.053646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.919171, valid_f1: 0.938395\n",
      "--- 7.916727542877197 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229147\n",
      "train_loss: 0.070545, valid_loss: 0.053603\n",
      "train_f1: 0.919946, valid_f1: 0.938469\n",
      "Early Stopping...\n",
      "Best Val Score: 0.938671\n",
      "Fold : 1\n",
      "TRAIN: (1200,) TEST: (600,)\n",
      "Epoch : 0\n",
      "learning_rate: 0.000010000\n",
      "train_loss: 2.486644, valid_loss: 1.832772\n",
      "train_f1: 0.059246, valid_f1: 0.028780\n",
      "--- 8.136149406433105 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000020962\n",
      "train_loss: 2.292979, valid_loss: 1.691832\n",
      "train_f1: 0.061995, valid_f1: 0.050412\n",
      "--- 8.67445421218872 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000053363\n",
      "train_loss: 1.982825, valid_loss: 1.549912\n",
      "train_f1: 0.067221, valid_f1: 0.038794\n",
      "--- 8.141481399536133 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000105767\n",
      "train_loss: 1.696141, valid_loss: 1.344538\n",
      "train_f1: 0.073735, valid_f1: 0.054497\n",
      "--- 8.742886781692505 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000175854\n",
      "train_loss: 1.453696, valid_loss: 1.047070\n",
      "train_f1: 0.081109, valid_f1: 0.024506\n",
      "--- 8.712971448898315 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000260519\n",
      "train_loss: 1.234732, valid_loss: 0.834826\n",
      "train_f1: 0.098530, valid_f1: 0.138400\n",
      "--- 8.029138803482056 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000356012\n",
      "train_loss: 1.033610, valid_loss: 0.698840\n",
      "train_f1: 0.129827, valid_f1: 0.149323\n",
      "--- 8.000167608261108 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000458105\n",
      "train_loss: 0.889989, valid_loss: 0.601866\n",
      "train_f1: 0.169939, valid_f1: 0.320400\n",
      "--- 8.6870698928833 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000562274\n",
      "train_loss: 0.765101, valid_loss: 0.499163\n",
      "train_f1: 0.223248, valid_f1: 0.337757\n",
      "--- 8.445668458938599 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000663907\n",
      "train_loss: 0.652470, valid_loss: 0.398375\n",
      "train_f1: 0.293475, valid_f1: 0.368849\n",
      "--- 8.547898530960083 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000758501\n",
      "train_loss: 0.543071, valid_loss: 0.336688\n",
      "train_f1: 0.361304, valid_f1: 0.455581\n",
      "--- 8.359973669052124 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000841868\n",
      "train_loss: 0.459833, valid_loss: 0.288267\n",
      "train_f1: 0.418223, valid_f1: 0.526513\n",
      "--- 8.398857593536377 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000910314\n",
      "train_loss: 0.394354, valid_loss: 0.244232\n",
      "train_f1: 0.469800, valid_f1: 0.616456\n",
      "--- 7.947406053543091 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000960808\n",
      "train_loss: 0.351073, valid_loss: 0.202652\n",
      "train_f1: 0.520881, valid_f1: 0.674157\n",
      "--- 8.332145690917969 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000991114\n",
      "train_loss: 0.304437, valid_loss: 0.165856\n",
      "train_f1: 0.570510, valid_f1: 0.750314\n",
      "--- 8.075852394104004 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.000999999\n",
      "train_loss: 0.262390, valid_loss: 0.140131\n",
      "train_f1: 0.613244, valid_f1: 0.790533\n",
      "--- 8.097872495651245 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999836\n",
      "train_loss: 0.233189, valid_loss: 0.123280\n",
      "train_f1: 0.647040, valid_f1: 0.801826\n",
      "--- 7.96384859085083 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999403\n",
      "train_loss: 0.210974, valid_loss: 0.113346\n",
      "train_f1: 0.672834, valid_f1: 0.815965\n",
      "--- 8.410183668136597 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998700\n",
      "train_loss: 0.191053, valid_loss: 0.105520\n",
      "train_f1: 0.692959, valid_f1: 0.825199\n",
      "--- 8.232837677001953 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997726\n",
      "train_loss: 0.179801, valid_loss: 0.101629\n",
      "train_f1: 0.709071, valid_f1: 0.828996\n",
      "--- 7.982243299484253 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996483\n",
      "train_loss: 0.168737, valid_loss: 0.096480\n",
      "train_f1: 0.723925, valid_f1: 0.831294\n",
      "--- 8.157044649124146 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000994971\n",
      "train_loss: 0.159758, valid_loss: 0.092014\n",
      "train_f1: 0.738193, valid_f1: 0.838778\n",
      "--- 8.783483028411865 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993191\n",
      "train_loss: 0.151051, valid_loss: 0.086739\n",
      "train_f1: 0.751310, valid_f1: 0.844480\n",
      "--- 8.022831678390503 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991144\n",
      "train_loss: 0.145825, valid_loss: 0.082876\n",
      "train_f1: 0.762744, valid_f1: 0.846096\n",
      "--- 7.947640419006348 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000988831\n",
      "train_loss: 0.139730, valid_loss: 0.079754\n",
      "train_f1: 0.773897, valid_f1: 0.846067\n",
      "--- 8.503342628479004 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986253\n",
      "train_loss: 0.136621, valid_loss: 0.077291\n",
      "train_f1: 0.783638, valid_f1: 0.846994\n",
      "--- 8.083459854125977 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983412\n",
      "train_loss: 0.129704, valid_loss: 0.074719\n",
      "train_f1: 0.792742, valid_f1: 0.847346\n",
      "--- 8.027629613876343 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980309\n",
      "train_loss: 0.124612, valid_loss: 0.072604\n",
      "train_f1: 0.799941, valid_f1: 0.848550\n",
      "--- 8.113097429275513 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000976946\n",
      "train_loss: 0.124866, valid_loss: 0.072106\n",
      "train_f1: 0.805219, valid_f1: 0.848117\n",
      "--- 8.292352676391602 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973325\n",
      "train_loss: 0.118151, valid_loss: 0.070960\n",
      "train_f1: 0.810664, valid_f1: 0.847671\n",
      "--- 7.9554362297058105 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969447\n",
      "train_loss: 0.116595, valid_loss: 0.070474\n",
      "train_f1: 0.814748, valid_f1: 0.846824\n",
      "--- 7.928643465042114 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965315\n",
      "train_loss: 0.113681, valid_loss: 0.069946\n",
      "train_f1: 0.818291, valid_f1: 0.848788\n",
      "--- 8.495235681533813 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000960932\n",
      "train_loss: 0.111838, valid_loss: 0.069149\n",
      "train_f1: 0.821634, valid_f1: 0.849335\n",
      "--- 8.259935855865479 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956298\n",
      "train_loss: 0.109562, valid_loss: 0.068915\n",
      "train_f1: 0.825007, valid_f1: 0.849043\n",
      "--- 7.944802761077881 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951418\n",
      "train_loss: 0.106005, valid_loss: 0.068555\n",
      "train_f1: 0.827619, valid_f1: 0.849406\n",
      "--- 8.258116483688354 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946293\n",
      "train_loss: 0.103412, valid_loss: 0.068311\n",
      "train_f1: 0.829136, valid_f1: 0.848816\n",
      "--- 8.111303567886353 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000940926\n",
      "train_loss: 0.102932, valid_loss: 0.067788\n",
      "train_f1: 0.830326, valid_f1: 0.849537\n",
      "--- 8.269439935684204 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935321\n",
      "train_loss: 0.101679, valid_loss: 0.067703\n",
      "train_f1: 0.832384, valid_f1: 0.849226\n",
      "--- 8.117582559585571 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929480\n",
      "train_loss: 0.100653, valid_loss: 0.067627\n",
      "train_f1: 0.833932, valid_f1: 0.849097\n",
      "--- 8.29470944404602 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923406\n",
      "train_loss: 0.099534, valid_loss: 0.067580\n",
      "train_f1: 0.835273, valid_f1: 0.849516\n",
      "--- 8.72587513923645 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917103\n",
      "train_loss: 0.098599, valid_loss: 0.067073\n",
      "train_f1: 0.836945, valid_f1: 0.848960\n",
      "--- 7.951521873474121 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000910575\n",
      "train_loss: 0.096721, valid_loss: 0.066848\n",
      "train_f1: 0.838048, valid_f1: 0.849691\n",
      "--- 7.98264217376709 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000903824\n",
      "train_loss: 0.097084, valid_loss: 0.066386\n",
      "train_f1: 0.839446, valid_f1: 0.849500\n",
      "--- 7.926103353500366 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000896854\n",
      "train_loss: 0.094944, valid_loss: 0.065866\n",
      "train_f1: 0.840667, valid_f1: 0.849502\n",
      "--- 8.411216497421265 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000889669\n",
      "train_loss: 0.094636, valid_loss: 0.065489\n",
      "train_f1: 0.842155, valid_f1: 0.849040\n",
      "--- 8.357616662979126 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882273\n",
      "train_loss: 0.093101, valid_loss: 0.065277\n",
      "train_f1: 0.843063, valid_f1: 0.849601\n",
      "--- 8.680635929107666 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000874671\n",
      "train_loss: 0.094198, valid_loss: 0.065116\n",
      "train_f1: 0.844519, valid_f1: 0.849284\n",
      "--- 8.427757978439331 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000866865\n",
      "train_loss: 0.091846, valid_loss: 0.064527\n",
      "train_f1: 0.845781, valid_f1: 0.849104\n",
      "--- 8.580481767654419 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000858861\n",
      "train_loss: 0.091248, valid_loss: 0.063942\n",
      "train_f1: 0.848134, valid_f1: 0.849840\n",
      "--- 8.154932498931885 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000850662\n",
      "train_loss: 0.090849, valid_loss: 0.063573\n",
      "train_f1: 0.849945, valid_f1: 0.849969\n",
      "--- 8.219809770584106 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842274\n",
      "train_loss: 0.089539, valid_loss: 0.062831\n",
      "train_f1: 0.850421, valid_f1: 0.849793\n",
      "--- 7.995444297790527 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000833700\n",
      "train_loss: 0.089167, valid_loss: 0.062571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.853990, valid_f1: 0.850474\n",
      "--- 7.920761346817017 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000824945\n",
      "train_loss: 0.087565, valid_loss: 0.062487\n",
      "train_f1: 0.856770, valid_f1: 0.855565\n",
      "--- 7.925373554229736 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816015\n",
      "train_loss: 0.086876, valid_loss: 0.062020\n",
      "train_f1: 0.858865, valid_f1: 0.869903\n",
      "--- 7.947523355484009 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000806913\n",
      "train_loss: 0.087991, valid_loss: 0.061256\n",
      "train_f1: 0.860415, valid_f1: 0.905121\n",
      "--- 7.954632043838501 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000797645\n",
      "train_loss: 0.088437, valid_loss: 0.060420\n",
      "train_f1: 0.866560, valid_f1: 0.918865\n",
      "--- 8.600877523422241 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000788216\n",
      "train_loss: 0.087435, valid_loss: 0.060046\n",
      "train_f1: 0.868978, valid_f1: 0.922863\n",
      "--- 8.351093053817749 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000778631\n",
      "train_loss: 0.084620, valid_loss: 0.059621\n",
      "train_f1: 0.872748, valid_f1: 0.928052\n",
      "--- 7.999316215515137 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000768895\n",
      "train_loss: 0.084159, valid_loss: 0.059116\n",
      "train_f1: 0.876198, valid_f1: 0.933327\n",
      "--- 8.134454488754272 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759014\n",
      "train_loss: 0.085935, valid_loss: 0.058898\n",
      "train_f1: 0.879074, valid_f1: 0.935130\n",
      "--- 8.631869077682495 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000748992\n",
      "train_loss: 0.083917, valid_loss: 0.058790\n",
      "train_f1: 0.882016, valid_f1: 0.935157\n",
      "--- 8.57745909690857 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000738835\n",
      "train_loss: 0.082831, valid_loss: 0.058086\n",
      "train_f1: 0.884954, valid_f1: 0.937003\n",
      "--- 8.109663009643555 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000728549\n",
      "train_loss: 0.083191, valid_loss: 0.058258\n",
      "train_f1: 0.887547, valid_f1: 0.937151\n",
      "--- 7.961639642715454 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000718139\n",
      "train_loss: 0.081924, valid_loss: 0.057823\n",
      "train_f1: 0.889681, valid_f1: 0.937901\n",
      "--- 7.9583165645599365 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000707612\n",
      "train_loss: 0.081703, valid_loss: 0.057814\n",
      "train_f1: 0.892007, valid_f1: 0.937895\n",
      "--- 7.9911346435546875 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000696971\n",
      "train_loss: 0.081673, valid_loss: 0.057302\n",
      "train_f1: 0.894323, valid_f1: 0.937855\n",
      "--- 7.948368787765503 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000686224\n",
      "train_loss: 0.080574, valid_loss: 0.056986\n",
      "train_f1: 0.895525, valid_f1: 0.938019\n",
      "--- 7.917846918106079 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000675376\n",
      "train_loss: 0.078868, valid_loss: 0.057290\n",
      "train_f1: 0.897495, valid_f1: 0.938104\n",
      "--- 7.947192907333374 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000664434\n",
      "train_loss: 0.079275, valid_loss: 0.056716\n",
      "train_f1: 0.899311, valid_f1: 0.938006\n",
      "--- 7.975669860839844 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000653402\n",
      "train_loss: 0.078765, valid_loss: 0.056774\n",
      "train_f1: 0.900025, valid_f1: 0.938135\n",
      "--- 7.963342666625977 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000642287\n",
      "train_loss: 0.079261, valid_loss: 0.056621\n",
      "train_f1: 0.901293, valid_f1: 0.938254\n",
      "--- 7.95112681388855 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000631095\n",
      "train_loss: 0.078542, valid_loss: 0.056514\n",
      "train_f1: 0.902892, valid_f1: 0.937942\n",
      "--- 7.938527584075928 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000619832\n",
      "train_loss: 0.076250, valid_loss: 0.056345\n",
      "train_f1: 0.903455, valid_f1: 0.938044\n",
      "--- 7.9296534061431885 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000608504\n",
      "train_loss: 0.077642, valid_loss: 0.056118\n",
      "train_f1: 0.904483, valid_f1: 0.937907\n",
      "--- 7.976356506347656 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000597118\n",
      "train_loss: 0.077338, valid_loss: 0.056110\n",
      "train_f1: 0.905310, valid_f1: 0.937961\n",
      "--- 7.9499671459198 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000585678\n",
      "train_loss: 0.076306, valid_loss: 0.055942\n",
      "train_f1: 0.906364, valid_f1: 0.937970\n",
      "--- 7.958308935165405 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000574193\n",
      "train_loss: 0.077039, valid_loss: 0.055993\n",
      "train_f1: 0.906981, valid_f1: 0.937611\n",
      "--- 7.951965093612671 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000562667\n",
      "train_loss: 0.076805, valid_loss: 0.055778\n",
      "train_f1: 0.906962, valid_f1: 0.937751\n",
      "--- 7.957732677459717 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000551107\n",
      "train_loss: 0.076086, valid_loss: 0.055671\n",
      "train_f1: 0.908354, valid_f1: 0.937713\n",
      "--- 7.965651988983154 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000539520\n",
      "train_loss: 0.075698, valid_loss: 0.055602\n",
      "train_f1: 0.908595, valid_f1: 0.937593\n",
      "--- 7.956407785415649 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000527911\n",
      "train_loss: 0.075951, valid_loss: 0.055430\n",
      "train_f1: 0.909072, valid_f1: 0.937659\n",
      "--- 8.003136396408081 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000516287\n",
      "train_loss: 0.075388, valid_loss: 0.055559\n",
      "train_f1: 0.909985, valid_f1: 0.937711\n",
      "--- 7.9424755573272705 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000504655\n",
      "train_loss: 0.075929, valid_loss: 0.055483\n",
      "train_f1: 0.910558, valid_f1: 0.938055\n",
      "--- 7.953167915344238 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493019\n",
      "train_loss: 0.075413, valid_loss: 0.055339\n",
      "train_f1: 0.910650, valid_f1: 0.937781\n",
      "--- 7.954097509384155 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000481388\n",
      "train_loss: 0.076068, valid_loss: 0.055231\n",
      "train_f1: 0.911331, valid_f1: 0.938007\n",
      "--- 7.939622402191162 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000469767\n",
      "train_loss: 0.074027, valid_loss: 0.055306\n",
      "train_f1: 0.911909, valid_f1: 0.937745\n",
      "--- 7.940247535705566 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000458162\n",
      "train_loss: 0.075150, valid_loss: 0.055032\n",
      "train_f1: 0.911991, valid_f1: 0.938163\n",
      "--- 7.931221961975098 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000446579\n",
      "train_loss: 0.073719, valid_loss: 0.055122\n",
      "train_f1: 0.912722, valid_f1: 0.937913\n",
      "--- 7.917250633239746 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435026\n",
      "train_loss: 0.073740, valid_loss: 0.054903\n",
      "train_f1: 0.912942, valid_f1: 0.938077\n",
      "--- 7.972393274307251 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000423508\n",
      "train_loss: 0.074271, valid_loss: 0.054926\n",
      "train_f1: 0.913123, valid_f1: 0.937686\n",
      "--- 7.997854948043823 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412031\n",
      "train_loss: 0.074090, valid_loss: 0.054909\n",
      "train_f1: 0.913114, valid_f1: 0.937802\n",
      "Early Stopping...\n",
      "Best Val Score: 0.938254\n",
      "Fold : 2\n",
      "TRAIN: (1200,) TEST: (600,)\n",
      "Epoch : 0\n",
      "learning_rate: 0.000010000\n",
      "train_loss: 2.665491, valid_loss: 1.946943\n",
      "train_f1: 0.058656, valid_f1: 0.025047\n",
      "--- 8.06115460395813 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000020962\n",
      "train_loss: 2.428344, valid_loss: 1.760636\n",
      "train_f1: 0.062429, valid_f1: 0.032401\n",
      "--- 7.985555410385132 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000053363\n",
      "train_loss: 2.083348, valid_loss: 1.539062\n",
      "train_f1: 0.071791, valid_f1: 0.055154\n",
      "--- 8.020015954971313 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.000105767\n",
      "train_loss: 1.769472, valid_loss: 1.253407\n",
      "train_f1: 0.088651, valid_f1: 0.146199\n",
      "--- 8.061856508255005 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.000175854\n",
      "train_loss: 1.504234, valid_loss: 0.981773\n",
      "train_f1: 0.103754, valid_f1: 0.105438\n",
      "--- 8.098950386047363 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.000260519\n",
      "train_loss: 1.254151, valid_loss: 0.821251\n",
      "train_f1: 0.115283, valid_f1: 0.056020\n",
      "--- 8.056216478347778 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.000356012\n",
      "train_loss: 1.043908, valid_loss: 0.710583\n",
      "train_f1: 0.133852, valid_f1: 0.165574\n",
      "--- 8.033417224884033 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.000458105\n",
      "train_loss: 0.905981, valid_loss: 0.635740\n",
      "train_f1: 0.156414, valid_f1: 0.170436\n",
      "--- 8.466259002685547 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.000562274\n",
      "train_loss: 0.787840, valid_loss: 0.529144\n",
      "train_f1: 0.200865, valid_f1: 0.392931\n",
      "--- 8.311254978179932 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.000663907\n",
      "train_loss: 0.678720, valid_loss: 0.436301\n",
      "train_f1: 0.263023, valid_f1: 0.333453\n",
      "--- 7.968942165374756 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.000758501\n",
      "train_loss: 0.573876, valid_loss: 0.364816\n",
      "train_f1: 0.325073, valid_f1: 0.405958\n",
      "--- 7.979994297027588 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.000841868\n",
      "train_loss: 0.492374, valid_loss: 0.309292\n",
      "train_f1: 0.382538, valid_f1: 0.483183\n",
      "--- 8.0201735496521 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.000910314\n",
      "train_loss: 0.421031, valid_loss: 0.268212\n",
      "train_f1: 0.439718, valid_f1: 0.517155\n",
      "--- 7.967368125915527 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.000960808\n",
      "train_loss: 0.365618, valid_loss: 0.228753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.489555, valid_f1: 0.660609\n",
      "--- 7.990440607070923 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.000991114\n",
      "train_loss: 0.319245, valid_loss: 0.188293\n",
      "train_f1: 0.541753, valid_f1: 0.723606\n",
      "--- 7.945739507675171 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.000999999\n",
      "train_loss: 0.281362, valid_loss: 0.153767\n",
      "train_f1: 0.590758, valid_f1: 0.734528\n",
      "--- 7.962782859802246 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.000999836\n",
      "train_loss: 0.251188, valid_loss: 0.129976\n",
      "train_f1: 0.633441, valid_f1: 0.808507\n",
      "--- 7.970511198043823 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.000999403\n",
      "train_loss: 0.219333, valid_loss: 0.112813\n",
      "train_f1: 0.667280, valid_f1: 0.822847\n",
      "--- 7.959457635879517 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.000998700\n",
      "train_loss: 0.199627, valid_loss: 0.101985\n",
      "train_f1: 0.692233, valid_f1: 0.833781\n",
      "--- 7.941775798797607 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.000997726\n",
      "train_loss: 0.182862, valid_loss: 0.093661\n",
      "train_f1: 0.712813, valid_f1: 0.839780\n",
      "--- 8.014472961425781 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.000996483\n",
      "train_loss: 0.171505, valid_loss: 0.087545\n",
      "train_f1: 0.729135, valid_f1: 0.845118\n",
      "--- 7.9929444789886475 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.000994971\n",
      "train_loss: 0.160417, valid_loss: 0.082759\n",
      "train_f1: 0.744710, valid_f1: 0.845346\n",
      "--- 7.975598335266113 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.000993191\n",
      "train_loss: 0.150583, valid_loss: 0.079198\n",
      "train_f1: 0.757220, valid_f1: 0.846068\n",
      "--- 7.952033519744873 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.000991144\n",
      "train_loss: 0.143555, valid_loss: 0.076013\n",
      "train_f1: 0.767817, valid_f1: 0.846841\n",
      "--- 7.95096755027771 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.000988831\n",
      "train_loss: 0.139234, valid_loss: 0.073874\n",
      "train_f1: 0.776268, valid_f1: 0.848187\n",
      "--- 7.98152232170105 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.000986253\n",
      "train_loss: 0.135017, valid_loss: 0.072202\n",
      "train_f1: 0.783910, valid_f1: 0.847854\n",
      "--- 7.97811484336853 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.000983412\n",
      "train_loss: 0.128763, valid_loss: 0.071058\n",
      "train_f1: 0.791184, valid_f1: 0.847736\n",
      "--- 7.966300964355469 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.000980309\n",
      "train_loss: 0.126509, valid_loss: 0.069684\n",
      "train_f1: 0.797168, valid_f1: 0.848242\n",
      "--- 7.94797682762146 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.000976946\n",
      "train_loss: 0.122235, valid_loss: 0.069205\n",
      "train_f1: 0.801199, valid_f1: 0.848654\n",
      "--- 7.959532260894775 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.000973325\n",
      "train_loss: 0.120063, valid_loss: 0.068701\n",
      "train_f1: 0.806037, valid_f1: 0.848835\n",
      "--- 7.956284046173096 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.000969447\n",
      "train_loss: 0.114951, valid_loss: 0.068143\n",
      "train_f1: 0.809954, valid_f1: 0.849012\n",
      "--- 8.010013580322266 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.000965315\n",
      "train_loss: 0.113199, valid_loss: 0.067535\n",
      "train_f1: 0.813715, valid_f1: 0.848703\n",
      "--- 7.94382119178772 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.000960932\n",
      "train_loss: 0.112115, valid_loss: 0.067351\n",
      "train_f1: 0.815887, valid_f1: 0.848928\n",
      "--- 7.9664812088012695 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.000956298\n",
      "train_loss: 0.109092, valid_loss: 0.067118\n",
      "train_f1: 0.818675, valid_f1: 0.848746\n",
      "--- 8.039892435073853 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.000951418\n",
      "train_loss: 0.108063, valid_loss: 0.067324\n",
      "train_f1: 0.821205, valid_f1: 0.848984\n",
      "--- 7.951061964035034 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.000946293\n",
      "train_loss: 0.105027, valid_loss: 0.066528\n",
      "train_f1: 0.822685, valid_f1: 0.849011\n",
      "--- 7.927318811416626 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.000940926\n",
      "train_loss: 0.102583, valid_loss: 0.066790\n",
      "train_f1: 0.824441, valid_f1: 0.849033\n",
      "--- 7.960977792739868 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.000935321\n",
      "train_loss: 0.101761, valid_loss: 0.066285\n",
      "train_f1: 0.826799, valid_f1: 0.849326\n",
      "--- 7.946653127670288 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.000929480\n",
      "train_loss: 0.103332, valid_loss: 0.065804\n",
      "train_f1: 0.828095, valid_f1: 0.849343\n",
      "--- 7.950136423110962 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.000923406\n",
      "train_loss: 0.099813, valid_loss: 0.065645\n",
      "train_f1: 0.828714, valid_f1: 0.849491\n",
      "--- 7.950624465942383 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.000917103\n",
      "train_loss: 0.098414, valid_loss: 0.065419\n",
      "train_f1: 0.830186, valid_f1: 0.849737\n",
      "--- 7.992541790008545 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.000910575\n",
      "train_loss: 0.097055, valid_loss: 0.065455\n",
      "train_f1: 0.830770, valid_f1: 0.849346\n",
      "--- 7.9768385887146 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.000903824\n",
      "train_loss: 0.096193, valid_loss: 0.065313\n",
      "train_f1: 0.832378, valid_f1: 0.849741\n",
      "--- 7.9732561111450195 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.000896854\n",
      "train_loss: 0.094528, valid_loss: 0.065076\n",
      "train_f1: 0.833566, valid_f1: 0.849740\n",
      "--- 7.967479944229126 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.000889669\n",
      "train_loss: 0.095196, valid_loss: 0.065014\n",
      "train_f1: 0.833867, valid_f1: 0.849912\n",
      "--- 7.972332239151001 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.000882273\n",
      "train_loss: 0.095751, valid_loss: 0.064667\n",
      "train_f1: 0.835316, valid_f1: 0.849880\n",
      "--- 7.9641273021698 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.000874671\n",
      "train_loss: 0.092555, valid_loss: 0.064732\n",
      "train_f1: 0.835493, valid_f1: 0.849741\n",
      "--- 7.939373254776001 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.000866865\n",
      "train_loss: 0.094148, valid_loss: 0.064272\n",
      "train_f1: 0.836146, valid_f1: 0.849625\n",
      "--- 7.944623947143555 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.000858861\n",
      "train_loss: 0.093124, valid_loss: 0.064017\n",
      "train_f1: 0.836998, valid_f1: 0.850152\n",
      "--- 8.013729572296143 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.000850662\n",
      "train_loss: 0.092866, valid_loss: 0.063713\n",
      "train_f1: 0.837832, valid_f1: 0.850057\n",
      "--- 7.964818000793457 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.000842274\n",
      "train_loss: 0.091265, valid_loss: 0.063482\n",
      "train_f1: 0.839112, valid_f1: 0.850131\n",
      "--- 7.960062742233276 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.000833700\n",
      "train_loss: 0.090082, valid_loss: 0.063473\n",
      "train_f1: 0.838937, valid_f1: 0.849625\n",
      "--- 7.980249643325806 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.000824945\n",
      "train_loss: 0.088247, valid_loss: 0.063062\n",
      "train_f1: 0.840049, valid_f1: 0.850102\n",
      "--- 7.9818480014801025 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.000816015\n",
      "train_loss: 0.088811, valid_loss: 0.062881\n",
      "train_f1: 0.840658, valid_f1: 0.850025\n",
      "--- 7.953043460845947 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.000806913\n",
      "train_loss: 0.086703, valid_loss: 0.062366\n",
      "train_f1: 0.841633, valid_f1: 0.849694\n",
      "--- 7.941276550292969 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.000797645\n",
      "train_loss: 0.088525, valid_loss: 0.062502\n",
      "train_f1: 0.842491, valid_f1: 0.850213\n",
      "--- 7.973635196685791 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.000788216\n",
      "train_loss: 0.088129, valid_loss: 0.062057\n",
      "train_f1: 0.843186, valid_f1: 0.850032\n",
      "--- 7.991039514541626 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.000778631\n",
      "train_loss: 0.086499, valid_loss: 0.061781\n",
      "train_f1: 0.844295, valid_f1: 0.850230\n",
      "--- 7.949217081069946 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.000768895\n",
      "train_loss: 0.085044, valid_loss: 0.061376\n",
      "train_f1: 0.845053, valid_f1: 0.849955\n",
      "--- 7.964010238647461 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.000759014\n",
      "train_loss: 0.086083, valid_loss: 0.061499\n",
      "train_f1: 0.846733, valid_f1: 0.850069\n",
      "--- 7.952672243118286 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.000748992\n",
      "train_loss: 0.086432, valid_loss: 0.061047\n",
      "train_f1: 0.848880, valid_f1: 0.849645\n",
      "--- 7.954594135284424 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.000738835\n",
      "train_loss: 0.084880, valid_loss: 0.060868\n",
      "train_f1: 0.849859, valid_f1: 0.850103\n",
      "--- 7.963215589523315 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.000728549\n",
      "train_loss: 0.083161, valid_loss: 0.060492\n",
      "train_f1: 0.852363, valid_f1: 0.850021\n",
      "--- 7.936820030212402 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.000718139\n",
      "train_loss: 0.083510, valid_loss: 0.060160\n",
      "train_f1: 0.855059, valid_f1: 0.850108\n",
      "--- 7.965002775192261 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.000707612\n",
      "train_loss: 0.083800, valid_loss: 0.059846\n",
      "train_f1: 0.856721, valid_f1: 0.850082\n",
      "--- 7.981961965560913 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.000696971\n",
      "train_loss: 0.084594, valid_loss: 0.059445\n",
      "train_f1: 0.860067, valid_f1: 0.850575\n",
      "--- 7.952617883682251 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.000686224\n",
      "train_loss: 0.083271, valid_loss: 0.059114\n",
      "train_f1: 0.863003, valid_f1: 0.865275\n",
      "--- 8.001205205917358 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.000675376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.082365, valid_loss: 0.058581\n",
      "train_f1: 0.865690, valid_f1: 0.893244\n",
      "--- 7.976168870925903 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.000664434\n",
      "train_loss: 0.081257, valid_loss: 0.058553\n",
      "train_f1: 0.867844, valid_f1: 0.918578\n",
      "--- 8.010127544403076 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.000653402\n",
      "train_loss: 0.079998, valid_loss: 0.057914\n",
      "train_f1: 0.872164, valid_f1: 0.920962\n",
      "--- 7.961558103561401 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.000642287\n",
      "train_loss: 0.080355, valid_loss: 0.057588\n",
      "train_f1: 0.874898, valid_f1: 0.930027\n",
      "--- 7.95403265953064 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.000631095\n",
      "train_loss: 0.081754, valid_loss: 0.057407\n",
      "train_f1: 0.877323, valid_f1: 0.932792\n",
      "--- 7.972431421279907 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.000619832\n",
      "train_loss: 0.079072, valid_loss: 0.057111\n",
      "train_f1: 0.879065, valid_f1: 0.935147\n",
      "--- 7.945966482162476 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.000608504\n",
      "train_loss: 0.078847, valid_loss: 0.056828\n",
      "train_f1: 0.882637, valid_f1: 0.936056\n",
      "--- 7.971785545349121 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.000597118\n",
      "train_loss: 0.080103, valid_loss: 0.056602\n",
      "train_f1: 0.883702, valid_f1: 0.937106\n",
      "--- 7.959843397140503 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.000585678\n",
      "train_loss: 0.079267, valid_loss: 0.056250\n",
      "train_f1: 0.885540, valid_f1: 0.937781\n",
      "--- 7.962692022323608 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.000574193\n",
      "train_loss: 0.079768, valid_loss: 0.056333\n",
      "train_f1: 0.887217, valid_f1: 0.938022\n",
      "--- 7.9551239013671875 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.000562667\n",
      "train_loss: 0.078103, valid_loss: 0.056123\n",
      "train_f1: 0.889069, valid_f1: 0.938461\n",
      "--- 7.9445531368255615 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.000551107\n",
      "train_loss: 0.078345, valid_loss: 0.055870\n",
      "train_f1: 0.890973, valid_f1: 0.938337\n",
      "--- 7.95908784866333 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.000539520\n",
      "train_loss: 0.078389, valid_loss: 0.055736\n",
      "train_f1: 0.892269, valid_f1: 0.938619\n",
      "--- 7.957640886306763 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.000527911\n",
      "train_loss: 0.078096, valid_loss: 0.055610\n",
      "train_f1: 0.893172, valid_f1: 0.938092\n",
      "--- 7.983015298843384 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.000516287\n",
      "train_loss: 0.078731, valid_loss: 0.055735\n",
      "train_f1: 0.895007, valid_f1: 0.937976\n",
      "--- 7.953597784042358 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.000504655\n",
      "train_loss: 0.076351, valid_loss: 0.055363\n",
      "train_f1: 0.896051, valid_f1: 0.938362\n",
      "--- 7.968176364898682 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.000493019\n",
      "train_loss: 0.076404, valid_loss: 0.055212\n",
      "train_f1: 0.896769, valid_f1: 0.938650\n",
      "--- 7.943320035934448 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.000481388\n",
      "train_loss: 0.076335, valid_loss: 0.055128\n",
      "train_f1: 0.897578, valid_f1: 0.938594\n",
      "--- 7.969539165496826 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.000469767\n",
      "train_loss: 0.077875, valid_loss: 0.054892\n",
      "train_f1: 0.898580, valid_f1: 0.938773\n",
      "--- 7.953182697296143 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.000458162\n",
      "train_loss: 0.074449, valid_loss: 0.054943\n",
      "train_f1: 0.899485, valid_f1: 0.938404\n",
      "--- 7.946981191635132 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.000446579\n",
      "train_loss: 0.075810, valid_loss: 0.054987\n",
      "train_f1: 0.899984, valid_f1: 0.938469\n",
      "--- 7.966122627258301 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.000435026\n",
      "train_loss: 0.075146, valid_loss: 0.054695\n",
      "train_f1: 0.900749, valid_f1: 0.938817\n",
      "--- 7.967587471008301 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.000423508\n",
      "train_loss: 0.077061, valid_loss: 0.054672\n",
      "train_f1: 0.902107, valid_f1: 0.938887\n",
      "--- 7.9879138469696045 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.000412031\n",
      "train_loss: 0.075237, valid_loss: 0.054623\n",
      "train_f1: 0.902583, valid_f1: 0.938877\n",
      "--- 7.992969989776611 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.000400602\n",
      "train_loss: 0.074514, valid_loss: 0.054523\n",
      "train_f1: 0.903374, valid_f1: 0.938827\n",
      "--- 7.948974370956421 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.000389226\n",
      "train_loss: 0.075176, valid_loss: 0.054368\n",
      "train_f1: 0.903834, valid_f1: 0.938950\n",
      "--- 7.9802844524383545 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.000377911\n",
      "train_loss: 0.074520, valid_loss: 0.054443\n",
      "train_f1: 0.904662, valid_f1: 0.938895\n",
      "--- 7.983798503875732 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.000366662\n",
      "train_loss: 0.073731, valid_loss: 0.054321\n",
      "train_f1: 0.904383, valid_f1: 0.938856\n",
      "--- 8.015792608261108 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.000355485\n",
      "train_loss: 0.074617, valid_loss: 0.054272\n",
      "train_f1: 0.904814, valid_f1: 0.938755\n",
      "--- 7.962192535400391 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.000344386\n",
      "train_loss: 0.074389, valid_loss: 0.054255\n",
      "train_f1: 0.905815, valid_f1: 0.938707\n",
      "--- 7.96568751335144 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.000333371\n",
      "train_loss: 0.075012, valid_loss: 0.054186\n",
      "train_f1: 0.905631, valid_f1: 0.938799\n",
      "--- 7.961455821990967 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.000322447\n",
      "train_loss: 0.075170, valid_loss: 0.054099\n",
      "train_f1: 0.906055, valid_f1: 0.938865\n",
      "--- 7.938904285430908 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.000311619\n",
      "train_loss: 0.074684, valid_loss: 0.054141\n",
      "train_f1: 0.907010, valid_f1: 0.938688\n",
      "--- 7.965456962585449 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.000300893\n",
      "train_loss: 0.072458, valid_loss: 0.054084\n",
      "train_f1: 0.906700, valid_f1: 0.938632\n",
      "--- 7.999289274215698 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.000290275\n",
      "train_loss: 0.073652, valid_loss: 0.054053\n",
      "train_f1: 0.907441, valid_f1: 0.938830\n",
      "--- 7.960123777389526 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.000279770\n",
      "train_loss: 0.071580, valid_loss: 0.053895\n",
      "train_f1: 0.907894, valid_f1: 0.938885\n",
      "--- 7.948395490646362 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.000269384\n",
      "train_loss: 0.073771, valid_loss: 0.053990\n",
      "train_f1: 0.908117, valid_f1: 0.938935\n",
      "--- 7.959450721740723 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.000259124\n",
      "train_loss: 0.072412, valid_loss: 0.053929\n",
      "train_f1: 0.907873, valid_f1: 0.939001\n",
      "--- 7.9501190185546875 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.000248994\n",
      "train_loss: 0.074449, valid_loss: 0.053865\n",
      "train_f1: 0.908676, valid_f1: 0.938881\n",
      "--- 7.967407703399658 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.000239000\n",
      "train_loss: 0.072853, valid_loss: 0.053803\n",
      "train_f1: 0.908807, valid_f1: 0.938742\n",
      "--- 7.989969491958618 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.000229147\n",
      "train_loss: 0.072907, valid_loss: 0.053783\n",
      "train_f1: 0.909307, valid_f1: 0.938925\n",
      "--- 7.967225074768066 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.000219440\n",
      "train_loss: 0.072438, valid_loss: 0.053743\n",
      "train_f1: 0.909149, valid_f1: 0.938962\n",
      "--- 8.02441930770874 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.000209886\n",
      "train_loss: 0.072369, valid_loss: 0.053743\n",
      "train_f1: 0.909217, valid_f1: 0.939033\n",
      "--- 7.966039180755615 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.000200489\n",
      "train_loss: 0.072114, valid_loss: 0.053690\n",
      "train_f1: 0.909550, valid_f1: 0.938943\n",
      "--- 7.938758611679077 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.000191254\n",
      "train_loss: 0.071852, valid_loss: 0.053644\n",
      "train_f1: 0.909247, valid_f1: 0.938828\n",
      "--- 7.962653875350952 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.000182186\n",
      "train_loss: 0.072912, valid_loss: 0.053649\n",
      "train_f1: 0.910214, valid_f1: 0.938925\n",
      "--- 7.9578697681427 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.000173291\n",
      "train_loss: 0.072967, valid_loss: 0.053639\n",
      "train_f1: 0.910344, valid_f1: 0.938959\n",
      "--- 7.948018312454224 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.000164572\n",
      "train_loss: 0.073570, valid_loss: 0.053593\n",
      "train_f1: 0.910619, valid_f1: 0.938977\n",
      "--- 7.937722444534302 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.000156035\n",
      "train_loss: 0.072701, valid_loss: 0.053601\n",
      "train_f1: 0.910680, valid_f1: 0.938914\n",
      "--- 7.9828431606292725 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.000147684\n",
      "train_loss: 0.072268, valid_loss: 0.053637\n",
      "train_f1: 0.910471, valid_f1: 0.938996\n",
      "--- 7.953235149383545 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.000139524\n",
      "train_loss: 0.072316, valid_loss: 0.053616\n",
      "train_f1: 0.910941, valid_f1: 0.938885\n",
      "--- 7.952826499938965 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.000131559\n",
      "train_loss: 0.071229, valid_loss: 0.053585\n",
      "train_f1: 0.911066, valid_f1: 0.938994\n",
      "--- 7.956913948059082 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.000123793\n",
      "train_loss: 0.073026, valid_loss: 0.053496\n",
      "train_f1: 0.911296, valid_f1: 0.938903\n",
      "--- 7.966847658157349 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.000116232\n",
      "train_loss: 0.071466, valid_loss: 0.053455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.911173, valid_f1: 0.938997\n",
      "--- 7.982801198959351 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.000108878\n",
      "train_loss: 0.072534, valid_loss: 0.053448\n",
      "train_f1: 0.910950, valid_f1: 0.939008\n",
      "--- 7.953637361526489 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.000101736\n",
      "train_loss: 0.071912, valid_loss: 0.053490\n",
      "train_f1: 0.910980, valid_f1: 0.938952\n",
      "--- 7.9549171924591064 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000094810\n",
      "train_loss: 0.071462, valid_loss: 0.053502\n",
      "train_f1: 0.911763, valid_f1: 0.938955\n",
      "--- 7.9355857372283936 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000088103\n",
      "train_loss: 0.071690, valid_loss: 0.053443\n",
      "train_f1: 0.911535, valid_f1: 0.939019\n",
      "--- 8.041980504989624 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000081619\n",
      "train_loss: 0.072744, valid_loss: 0.053431\n",
      "train_f1: 0.911423, valid_f1: 0.938938\n",
      "--- 7.966798305511475 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000075361\n",
      "train_loss: 0.071123, valid_loss: 0.053437\n",
      "train_f1: 0.911743, valid_f1: 0.938965\n",
      "--- 7.95628023147583 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000069334\n",
      "train_loss: 0.072802, valid_loss: 0.053460\n",
      "train_f1: 0.911907, valid_f1: 0.938891\n",
      "--- 7.940094709396362 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000063540\n",
      "train_loss: 0.071301, valid_loss: 0.053471\n",
      "train_f1: 0.911570, valid_f1: 0.938956\n",
      "--- 7.985653638839722 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000057982\n",
      "train_loss: 0.070045, valid_loss: 0.053487\n",
      "train_f1: 0.911615, valid_f1: 0.938948\n",
      "Early Stopping...\n",
      "Best Val Score: 0.939033\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models\"):\n",
    "            os.makedirs(\"./models\")\n",
    "for index, (train_index, val_index ) in enumerate(skf.split(df_train, df_train_y, group)):\n",
    "    print(\"Fold : {}\".format(index))\n",
    "    print(\"TRAIN:\", train_index.shape, \"TEST:\", val_index.shape)\n",
    "    \n",
    "    batchsize = 128\n",
    "    train_dataset = IonDataset(df_train[train_index],  df_train_y[train_index], flip=False, noise_level=0.0, class_split=0.0)\n",
    "    train_dataloader = DataLoader(train_dataset, batchsize, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    valid_dataset = IonDataset(df_train[val_index],  df_train_y[val_index], flip=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batchsize, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    test_dataset = IonDataset(df_test,  df_test_y, flip=False, noise_level=0.0, class_split=0.0)\n",
    "    test_dataloader = DataLoader(test_dataset, batchsize, shuffle=False, num_workers=16, pin_memory=True)\n",
    "    test_preds_iter = np.zeros((2000000, 11))\n",
    "\n",
    "    for it in range(1):\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model=Seq2SeqRnn(input_size=df_train.shape[1], seq_len=2500, hidden_size=128, output_size=11, num_layers=2, hidden_layers=[128,64,128],\n",
    "                         bidirectional=True).to(device)\n",
    "        \n",
    "        no_of_epochs = 150\n",
    "        early_stopping = EarlyStopping(patience=20, is_maximize=True, checkpoint_path=\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it))\n",
    "        criterion = L.FocalLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e2, max_lr=0.001, epochs=no_of_epochs,\n",
    "                                                steps_per_epoch=len(train_dataloader))\n",
    "        avg_train_losses, avg_valid_losses = [], [] \n",
    "    \n",
    "    \n",
    "        for epoch in range(no_of_epochs):\n",
    "            start_time = time.time()\n",
    "    \n",
    "            print(\"Epoch : {}\".format(epoch))\n",
    "            print( \"learning_rate: {:0.9f}\".format(schedular.get_lr()[0]))\n",
    "            train_losses, valid_losses = [], []\n",
    "    \n",
    "            model.train() # prep model for training\n",
    "            train_preds, train_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "    \n",
    "            for x, y in train_dataloader:\n",
    "            \n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(x[:, :df_train.shape[1], :])\n",
    "    \n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                y_ = y.view(-1)\n",
    "    \n",
    "                loss = criterion(predictions_, y_)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                schedular.step()\n",
    "                # record training loss\n",
    "                train_losses.append(loss.item())\n",
    "    \n",
    "                train_true = torch.cat([train_true, y_], 0)\n",
    "                train_preds = torch.cat([train_preds, predictions_], 0)\n",
    "\n",
    "            model.eval() # prep model for evaluation\n",
    "            val_preds, val_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_dataloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "    \n",
    "                    predictions = model(x[:,:df_train.shape[1],:])\n",
    "                    predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                    y_ = y.view(-1)\n",
    "    \n",
    "                    loss = criterion(predictions_, y_)\n",
    "                    valid_losses.append(loss.item())\n",
    "                    \n",
    "                    val_true = torch.cat([val_true, y_], 0)\n",
    "                    val_preds = torch.cat([val_preds, predictions_], 0)\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            train_loss = np.average(train_losses)\n",
    "            valid_loss = np.average(valid_losses)\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "\n",
    "            print( \"train_loss: {:0.6f}, valid_loss: {:0.6f}\".format(train_loss, valid_loss))\n",
    "            \n",
    "            train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            print( \"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "    \n",
    "            if early_stopping(val_score, model):\n",
    "                print(\"Early Stopping...\")\n",
    "                print(\"Best Val Score: {:0.6f}\".format(early_stopping.best_score))\n",
    "                break\n",
    "    \n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it)))\n",
    "        with torch.no_grad():\n",
    "            pred_list = []\n",
    "            for x, y in test_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                predictions = model(x[:,:df_train.shape[1],:])\n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "\n",
    "                pred_list.append(F.softmax(predictions_, dim=1).cpu().numpy())\n",
    "            test_preds = np.vstack(pred_list)\n",
    "       \n",
    "        test_preds_iter += test_preds\n",
    "        test_preds_all += test_preds\n",
    "        if not os.path.exists(\"./predictions/test\"):\n",
    "            os.makedirs(\"./predictions/test\")\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_iter_{}_raw.npy'.format(index, it), arr=test_preds_iter)\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_raw.npy'.format(index), arr=test_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T06:22:01.104553Z",
     "start_time": "2020-04-12T06:21:58.145587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Best Val Score: 0.939033\n",
    "ss = pd.read_csv(\"../input/sample_submission.csv\", dtype={'time':str})\n",
    "\n",
    "test_preds_all = test_preds_all/np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"../submissions/gru_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
