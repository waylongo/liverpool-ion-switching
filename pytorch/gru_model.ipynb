{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:11.930924Z",
     "start_time": "2020-04-10T23:22:10.393529Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Much of this comes from https://www.kaggle.com/pradeeppathak9/gamma-log-facies-type-prediction\n",
    "# https://www.crowdanalytix.com/contests/gamma-log-facies-type-prediction\n",
    "######################################################\n",
    "import os\n",
    "os.system('pip install pytorch_toolbelt')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby, accumulate\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_toolbelt import losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:13.783502Z",
     "start_time": "2020-04-10T23:22:11.932014Z"
    }
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"../input/sample_submission.csv\", dtype={'time':str})\n",
    "train = pd.read_csv('../input/train_clean.csv')\n",
    "train['filter'] = 0\n",
    "test = pd.read_csv('../input/test_clean.csv')\n",
    "test['filter'] = 2\n",
    "ts1 = pd.concat([train, test], axis=0, sort=False).reset_index(drop=True)\n",
    "\n",
    "# ts1['time2'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14 + 1), labels=list(range(14)), include_lowest=True).astype(int)\n",
    "# ts1['time2'] = ts1.groupby('time2')['time'].rank( )/500000.\n",
    "# (never used)\n",
    "\n",
    "np.random.seed(321)\n",
    "ts1['group'] = pd.cut(ts1['time'], bins=np.linspace(0.0000, 700., num=14*125 + 1), labels=list(range(14*125)), include_lowest=True).astype(int)\n",
    "# --- there might be an improvement ---\n",
    "np.random.seed(321)\n",
    "\n",
    "y = ts1.loc[ts1['filter']==0, 'open_channels']\n",
    "group = ts1.loc[ts1['filter']==0, 'group']\n",
    "X = ts1.loc[ts1['filter']==0, 'signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:13.791608Z",
     "start_time": "2020-04-10T23:22:13.784490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>filter</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  filter  group\n",
       "0  0.0001 -2.7600            0.0       0      0\n",
       "1  0.0002 -2.8557            0.0       0      0\n",
       "2  0.0003 -2.4074            0.0       0      0\n",
       "3  0.0004 -3.1404            0.0       0      0\n",
       "4  0.0005 -3.1525            0.0       0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:13.829452Z",
     "start_time": "2020-04-10T23:22:13.792590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1[ts1.group==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:13.832860Z",
     "start_time": "2020-04-10T23:22:13.830439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000,) (5000000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:13.843756Z",
     "start_time": "2020-04-10T23:22:13.834452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -2.7600\n",
       "1   -2.8557\n",
       "2   -2.4074\n",
       "3   -3.1404\n",
       "4   -3.1525\n",
       "Name: signal, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:14.080682Z",
     "start_time": "2020-04-10T23:22:13.844940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['signal']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(321)\n",
    "skf = GroupKFold(n_splits=3) # there might be a problem, I would go with K-folder\n",
    "splits = [x for x in skf.split(X, y, group)]\n",
    "\n",
    "use_cols = [col for col in ts1.columns if col not in ['index','filter','group', 'open_channels', 'time', 'time2']]  \n",
    "print(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:14.083255Z",
     "start_time": "2020-04-10T23:22:14.081634Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create numpy array of inputs  # there is no NA vals\n",
    "# for col in use_cols:\n",
    "#     col_mean = ts1[col].mean()\n",
    "#     ts1[col] = ts1[col].fillna(col_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:14.263046Z",
     "start_time": "2020-04-10T23:22:14.083995Z"
    }
   },
   "outputs": [],
   "source": [
    "val_preds_all = np.zeros((ts1[ts1['filter']==0].shape[0], 11)) # why 11?\n",
    "test_preds_all = np.zeros((ts1[ts1['filter']==2].shape[0], 11))\n",
    "\n",
    "groups = ts1.loc[ts1['filter']==0, 'group']\n",
    "times = ts1.loc[ts1['filter']==0, 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:15.092476Z",
     "start_time": "2020-04-10T23:22:14.263976Z"
    }
   },
   "outputs": [],
   "source": [
    "new_splits = []\n",
    "for sp in splits:\n",
    "    new_split = []\n",
    "    new_split.append(np.unique(groups[sp[0]]))\n",
    "    new_split.append(np.unique(groups[sp[1]]))\n",
    "    new_splits.append(new_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.891245Z",
     "start_time": "2020-04-10T23:22:15.093366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 4000, 1) (500, 4000, 1) (1250, 4000, 1)\n"
     ]
    }
   ],
   "source": [
    "trainval = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "test = np.array(list(ts1[ts1['filter']==2].groupby('group').apply(lambda x: x[use_cols].values)))\n",
    "trainval_y = np.array(list(ts1[ts1['filter']==0].groupby('group').apply(lambda x: x[['open_channels']].values)))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(trainval.shape, test.shape, trainval_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.895597Z",
     "start_time": "2020-04-10T23:22:16.892129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250, 1, 4000) (500, 1, 4000) (1250, 4000) (500, 4000)\n"
     ]
    }
   ],
   "source": [
    "# transpose to B x C x L\n",
    "trainval = trainval.transpose((0,2,1))\n",
    "test = test.transpose((0,2,1))\n",
    "\n",
    "trainval_y = trainval_y.reshape(trainval_y.shape[:2])\n",
    "test_y = np.zeros((test.shape[0], trainval_y.shape[1]))\n",
    "\n",
    "print(trainval.shape, test.shape, trainval_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.931184Z",
     "start_time": "2020-04-10T23:22:16.896514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1250, 1, 4000]) torch.Size([500, 1, 4000])\n"
     ]
    }
   ],
   "source": [
    "trainval = torch.Tensor(trainval)\n",
    "test = torch.Tensor(test)\n",
    "\n",
    "print(trainval.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.936760Z",
     "start_time": "2020-04-10T23:22:16.932255Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, checkpoint_path='checkpoint.pt', is_maximize=True):\n",
    "        self.patience, self.delta, self.checkpoint_path = patience, delta, checkpoint_path\n",
    "        self.counter, self.best_score = 0, None\n",
    "        self.is_maximize = is_maximize\n",
    "\n",
    "    def load_best_weights(self, model):\n",
    "        model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "\n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None or \\\n",
    "        (score > self.best_score + self.delta if self.is_maximize else score < self.best_score - self.delta):\n",
    "            torch.save(model.state_dict(), self.checkpoint_path)\n",
    "            self.best_score, self.counter = score, 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.949029Z",
     "start_time": "2020-04-10T23:22:16.937904Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRnn(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, output_size, num_layers=1, bidirectional=False, dropout=.3,\n",
    "            hidden_layers = [100, 200]):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers=num_layers\n",
    "        self.bidirectional=bidirectional\n",
    "        self.output_size=output_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, \n",
    "                           bidirectional=bidirectional, batch_first=True,dropout=0.3)\n",
    "         # Input Layer\n",
    "        if hidden_layers and len(hidden_layers):\n",
    "            first_layer  = nn.Linear(hidden_size*2 if bidirectional else hidden_size, hidden_layers[0])\n",
    "\n",
    "            # Hidden Layers\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [first_layer]+[nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers) - 1)]\n",
    "            )\n",
    "            for layer in self.hidden_layers: nn.init.kaiming_normal_(layer.weight.data)   \n",
    "\n",
    "            self.intermediate_layer = nn.Linear(hidden_layers[-1], self.input_size)\n",
    "            # output layers\n",
    "            self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "           \n",
    "        else:\n",
    "            self.hidden_layers = []\n",
    "            self.intermediate_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_siz, self.input_size)\n",
    "            self.output_layer = nn.Linear(hidden_size*2 if bidirectional else hidden_size, output_size)\n",
    "            nn.init.kaiming_normal_(self.output_layer.weight.data) \n",
    "\n",
    "        self.activation_fn = torch.relu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        outputs, hidden = self.rnn(x)        \n",
    "\n",
    "        x = self.dropout(self.activation_fn(outputs))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fn(hidden_layer(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:02:31.059518Z",
     "start_time": "2020-04-10T23:02:31.053570Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T23:22:16.962550Z",
     "start_time": "2020-04-10T23:22:16.950452Z"
    }
   },
   "outputs": [],
   "source": [
    "class IonDataset(Dataset):\n",
    "    \"\"\"Ion dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, labels, training=True, transform=None, flip=0.5, noise_level=0, class_split=0.0):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.training = training\n",
    "        self.flip = flip\n",
    "        self.noise_level = noise_level\n",
    "        self.class_split = class_split\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        data = self.data[idx]\n",
    "        labels = self.labels[idx]\n",
    "        if np.random.rand() < self.class_split:\n",
    "            data, labels = class_split(data, labels)\n",
    "        if  np.random.rand() < self.noise_level:\n",
    "            data = data * torch.FloatTensor(10000).uniform_(1-self.noise_level, 1+self.noise_level)\n",
    "        if np.random.rand() < self.flip:\n",
    "            data = torch.flip(data, dims=[1])\n",
    "            labels = np.flip(labels, axis=0).copy().astype(int)\n",
    "\n",
    "        return [data, labels.astype(int)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:13:12.474725Z",
     "start_time": "2020-04-10T23:22:16.963415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Epoch : 0\n",
      "learning_rate: 0.000100000\n",
      "train_loss: 2.186580, valid_loss: 1.845660\n",
      "train_f1: 0.045292, valid_f1: 0.018308\n",
      "--- 7.415477514266968 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000210252\n",
      "train_loss: 1.908828, valid_loss: 1.566396\n",
      "train_f1: 0.054074, valid_f1: 0.025139\n",
      "--- 7.729543209075928 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000536096\n",
      "train_loss: 1.585143, valid_loss: 1.198098\n",
      "train_f1: 0.075707, valid_f1: 0.094982\n",
      "--- 7.414370536804199 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.001063017\n",
      "train_loss: 1.261296, valid_loss: 0.817176\n",
      "train_f1: 0.099017, valid_f1: 0.088155\n",
      "--- 7.714250087738037 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.001767543\n",
      "train_loss: 1.009829, valid_loss: 0.745155\n",
      "train_f1: 0.129883, valid_f1: 0.075647\n",
      "--- 7.32867169380188 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.002618290\n",
      "train_loss: 0.816270, valid_loss: 0.648013\n",
      "train_f1: 0.161181, valid_f1: 0.198276\n",
      "--- 8.332963705062866 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.003577360\n",
      "train_loss: 0.695454, valid_loss: 0.586066\n",
      "train_f1: 0.207966, valid_f1: 0.311075\n",
      "--- 7.713640213012695 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.004602031\n",
      "train_loss: 0.595619, valid_loss: 0.513628\n",
      "train_f1: 0.272645, valid_f1: 0.325373\n",
      "--- 7.698567628860474 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.005646657\n",
      "train_loss: 0.508178, valid_loss: 0.589477\n",
      "train_f1: 0.324581, valid_f1: 0.318123\n",
      "--- 7.305248260498047 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.006664704\n",
      "train_loss: 0.502195, valid_loss: 0.421828\n",
      "train_f1: 0.359193, valid_f1: 0.425611\n",
      "--- 7.389857530593872 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.007610822\n",
      "train_loss: 0.420705, valid_loss: 0.401920\n",
      "train_f1: 0.396293, valid_f1: 0.380397\n",
      "--- 7.449707508087158 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.008442866\n",
      "train_loss: 0.366479, valid_loss: 0.339537\n",
      "train_f1: 0.426478, valid_f1: 0.485481\n",
      "--- 7.258016586303711 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.009123770\n",
      "train_loss: 0.319361, valid_loss: 0.289970\n",
      "train_f1: 0.476397, valid_f1: 0.551189\n",
      "--- 7.571578502655029 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.009623204\n",
      "train_loss: 0.276518, valid_loss: 0.252307\n",
      "train_f1: 0.529380, valid_f1: 0.671506\n",
      "--- 7.720659494400024 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.009918919\n",
      "train_loss: 0.247752, valid_loss: 0.217147\n",
      "train_f1: 0.580868, valid_f1: 0.738787\n",
      "--- 7.422249794006348 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.009999972\n",
      "train_loss: 0.215452, valid_loss: 0.193725\n",
      "train_f1: 0.618880, valid_f1: 0.783138\n",
      "--- 7.396515607833862 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.009998232\n",
      "train_loss: 0.200158, valid_loss: 0.174778\n",
      "train_f1: 0.650131, valid_f1: 0.781508\n",
      "--- 8.072690725326538 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.009993785\n",
      "train_loss: 0.183502, valid_loss: 0.157526\n",
      "train_f1: 0.680365, valid_f1: 0.809210\n",
      "--- 7.602712392807007 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.009986633\n",
      "train_loss: 0.169923, valid_loss: 0.154464\n",
      "train_f1: 0.706974, valid_f1: 0.778263\n",
      "--- 7.2729387283325195 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.009976781\n",
      "train_loss: 0.165006, valid_loss: 0.140075\n",
      "train_f1: 0.711317, valid_f1: 0.822178\n",
      "--- 7.281948804855347 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.009964235\n",
      "train_loss: 0.152210, valid_loss: 0.128176\n",
      "train_f1: 0.733417, valid_f1: 0.825896\n",
      "--- 7.582820892333984 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.009949000\n",
      "train_loss: 0.144299, valid_loss: 0.125703\n",
      "train_f1: 0.750353, valid_f1: 0.829076\n",
      "--- 7.799180030822754 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.009931085\n",
      "train_loss: 0.137658, valid_loss: 0.117122\n",
      "train_f1: 0.760990, valid_f1: 0.840705\n",
      "--- 7.665203094482422 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.009910499\n",
      "train_loss: 0.129998, valid_loss: 0.109943\n",
      "train_f1: 0.774143, valid_f1: 0.842092\n",
      "--- 7.445676565170288 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.009887255\n",
      "train_loss: 0.124212, valid_loss: 0.104490\n",
      "train_f1: 0.784441, valid_f1: 0.844583\n",
      "--- 7.339653491973877 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.009861364\n",
      "train_loss: 0.121948, valid_loss: 0.110707\n",
      "train_f1: 0.791323, valid_f1: 0.823610\n",
      "--- 7.5187764167785645 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.009832841\n",
      "train_loss: 0.127214, valid_loss: 0.120291\n",
      "train_f1: 0.780834, valid_f1: 0.819131\n",
      "--- 7.36049485206604 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.009801700\n",
      "train_loss: 0.116532, valid_loss: 0.103626\n",
      "train_f1: 0.795859, valid_f1: 0.836236\n",
      "--- 7.2164716720581055 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.009767960\n",
      "train_loss: 0.112561, valid_loss: 0.097316\n",
      "train_f1: 0.804576, valid_f1: 0.845168\n",
      "--- 7.243736743927002 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.009731637\n",
      "train_loss: 0.107329, valid_loss: 0.097449\n",
      "train_f1: 0.810438, valid_f1: 0.841945\n",
      "--- 7.6922831535339355 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.009692752\n",
      "train_loss: 0.106769, valid_loss: 0.095463\n",
      "train_f1: 0.813569, valid_f1: 0.843805\n",
      "--- 7.201244115829468 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.009651326\n",
      "train_loss: 0.103563, valid_loss: 0.092247\n",
      "train_f1: 0.816601, valid_f1: 0.845770\n",
      "--- 7.256939888000488 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.009607381\n",
      "train_loss: 0.102877, valid_loss: 0.093164\n",
      "train_f1: 0.818463, valid_f1: 0.844595\n",
      "--- 7.224789142608643 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.009560942\n",
      "train_loss: 0.098851, valid_loss: 0.092292\n",
      "train_f1: 0.821241, valid_f1: 0.845968\n",
      "--- 7.316389799118042 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.009512032\n",
      "train_loss: 0.097277, valid_loss: 0.090941\n",
      "train_f1: 0.823121, valid_f1: 0.846361\n",
      "--- 7.2267560958862305 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.009460679\n",
      "train_loss: 0.096416, valid_loss: 0.090135\n",
      "train_f1: 0.824351, valid_f1: 0.846163\n",
      "--- 7.207167625427246 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.009406911\n",
      "train_loss: 0.097395, valid_loss: 0.089242\n",
      "train_f1: 0.826105, valid_f1: 0.846163\n",
      "--- 7.350248336791992 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.009350756\n",
      "train_loss: 0.092128, valid_loss: 0.089500\n",
      "train_f1: 0.826139, valid_f1: 0.846862\n",
      "--- 7.221472978591919 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.009292245\n",
      "train_loss: 0.096806, valid_loss: 0.097700\n",
      "train_f1: 0.821854, valid_f1: 0.837269\n",
      "--- 7.191014766693115 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.009231409\n",
      "train_loss: 0.100109, valid_loss: 0.099274\n",
      "train_f1: 0.815241, valid_f1: 0.836650\n",
      "--- 7.21083664894104 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.009168283\n",
      "train_loss: 0.094389, valid_loss: 0.091111\n",
      "train_f1: 0.824341, valid_f1: 0.844596\n",
      "--- 7.211156368255615 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.009102899\n",
      "train_loss: 0.092271, valid_loss: 0.088302\n",
      "train_f1: 0.828518, valid_f1: 0.846525\n",
      "--- 7.292144060134888 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.009035293\n",
      "train_loss: 0.090276, valid_loss: 0.087752\n",
      "train_f1: 0.830129, valid_f1: 0.846638\n",
      "--- 7.272059202194214 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.008965503\n",
      "train_loss: 0.088685, valid_loss: 0.087872\n",
      "train_f1: 0.831617, valid_f1: 0.846789\n",
      "--- 7.154371976852417 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.008893564\n",
      "train_loss: 0.087462, valid_loss: 0.086988\n",
      "train_f1: 0.831895, valid_f1: 0.846767\n",
      "--- 7.17439079284668 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.008819518\n",
      "train_loss: 0.087840, valid_loss: 0.085867\n",
      "train_f1: 0.833694, valid_f1: 0.847216\n",
      "--- 7.179075241088867 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.008743403\n",
      "train_loss: 0.086384, valid_loss: 0.085534\n",
      "train_f1: 0.834274, valid_f1: 0.846795\n",
      "--- 7.793308734893799 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.008665261\n",
      "train_loss: 0.086429, valid_loss: 0.085268\n",
      "train_f1: 0.834756, valid_f1: 0.847237\n",
      "--- 7.551937580108643 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.008585134\n",
      "train_loss: 0.085603, valid_loss: 0.085668\n",
      "train_f1: 0.836844, valid_f1: 0.846444\n",
      "--- 7.904926300048828 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.008503066\n",
      "train_loss: 0.085805, valid_loss: 0.085029\n",
      "train_f1: 0.838652, valid_f1: 0.847105\n",
      "--- 7.392057418823242 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.008419100\n",
      "train_loss: 0.084334, valid_loss: 0.085303\n",
      "train_f1: 0.840987, valid_f1: 0.847595\n",
      "--- 7.833235502243042 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.008333284\n",
      "train_loss: 0.086087, valid_loss: 0.085599\n",
      "train_f1: 0.842820, valid_f1: 0.844454\n",
      "--- 7.411978006362915 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.008245662\n",
      "train_loss: 0.086199, valid_loss: 0.086566\n",
      "train_f1: 0.842984, valid_f1: 0.844352\n",
      "--- 7.740553855895996 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.008156282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.083382, valid_loss: 0.085191\n",
      "train_f1: 0.844158, valid_f1: 0.909571\n",
      "--- 7.440787076950073 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.008065194\n",
      "train_loss: 0.083273, valid_loss: 0.083980\n",
      "train_f1: 0.849426, valid_f1: 0.858283\n",
      "--- 7.554769039154053 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.007972445\n",
      "train_loss: 0.082544, valid_loss: 0.082920\n",
      "train_f1: 0.852907, valid_f1: 0.846079\n",
      "--- 7.7946226596832275 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.007878087\n",
      "train_loss: 0.081674, valid_loss: 0.082950\n",
      "train_f1: 0.852757, valid_f1: 0.930233\n",
      "--- 7.5721821784973145 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.007782171\n",
      "train_loss: 0.082213, valid_loss: 0.082118\n",
      "train_f1: 0.859070, valid_f1: 0.916921\n",
      "--- 7.842922210693359 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.007684748\n",
      "train_loss: 0.081123, valid_loss: 0.082010\n",
      "train_f1: 0.860000, valid_f1: 0.900025\n",
      "--- 7.745798587799072 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.007585871\n",
      "train_loss: 0.080693, valid_loss: 0.081838\n",
      "train_f1: 0.863300, valid_f1: 0.931498\n",
      "--- 7.472744941711426 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.007485593\n",
      "train_loss: 0.081004, valid_loss: 0.082842\n",
      "train_f1: 0.866325, valid_f1: 0.916321\n",
      "--- 7.211886167526245 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.007383970\n",
      "train_loss: 0.080437, valid_loss: 0.080993\n",
      "train_f1: 0.866092, valid_f1: 0.927157\n",
      "--- 7.394275665283203 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.007281056\n",
      "train_loss: 0.080531, valid_loss: 0.081167\n",
      "train_f1: 0.870699, valid_f1: 0.932561\n",
      "--- 7.390882253646851 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.007176907\n",
      "train_loss: 0.078483, valid_loss: 0.080093\n",
      "train_f1: 0.872585, valid_f1: 0.923863\n",
      "--- 7.38194465637207 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.007071578\n",
      "train_loss: 0.078444, valid_loss: 0.080186\n",
      "train_f1: 0.872041, valid_f1: 0.932305\n",
      "--- 7.937031030654907 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.006965128\n",
      "train_loss: 0.079196, valid_loss: 0.080054\n",
      "train_f1: 0.874549, valid_f1: 0.931249\n",
      "--- 7.60947585105896 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.006857614\n",
      "train_loss: 0.079834, valid_loss: 0.079144\n",
      "train_f1: 0.875991, valid_f1: 0.926321\n",
      "--- 7.315767765045166 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.006749094\n",
      "train_loss: 0.079360, valid_loss: 0.079238\n",
      "train_f1: 0.875253, valid_f1: 0.932082\n",
      "--- 7.275076389312744 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.006639626\n",
      "train_loss: 0.079333, valid_loss: 0.079280\n",
      "train_f1: 0.876835, valid_f1: 0.932861\n",
      "--- 7.261738538742065 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.006529271\n",
      "train_loss: 0.078116, valid_loss: 0.078724\n",
      "train_f1: 0.880149, valid_f1: 0.932317\n",
      "--- 7.229919195175171 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.006418088\n",
      "train_loss: 0.076982, valid_loss: 0.078362\n",
      "train_f1: 0.879279, valid_f1: 0.933470\n",
      "--- 7.293828964233398 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.006306137\n",
      "train_loss: 0.076899, valid_loss: 0.078243\n",
      "train_f1: 0.881598, valid_f1: 0.932455\n",
      "--- 7.336419582366943 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.006193478\n",
      "train_loss: 0.077699, valid_loss: 0.078079\n",
      "train_f1: 0.882815, valid_f1: 0.934438\n",
      "--- 8.11570429801941 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.006080173\n",
      "train_loss: 0.076647, valid_loss: 0.077689\n",
      "train_f1: 0.882665, valid_f1: 0.933637\n",
      "--- 8.087402820587158 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.005966284\n",
      "train_loss: 0.076790, valid_loss: 0.077502\n",
      "train_f1: 0.883419, valid_f1: 0.934539\n",
      "--- 7.24311089515686 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.005851871\n",
      "train_loss: 0.076371, valid_loss: 0.077573\n",
      "train_f1: 0.884459, valid_f1: 0.933832\n",
      "--- 7.26850962638855 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.005736996\n",
      "train_loss: 0.076054, valid_loss: 0.077843\n",
      "train_f1: 0.886024, valid_f1: 0.933283\n",
      "--- 7.54107666015625 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.005621723\n",
      "train_loss: 0.076284, valid_loss: 0.077275\n",
      "train_f1: 0.885907, valid_f1: 0.933227\n",
      "--- 7.512638568878174 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.005506113\n",
      "train_loss: 0.076117, valid_loss: 0.077543\n",
      "train_f1: 0.886029, valid_f1: 0.935100\n",
      "--- 7.604971647262573 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.005390229\n",
      "train_loss: 0.074817, valid_loss: 0.077384\n",
      "train_f1: 0.887958, valid_f1: 0.934719\n",
      "--- 7.725688219070435 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.005274133\n",
      "train_loss: 0.075293, valid_loss: 0.077050\n",
      "train_f1: 0.888201, valid_f1: 0.934888\n",
      "--- 7.588476181030273 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.005157889\n",
      "train_loss: 0.074630, valid_loss: 0.076414\n",
      "train_f1: 0.889380, valid_f1: 0.934581\n",
      "--- 7.84235692024231 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.005041560\n",
      "train_loss: 0.074755, valid_loss: 0.076858\n",
      "train_f1: 0.889591, valid_f1: 0.935154\n",
      "--- 7.921597242355347 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.004925208\n",
      "train_loss: 0.075856, valid_loss: 0.076538\n",
      "train_f1: 0.889964, valid_f1: 0.934810\n",
      "--- 8.325503587722778 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.004808897\n",
      "train_loss: 0.074438, valid_loss: 0.076341\n",
      "train_f1: 0.889799, valid_f1: 0.934730\n",
      "--- 7.452904939651489 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.004692689\n",
      "train_loss: 0.073496, valid_loss: 0.076126\n",
      "train_f1: 0.891238, valid_f1: 0.935205\n",
      "--- 7.566087245941162 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.004576647\n",
      "train_loss: 0.073712, valid_loss: 0.076126\n",
      "train_f1: 0.892004, valid_f1: 0.934585\n",
      "--- 7.781347751617432 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.004460835\n",
      "train_loss: 0.074499, valid_loss: 0.076369\n",
      "train_f1: 0.892386, valid_f1: 0.935142\n",
      "--- 7.479262590408325 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.004345315\n",
      "train_loss: 0.073935, valid_loss: 0.076027\n",
      "train_f1: 0.892869, valid_f1: 0.934971\n",
      "--- 7.23417592048645 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.004230149\n",
      "train_loss: 0.072679, valid_loss: 0.075872\n",
      "train_f1: 0.893492, valid_f1: 0.935504\n",
      "--- 7.367676019668579 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.004115400\n",
      "train_loss: 0.074913, valid_loss: 0.075725\n",
      "train_f1: 0.893686, valid_f1: 0.934746\n",
      "--- 8.07718014717102 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.004001130\n",
      "train_loss: 0.073466, valid_loss: 0.076164\n",
      "train_f1: 0.893709, valid_f1: 0.935192\n",
      "--- 7.7748801708221436 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.003887401\n",
      "train_loss: 0.074471, valid_loss: 0.075963\n",
      "train_f1: 0.894236, valid_f1: 0.934171\n",
      "--- 8.25295639038086 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.003774275\n",
      "train_loss: 0.072922, valid_loss: 0.076051\n",
      "train_f1: 0.894014, valid_f1: 0.935164\n",
      "--- 7.912461042404175 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.003661812\n",
      "train_loss: 0.073214, valid_loss: 0.075743\n",
      "train_f1: 0.894425, valid_f1: 0.934908\n",
      "--- 7.284782409667969 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.003550074\n",
      "train_loss: 0.072031, valid_loss: 0.075517\n",
      "train_f1: 0.895459, valid_f1: 0.934576\n",
      "--- 7.902727127075195 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.003439122\n",
      "train_loss: 0.073349, valid_loss: 0.075685\n",
      "train_f1: 0.895643, valid_f1: 0.935352\n",
      "--- 7.2135093212127686 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.003329014\n",
      "train_loss: 0.072415, valid_loss: 0.075135\n",
      "train_f1: 0.895887, valid_f1: 0.935010\n",
      "--- 7.2106850147247314 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.003219811\n",
      "train_loss: 0.072469, valid_loss: 0.075382\n",
      "train_f1: 0.896253, valid_f1: 0.935577\n",
      "--- 7.173194885253906 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.003111572\n",
      "train_loss: 0.071983, valid_loss: 0.075309\n",
      "train_f1: 0.896240, valid_f1: 0.935546\n",
      "--- 7.185336589813232 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.003004356\n",
      "train_loss: 0.073581, valid_loss: 0.075211\n",
      "train_f1: 0.896434, valid_f1: 0.935517\n",
      "--- 7.2366790771484375 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.002898221\n",
      "train_loss: 0.071942, valid_loss: 0.075257\n",
      "train_f1: 0.897181, valid_f1: 0.935531\n",
      "--- 7.338118076324463 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.002793224\n",
      "train_loss: 0.072226, valid_loss: 0.074979\n",
      "train_f1: 0.896996, valid_f1: 0.935434\n",
      "--- 7.249877214431763 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.002689421\n",
      "train_loss: 0.072734, valid_loss: 0.075139\n",
      "train_f1: 0.896442, valid_f1: 0.935176\n",
      "--- 7.229218006134033 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.002586870\n",
      "train_loss: 0.072919, valid_loss: 0.074724\n",
      "train_f1: 0.897608, valid_f1: 0.935528\n",
      "--- 7.533965110778809 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.002485626\n",
      "train_loss: 0.071574, valid_loss: 0.074952\n",
      "train_f1: 0.898333, valid_f1: 0.935600\n",
      "--- 7.755354642868042 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.002385743\n",
      "train_loss: 0.072098, valid_loss: 0.075098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.898694, valid_f1: 0.935497\n",
      "--- 7.442668676376343 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.002287276\n",
      "train_loss: 0.071798, valid_loss: 0.074703\n",
      "train_f1: 0.897726, valid_f1: 0.935788\n",
      "--- 7.184764862060547 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.002190278\n",
      "train_loss: 0.071933, valid_loss: 0.074950\n",
      "train_f1: 0.898937, valid_f1: 0.935618\n",
      "--- 7.582178115844727 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.002094802\n",
      "train_loss: 0.070248, valid_loss: 0.074758\n",
      "train_f1: 0.899167, valid_f1: 0.935531\n",
      "--- 7.312358379364014 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.002000899\n",
      "train_loss: 0.071310, valid_loss: 0.074666\n",
      "train_f1: 0.899601, valid_f1: 0.935673\n",
      "--- 7.632787227630615 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.001908619\n",
      "train_loss: 0.071380, valid_loss: 0.074793\n",
      "train_f1: 0.899161, valid_f1: 0.935671\n",
      "--- 7.253572940826416 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.001818014\n",
      "train_loss: 0.070880, valid_loss: 0.074504\n",
      "train_f1: 0.899375, valid_f1: 0.935612\n",
      "--- 7.3435704708099365 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.001729132\n",
      "train_loss: 0.072222, valid_loss: 0.074421\n",
      "train_f1: 0.899863, valid_f1: 0.935619\n",
      "--- 7.684225082397461 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.001642021\n",
      "train_loss: 0.071840, valid_loss: 0.074601\n",
      "train_f1: 0.899667, valid_f1: 0.935664\n",
      "--- 7.409027099609375 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.001556729\n",
      "train_loss: 0.070367, valid_loss: 0.074429\n",
      "train_f1: 0.900377, valid_f1: 0.935627\n",
      "--- 7.659163236618042 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.001473301\n",
      "train_loss: 0.070663, valid_loss: 0.074374\n",
      "train_f1: 0.899984, valid_f1: 0.935652\n",
      "--- 7.9255571365356445 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.001391783\n",
      "train_loss: 0.072304, valid_loss: 0.074305\n",
      "train_f1: 0.900123, valid_f1: 0.935560\n",
      "--- 7.682528257369995 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.001312219\n",
      "train_loss: 0.070963, valid_loss: 0.074443\n",
      "train_f1: 0.900544, valid_f1: 0.935657\n",
      "--- 7.511346101760864 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.001234651\n",
      "train_loss: 0.070108, valid_loss: 0.074522\n",
      "train_f1: 0.900526, valid_f1: 0.935877\n",
      "--- 7.287232398986816 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.001159123\n",
      "train_loss: 0.073374, valid_loss: 0.074249\n",
      "train_f1: 0.900276, valid_f1: 0.935790\n",
      "--- 7.22216796875 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.001085675\n",
      "train_loss: 0.071554, valid_loss: 0.074150\n",
      "train_f1: 0.901280, valid_f1: 0.935585\n",
      "--- 7.755919456481934 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.001014346\n",
      "train_loss: 0.072025, valid_loss: 0.074360\n",
      "train_f1: 0.900856, valid_f1: 0.935709\n",
      "--- 8.16477918624878 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000945176\n",
      "train_loss: 0.070860, valid_loss: 0.074365\n",
      "train_f1: 0.900570, valid_f1: 0.935865\n",
      "--- 7.552356243133545 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000878202\n",
      "train_loss: 0.071484, valid_loss: 0.074159\n",
      "train_f1: 0.901190, valid_f1: 0.935370\n",
      "--- 7.378142595291138 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000813459\n",
      "train_loss: 0.072283, valid_loss: 0.074342\n",
      "train_f1: 0.900511, valid_f1: 0.935765\n",
      "--- 7.366250991821289 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000750984\n",
      "train_loss: 0.070361, valid_loss: 0.074311\n",
      "train_f1: 0.901450, valid_f1: 0.935719\n",
      "--- 7.270313024520874 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000690809\n",
      "train_loss: 0.070877, valid_loss: 0.074249\n",
      "train_f1: 0.900954, valid_f1: 0.935690\n",
      "--- 7.236026048660278 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000632968\n",
      "train_loss: 0.072050, valid_loss: 0.074242\n",
      "train_f1: 0.900930, valid_f1: 0.935724\n",
      "--- 7.217967987060547 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000577492\n",
      "train_loss: 0.070507, valid_loss: 0.074188\n",
      "train_f1: 0.901053, valid_f1: 0.935676\n",
      "--- 7.419368267059326 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000524411\n",
      "train_loss: 0.070520, valid_loss: 0.074168\n",
      "train_f1: 0.901540, valid_f1: 0.935783\n",
      "--- 7.312666893005371 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000473753\n",
      "train_loss: 0.071344, valid_loss: 0.074204\n",
      "train_f1: 0.901452, valid_f1: 0.935765\n",
      "--- 7.72908091545105 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000425547\n",
      "train_loss: 0.071248, valid_loss: 0.074241\n",
      "train_f1: 0.901750, valid_f1: 0.935682\n",
      "--- 7.490127801895142 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000379817\n",
      "train_loss: 0.071064, valid_loss: 0.074190\n",
      "train_f1: 0.901366, valid_f1: 0.935656\n",
      "--- 7.6135334968566895 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000336590\n",
      "train_loss: 0.070555, valid_loss: 0.074194\n",
      "train_f1: 0.901548, valid_f1: 0.935723\n",
      "--- 7.467933177947998 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000295887\n",
      "train_loss: 0.069196, valid_loss: 0.074162\n",
      "train_f1: 0.901588, valid_f1: 0.935755\n",
      "--- 7.197663307189941 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000257733\n",
      "train_loss: 0.071868, valid_loss: 0.074104\n",
      "train_f1: 0.901163, valid_f1: 0.935727\n",
      "--- 7.199474811553955 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000222146\n",
      "train_loss: 0.070831, valid_loss: 0.074141\n",
      "train_f1: 0.901523, valid_f1: 0.935662\n",
      "--- 7.186694383621216 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000189146\n",
      "train_loss: 0.070195, valid_loss: 0.074179\n",
      "train_f1: 0.901517, valid_f1: 0.935798\n",
      "--- 7.827807426452637 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000158752\n",
      "train_loss: 0.071371, valid_loss: 0.074190\n",
      "train_f1: 0.901239, valid_f1: 0.935805\n",
      "Early Stopping...\n",
      "Best Val Score: 0.935877\n",
      "Fold : 1\n",
      "Epoch : 0\n",
      "learning_rate: 0.000100000\n",
      "train_loss: 2.374625, valid_loss: 2.030020\n",
      "train_f1: 0.048378, valid_f1: 0.003402\n",
      "--- 7.709686279296875 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000210252\n",
      "train_loss: 2.097528, valid_loss: 1.767073\n",
      "train_f1: 0.056148, valid_f1: 0.031469\n",
      "--- 7.5423126220703125 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000536096\n",
      "train_loss: 1.792290, valid_loss: 1.543216\n",
      "train_f1: 0.069550, valid_f1: 0.029526\n",
      "--- 7.86620569229126 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.001063017\n",
      "train_loss: 1.500590, valid_loss: 1.212890\n",
      "train_f1: 0.083447, valid_f1: 0.029812\n",
      "--- 7.715807676315308 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.001767543\n",
      "train_loss: 1.126315, valid_loss: 0.782871\n",
      "train_f1: 0.109346, valid_f1: 0.128346\n",
      "--- 7.764302015304565 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.002618290\n",
      "train_loss: 0.859488, valid_loss: 0.694320\n",
      "train_f1: 0.143828, valid_f1: 0.178599\n",
      "--- 7.971554756164551 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.003577360\n",
      "train_loss: 0.732199, valid_loss: 0.636814\n",
      "train_f1: 0.180105, valid_f1: 0.288496\n",
      "--- 8.025814533233643 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.004602031\n",
      "train_loss: 0.637432, valid_loss: 0.567866\n",
      "train_f1: 0.229215, valid_f1: 0.378131\n",
      "--- 8.098599910736084 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.005646657\n",
      "train_loss: 0.555521, valid_loss: 0.489298\n",
      "train_f1: 0.279069, valid_f1: 0.342443\n",
      "--- 7.774015426635742 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.006664704\n",
      "train_loss: 0.478489, valid_loss: 0.426673\n",
      "train_f1: 0.328938, valid_f1: 0.474396\n",
      "--- 8.33693528175354 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.007610822\n",
      "train_loss: 0.420389, valid_loss: 0.404792\n",
      "train_f1: 0.376527, valid_f1: 0.430809\n",
      "--- 7.987672567367554 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.008442866\n",
      "train_loss: 0.384974, valid_loss: 0.344423\n",
      "train_f1: 0.413186, valid_f1: 0.525107\n",
      "--- 7.300769329071045 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.009123770\n",
      "train_loss: 0.329745, valid_loss: 0.290152\n",
      "train_f1: 0.465576, valid_f1: 0.547686\n",
      "--- 7.924025535583496 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.009623204\n",
      "train_loss: 0.283638, valid_loss: 0.234302\n",
      "train_f1: 0.527185, valid_f1: 0.588365\n",
      "--- 7.931185483932495 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.009918919\n",
      "train_loss: 0.249812, valid_loss: 0.199286\n",
      "train_f1: 0.579878, valid_f1: 0.751870\n",
      "--- 7.7896728515625 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.009999972\n",
      "train_loss: 0.220222, valid_loss: 0.179377\n",
      "train_f1: 0.620692, valid_f1: 0.785008\n",
      "--- 7.278577089309692 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.009998232\n",
      "train_loss: 0.197886, valid_loss: 0.166657\n",
      "train_f1: 0.653100, valid_f1: 0.822752\n",
      "--- 7.3290114402771 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.009993785\n",
      "train_loss: 0.187698, valid_loss: 0.154194\n",
      "train_f1: 0.667395, valid_f1: 0.810066\n",
      "--- 7.418403625488281 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.009986633\n",
      "train_loss: 0.173218, valid_loss: 0.139192\n",
      "train_f1: 0.697753, valid_f1: 0.822904\n",
      "--- 7.813960313796997 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.009976781\n",
      "train_loss: 0.159300, valid_loss: 0.130233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.717229, valid_f1: 0.837544\n",
      "--- 7.267252206802368 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.009964235\n",
      "train_loss: 0.152288, valid_loss: 0.136460\n",
      "train_f1: 0.732686, valid_f1: 0.804837\n",
      "--- 7.333908557891846 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.009949000\n",
      "train_loss: 0.173239, valid_loss: 0.155341\n",
      "train_f1: 0.700498, valid_f1: 0.831905\n",
      "--- 7.453807353973389 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.009931085\n",
      "train_loss: 0.161333, valid_loss: 0.124429\n",
      "train_f1: 0.722510, valid_f1: 0.811747\n",
      "--- 7.56661319732666 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.009910499\n",
      "train_loss: 0.143337, valid_loss: 0.119229\n",
      "train_f1: 0.741670, valid_f1: 0.814081\n",
      "--- 7.738405704498291 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.009887255\n",
      "train_loss: 0.130614, valid_loss: 0.112373\n",
      "train_f1: 0.759422, valid_f1: 0.831245\n",
      "--- 7.240250825881958 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.009861364\n",
      "train_loss: 0.124436, valid_loss: 0.105702\n",
      "train_f1: 0.768781, valid_f1: 0.840925\n",
      "--- 7.422787666320801 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.009832841\n",
      "train_loss: 0.124413, valid_loss: 0.101848\n",
      "train_f1: 0.779029, valid_f1: 0.844528\n",
      "--- 7.395282506942749 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.009801700\n",
      "train_loss: 0.118439, valid_loss: 0.099072\n",
      "train_f1: 0.786764, valid_f1: 0.845262\n",
      "--- 7.213160276412964 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.009767960\n",
      "train_loss: 0.114899, valid_loss: 0.096548\n",
      "train_f1: 0.794869, valid_f1: 0.846861\n",
      "--- 7.22514271736145 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.009731637\n",
      "train_loss: 0.109558, valid_loss: 0.094605\n",
      "train_f1: 0.801037, valid_f1: 0.846623\n",
      "--- 7.222107172012329 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.009692752\n",
      "train_loss: 0.108439, valid_loss: 0.092675\n",
      "train_f1: 0.806308, valid_f1: 0.847203\n",
      "--- 7.253777265548706 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.009651326\n",
      "train_loss: 0.108075, valid_loss: 0.092295\n",
      "train_f1: 0.809691, valid_f1: 0.847028\n",
      "--- 7.4379425048828125 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.009607381\n",
      "train_loss: 0.104441, valid_loss: 0.091080\n",
      "train_f1: 0.813200, valid_f1: 0.847469\n",
      "--- 7.247391939163208 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.009560942\n",
      "train_loss: 0.102837, valid_loss: 0.091233\n",
      "train_f1: 0.814817, valid_f1: 0.846857\n",
      "--- 7.325725317001343 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.009512032\n",
      "train_loss: 0.101069, valid_loss: 0.090018\n",
      "train_f1: 0.816513, valid_f1: 0.847535\n",
      "--- 7.406058311462402 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.009460679\n",
      "train_loss: 0.099480, valid_loss: 0.089604\n",
      "train_f1: 0.818650, valid_f1: 0.847629\n",
      "--- 7.416127443313599 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.009406911\n",
      "train_loss: 0.098251, valid_loss: 0.089129\n",
      "train_f1: 0.820729, valid_f1: 0.846554\n",
      "--- 7.366179466247559 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.009350756\n",
      "train_loss: 0.096815, valid_loss: 0.088494\n",
      "train_f1: 0.822558, valid_f1: 0.847450\n",
      "--- 7.5027852058410645 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.009292245\n",
      "train_loss: 0.097175, valid_loss: 0.088593\n",
      "train_f1: 0.822763, valid_f1: 0.847050\n",
      "--- 7.784519195556641 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.009231409\n",
      "train_loss: 0.097510, valid_loss: 0.091733\n",
      "train_f1: 0.825984, valid_f1: 0.841340\n",
      "--- 7.653857231140137 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.009168283\n",
      "train_loss: 0.096600, valid_loss: 0.093202\n",
      "train_f1: 0.822676, valid_f1: 0.842025\n",
      "--- 7.333647727966309 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.009102899\n",
      "train_loss: 0.093144, valid_loss: 0.086635\n",
      "train_f1: 0.827057, valid_f1: 0.847384\n",
      "--- 7.808234453201294 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.009035293\n",
      "train_loss: 0.092261, valid_loss: 0.087544\n",
      "train_f1: 0.829414, valid_f1: 0.845905\n",
      "--- 7.48078727722168 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.008965503\n",
      "train_loss: 0.091552, valid_loss: 0.085848\n",
      "train_f1: 0.833327, valid_f1: 0.847317\n",
      "--- 7.2416417598724365 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.008893564\n",
      "train_loss: 0.090019, valid_loss: 0.085586\n",
      "train_f1: 0.834428, valid_f1: 0.847492\n",
      "--- 7.257047414779663 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.008819518\n",
      "train_loss: 0.088015, valid_loss: 0.085656\n",
      "train_f1: 0.836000, valid_f1: 0.847225\n",
      "--- 7.223412275314331 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.008743403\n",
      "train_loss: 0.089626, valid_loss: 0.084783\n",
      "train_f1: 0.837571, valid_f1: 0.847209\n",
      "--- 7.620035648345947 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.008665261\n",
      "train_loss: 0.089721, valid_loss: 0.084738\n",
      "train_f1: 0.840889, valid_f1: 0.847930\n",
      "--- 7.226021766662598 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.008585134\n",
      "train_loss: 0.089078, valid_loss: 0.083842\n",
      "train_f1: 0.842723, valid_f1: 0.849116\n",
      "--- 7.216685056686401 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.008503066\n",
      "train_loss: 0.088307, valid_loss: 0.083045\n",
      "train_f1: 0.843690, valid_f1: 0.852190\n",
      "--- 7.24005913734436 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.008419100\n",
      "train_loss: 0.087192, valid_loss: 0.083384\n",
      "train_f1: 0.845607, valid_f1: 0.903942\n",
      "--- 7.55276083946228 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.008333284\n",
      "train_loss: 0.086646, valid_loss: 0.085114\n",
      "train_f1: 0.848775, valid_f1: 0.885588\n",
      "--- 7.649646997451782 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.008245662\n",
      "train_loss: 0.087922, valid_loss: 0.083434\n",
      "train_f1: 0.847545, valid_f1: 0.908726\n",
      "--- 7.482660293579102 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.008156282\n",
      "train_loss: 0.087643, valid_loss: 0.087219\n",
      "train_f1: 0.849863, valid_f1: 0.921678\n",
      "--- 7.890324831008911 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.008065194\n",
      "train_loss: 0.088840, valid_loss: 0.085078\n",
      "train_f1: 0.849028, valid_f1: 0.923303\n",
      "--- 7.960654020309448 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.007972445\n",
      "train_loss: 0.084587, valid_loss: 0.081938\n",
      "train_f1: 0.854555, valid_f1: 0.922137\n",
      "--- 7.919229030609131 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.007878087\n",
      "train_loss: 0.082769, valid_loss: 0.082164\n",
      "train_f1: 0.858546, valid_f1: 0.928895\n",
      "--- 7.680266380310059 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.007782171\n",
      "train_loss: 0.082829, valid_loss: 0.081178\n",
      "train_f1: 0.861890, valid_f1: 0.925274\n",
      "--- 8.127350330352783 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.007684748\n",
      "train_loss: 0.083198, valid_loss: 0.080708\n",
      "train_f1: 0.863278, valid_f1: 0.930211\n",
      "--- 7.927580118179321 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.007585871\n",
      "train_loss: 0.084409, valid_loss: 0.080126\n",
      "train_f1: 0.865290, valid_f1: 0.929688\n",
      "--- 7.836247205734253 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.007485593\n",
      "train_loss: 0.080936, valid_loss: 0.079559\n",
      "train_f1: 0.866952, valid_f1: 0.929883\n",
      "--- 7.920515060424805 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.007383970\n",
      "train_loss: 0.079878, valid_loss: 0.079753\n",
      "train_f1: 0.867845, valid_f1: 0.931591\n",
      "--- 7.83279824256897 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.007281056\n",
      "train_loss: 0.082269, valid_loss: 0.079454\n",
      "train_f1: 0.869464, valid_f1: 0.931054\n",
      "--- 7.701791048049927 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.007176907\n",
      "train_loss: 0.080614, valid_loss: 0.079374\n",
      "train_f1: 0.871429, valid_f1: 0.934840\n",
      "--- 7.253421068191528 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.007071578\n",
      "train_loss: 0.080526, valid_loss: 0.078697\n",
      "train_f1: 0.872275, valid_f1: 0.932232\n",
      "--- 7.22688102722168 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.006965128\n",
      "train_loss: 0.080065, valid_loss: 0.078972\n",
      "train_f1: 0.873449, valid_f1: 0.933966\n",
      "--- 7.529978036880493 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.006857614\n",
      "train_loss: 0.080920, valid_loss: 0.078502\n",
      "train_f1: 0.874495, valid_f1: 0.934380\n",
      "--- 7.595015525817871 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.006749094\n",
      "train_loss: 0.079561, valid_loss: 0.078132\n",
      "train_f1: 0.875768, valid_f1: 0.935996\n",
      "--- 7.445438385009766 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.006639626\n",
      "train_loss: 0.079891, valid_loss: 0.077977\n",
      "train_f1: 0.876060, valid_f1: 0.935941\n",
      "--- 7.771615743637085 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.006529271\n",
      "train_loss: 0.079926, valid_loss: 0.077582\n",
      "train_f1: 0.877615, valid_f1: 0.935011\n",
      "--- 7.754413843154907 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.006418088\n",
      "train_loss: 0.077465, valid_loss: 0.077886\n",
      "train_f1: 0.877890, valid_f1: 0.936474\n",
      "--- 7.591376066207886 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.006306137\n",
      "train_loss: 0.079467, valid_loss: 0.077294\n",
      "train_f1: 0.878893, valid_f1: 0.935294\n",
      "--- 7.945629358291626 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.006193478\n",
      "train_loss: 0.077440, valid_loss: 0.077212\n",
      "train_f1: 0.879234, valid_f1: 0.935445\n",
      "--- 7.769406795501709 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.006080173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.075889, valid_loss: 0.077276\n",
      "train_f1: 0.880525, valid_f1: 0.935831\n",
      "--- 7.6561126708984375 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.005966284\n",
      "train_loss: 0.076327, valid_loss: 0.077347\n",
      "train_f1: 0.880745, valid_f1: 0.935598\n",
      "--- 7.821583271026611 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.005851871\n",
      "train_loss: 0.077177, valid_loss: 0.077098\n",
      "train_f1: 0.881271, valid_f1: 0.936369\n",
      "--- 7.667788743972778 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.005736996\n",
      "train_loss: 0.076726, valid_loss: 0.077225\n",
      "train_f1: 0.882042, valid_f1: 0.936354\n",
      "--- 7.718796730041504 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.005621723\n",
      "train_loss: 0.076800, valid_loss: 0.076926\n",
      "train_f1: 0.882694, valid_f1: 0.936126\n",
      "--- 8.388787508010864 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.005506113\n",
      "train_loss: 0.077302, valid_loss: 0.076770\n",
      "train_f1: 0.881747, valid_f1: 0.936310\n",
      "--- 7.229533433914185 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.005390229\n",
      "train_loss: 0.076855, valid_loss: 0.077054\n",
      "train_f1: 0.883014, valid_f1: 0.936269\n",
      "--- 7.831188440322876 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.005274133\n",
      "train_loss: 0.077780, valid_loss: 0.076564\n",
      "train_f1: 0.883864, valid_f1: 0.936711\n",
      "--- 7.653387069702148 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.005157889\n",
      "train_loss: 0.075407, valid_loss: 0.076515\n",
      "train_f1: 0.883591, valid_f1: 0.936964\n",
      "--- 7.495096921920776 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.005041560\n",
      "train_loss: 0.075032, valid_loss: 0.076578\n",
      "train_f1: 0.883703, valid_f1: 0.936494\n",
      "--- 7.34949254989624 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.004925208\n",
      "train_loss: 0.077390, valid_loss: 0.076824\n",
      "train_f1: 0.883994, valid_f1: 0.936630\n",
      "--- 7.235379219055176 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.004808897\n",
      "train_loss: 0.074929, valid_loss: 0.075988\n",
      "train_f1: 0.884739, valid_f1: 0.936997\n",
      "--- 7.207217454910278 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.004692689\n",
      "train_loss: 0.076996, valid_loss: 0.076355\n",
      "train_f1: 0.885095, valid_f1: 0.936882\n",
      "--- 7.515012741088867 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.004576647\n",
      "train_loss: 0.076136, valid_loss: 0.076866\n",
      "train_f1: 0.884943, valid_f1: 0.936968\n",
      "--- 7.727028131484985 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.004460835\n",
      "train_loss: 0.076365, valid_loss: 0.075981\n",
      "train_f1: 0.886059, valid_f1: 0.937197\n",
      "--- 7.377610921859741 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.004345315\n",
      "train_loss: 0.075092, valid_loss: 0.076254\n",
      "train_f1: 0.885638, valid_f1: 0.936746\n",
      "--- 7.681433916091919 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.004230149\n",
      "train_loss: 0.075863, valid_loss: 0.075933\n",
      "train_f1: 0.886544, valid_f1: 0.937120\n",
      "--- 8.330418586730957 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.004115400\n",
      "train_loss: 0.075409, valid_loss: 0.075968\n",
      "train_f1: 0.886005, valid_f1: 0.937061\n",
      "--- 7.746665000915527 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.004001130\n",
      "train_loss: 0.074452, valid_loss: 0.077154\n",
      "train_f1: 0.884854, valid_f1: 0.935645\n",
      "--- 7.962752103805542 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.003887401\n",
      "train_loss: 0.073510, valid_loss: 0.076267\n",
      "train_f1: 0.886160, valid_f1: 0.935444\n",
      "--- 8.27105164527893 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.003774275\n",
      "train_loss: 0.077166, valid_loss: 0.076487\n",
      "train_f1: 0.887394, valid_f1: 0.936393\n",
      "--- 7.771929740905762 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.003661812\n",
      "train_loss: 0.074272, valid_loss: 0.076583\n",
      "train_f1: 0.886946, valid_f1: 0.936730\n",
      "--- 7.782032012939453 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.003550074\n",
      "train_loss: 0.076889, valid_loss: 0.075913\n",
      "train_f1: 0.886297, valid_f1: 0.936426\n",
      "--- 7.498237609863281 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.003439122\n",
      "train_loss: 0.073788, valid_loss: 0.076055\n",
      "train_f1: 0.886568, valid_f1: 0.936353\n",
      "--- 7.5163254737854 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.003329014\n",
      "train_loss: 0.075072, valid_loss: 0.076172\n",
      "train_f1: 0.887650, valid_f1: 0.937133\n",
      "--- 7.987670660018921 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.003219811\n",
      "train_loss: 0.073428, valid_loss: 0.076455\n",
      "train_f1: 0.887982, valid_f1: 0.936098\n",
      "--- 7.396061182022095 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.003111572\n",
      "train_loss: 0.073881, valid_loss: 0.076102\n",
      "train_f1: 0.887780, valid_f1: 0.936433\n",
      "--- 7.5043044090271 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.003004356\n",
      "train_loss: 0.074468, valid_loss: 0.075470\n",
      "train_f1: 0.887808, valid_f1: 0.937468\n",
      "--- 7.603073835372925 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.002898221\n",
      "train_loss: 0.074145, valid_loss: 0.075940\n",
      "train_f1: 0.888331, valid_f1: 0.936593\n",
      "--- 7.267435073852539 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.002793224\n",
      "train_loss: 0.073716, valid_loss: 0.075710\n",
      "train_f1: 0.887750, valid_f1: 0.937331\n",
      "--- 7.31123161315918 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.002689421\n",
      "train_loss: 0.073210, valid_loss: 0.075645\n",
      "train_f1: 0.888944, valid_f1: 0.937189\n",
      "--- 7.299249172210693 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.002586870\n",
      "train_loss: 0.074350, valid_loss: 0.075435\n",
      "train_f1: 0.888046, valid_f1: 0.937280\n",
      "--- 7.346357345581055 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.002485626\n",
      "train_loss: 0.072452, valid_loss: 0.075335\n",
      "train_f1: 0.889015, valid_f1: 0.937362\n",
      "--- 7.319593667984009 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.002385743\n",
      "train_loss: 0.072451, valid_loss: 0.075521\n",
      "train_f1: 0.888806, valid_f1: 0.937380\n",
      "--- 7.629723072052002 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.002287276\n",
      "train_loss: 0.073088, valid_loss: 0.075262\n",
      "train_f1: 0.889383, valid_f1: 0.937425\n",
      "--- 7.2471864223480225 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.002190278\n",
      "train_loss: 0.071770, valid_loss: 0.075311\n",
      "train_f1: 0.889409, valid_f1: 0.937397\n",
      "--- 7.690198659896851 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.002094802\n",
      "train_loss: 0.073698, valid_loss: 0.075319\n",
      "train_f1: 0.889313, valid_f1: 0.937379\n",
      "--- 7.577575445175171 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.002000899\n",
      "train_loss: 0.071770, valid_loss: 0.075361\n",
      "train_f1: 0.889580, valid_f1: 0.937381\n",
      "--- 7.29948353767395 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.001908619\n",
      "train_loss: 0.072069, valid_loss: 0.075171\n",
      "train_f1: 0.890282, valid_f1: 0.937392\n",
      "--- 7.356181383132935 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.001818014\n",
      "train_loss: 0.073132, valid_loss: 0.075329\n",
      "train_f1: 0.889527, valid_f1: 0.937323\n",
      "--- 7.341277360916138 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.001729132\n",
      "train_loss: 0.073017, valid_loss: 0.075426\n",
      "train_f1: 0.890279, valid_f1: 0.937371\n",
      "--- 7.316858291625977 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.001642021\n",
      "train_loss: 0.073088, valid_loss: 0.075228\n",
      "train_f1: 0.889871, valid_f1: 0.937346\n",
      "--- 7.450114011764526 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.001556729\n",
      "train_loss: 0.074042, valid_loss: 0.075017\n",
      "train_f1: 0.889867, valid_f1: 0.937351\n",
      "--- 7.4813618659973145 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.001473301\n",
      "train_loss: 0.072859, valid_loss: 0.075268\n",
      "train_f1: 0.889866, valid_f1: 0.937424\n",
      "--- 7.368082761764526 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.001391783\n",
      "train_loss: 0.071631, valid_loss: 0.075102\n",
      "train_f1: 0.890669, valid_f1: 0.937409\n",
      "--- 7.8426902294158936 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.001312219\n",
      "train_loss: 0.072892, valid_loss: 0.075108\n",
      "train_f1: 0.890006, valid_f1: 0.937468\n",
      "--- 7.733685255050659 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.001234651\n",
      "train_loss: 0.073559, valid_loss: 0.074991\n",
      "train_f1: 0.890556, valid_f1: 0.937598\n",
      "--- 7.651453495025635 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.001159123\n",
      "train_loss: 0.072762, valid_loss: 0.075155\n",
      "train_f1: 0.890039, valid_f1: 0.937503\n",
      "--- 7.302357196807861 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.001085675\n",
      "train_loss: 0.073670, valid_loss: 0.075218\n",
      "train_f1: 0.890284, valid_f1: 0.937467\n",
      "--- 7.582639694213867 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.001014346\n",
      "train_loss: 0.071940, valid_loss: 0.075235\n",
      "train_f1: 0.890380, valid_f1: 0.937591\n",
      "--- 7.202604532241821 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000945176\n",
      "train_loss: 0.074315, valid_loss: 0.075133\n",
      "train_f1: 0.890324, valid_f1: 0.937518\n",
      "--- 7.451607942581177 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000878202\n",
      "train_loss: 0.072450, valid_loss: 0.074993\n",
      "train_f1: 0.890661, valid_f1: 0.937559\n",
      "--- 8.081453561782837 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000813459\n",
      "train_loss: 0.072433, valid_loss: 0.074941\n",
      "train_f1: 0.891249, valid_f1: 0.937541\n",
      "--- 7.92795729637146 seconds ---\n",
      "Epoch : 126\n",
      "learning_rate: 0.000750984\n",
      "train_loss: 0.071704, valid_loss: 0.074942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.890304, valid_f1: 0.937501\n",
      "--- 8.06304407119751 seconds ---\n",
      "Epoch : 127\n",
      "learning_rate: 0.000690809\n",
      "train_loss: 0.072314, valid_loss: 0.074967\n",
      "train_f1: 0.890297, valid_f1: 0.937465\n",
      "--- 8.031936168670654 seconds ---\n",
      "Epoch : 128\n",
      "learning_rate: 0.000632968\n",
      "train_loss: 0.072831, valid_loss: 0.074943\n",
      "train_f1: 0.890673, valid_f1: 0.937456\n",
      "--- 7.555810213088989 seconds ---\n",
      "Epoch : 129\n",
      "learning_rate: 0.000577492\n",
      "train_loss: 0.072314, valid_loss: 0.075029\n",
      "train_f1: 0.890137, valid_f1: 0.937529\n",
      "--- 7.449528217315674 seconds ---\n",
      "Epoch : 130\n",
      "learning_rate: 0.000524411\n",
      "train_loss: 0.072901, valid_loss: 0.075020\n",
      "train_f1: 0.891381, valid_f1: 0.937459\n",
      "--- 7.446623086929321 seconds ---\n",
      "Epoch : 131\n",
      "learning_rate: 0.000473753\n",
      "train_loss: 0.073317, valid_loss: 0.074996\n",
      "train_f1: 0.890755, valid_f1: 0.937483\n",
      "--- 7.499983787536621 seconds ---\n",
      "Epoch : 132\n",
      "learning_rate: 0.000425547\n",
      "train_loss: 0.072906, valid_loss: 0.074985\n",
      "train_f1: 0.890577, valid_f1: 0.937480\n",
      "--- 7.313392877578735 seconds ---\n",
      "Epoch : 133\n",
      "learning_rate: 0.000379817\n",
      "train_loss: 0.070911, valid_loss: 0.075041\n",
      "train_f1: 0.890647, valid_f1: 0.937449\n",
      "--- 7.343663215637207 seconds ---\n",
      "Epoch : 134\n",
      "learning_rate: 0.000336590\n",
      "train_loss: 0.072627, valid_loss: 0.074995\n",
      "train_f1: 0.891510, valid_f1: 0.937469\n",
      "--- 7.633938789367676 seconds ---\n",
      "Epoch : 135\n",
      "learning_rate: 0.000295887\n",
      "train_loss: 0.071563, valid_loss: 0.075037\n",
      "train_f1: 0.890952, valid_f1: 0.937479\n",
      "--- 7.676448822021484 seconds ---\n",
      "Epoch : 136\n",
      "learning_rate: 0.000257733\n",
      "train_loss: 0.071856, valid_loss: 0.075127\n",
      "train_f1: 0.890550, valid_f1: 0.937389\n",
      "--- 7.532271146774292 seconds ---\n",
      "Epoch : 137\n",
      "learning_rate: 0.000222146\n",
      "train_loss: 0.073349, valid_loss: 0.075105\n",
      "train_f1: 0.890967, valid_f1: 0.937421\n",
      "--- 7.425623416900635 seconds ---\n",
      "Epoch : 138\n",
      "learning_rate: 0.000189146\n",
      "train_loss: 0.071355, valid_loss: 0.075077\n",
      "train_f1: 0.891031, valid_f1: 0.937458\n",
      "--- 7.450927972793579 seconds ---\n",
      "Epoch : 139\n",
      "learning_rate: 0.000158752\n",
      "train_loss: 0.072141, valid_loss: 0.075067\n",
      "train_f1: 0.891158, valid_f1: 0.937469\n",
      "Early Stopping...\n",
      "Best Val Score: 0.937598\n",
      "Fold : 2\n",
      "Epoch : 0\n",
      "learning_rate: 0.000100000\n",
      "train_loss: 1.864317, valid_loss: 1.649049\n",
      "train_f1: 0.063314, valid_f1: 0.030588\n",
      "--- 7.428007364273071 seconds ---\n",
      "Epoch : 1\n",
      "learning_rate: 0.000210252\n",
      "train_loss: 1.697286, valid_loss: 1.468374\n",
      "train_f1: 0.074395, valid_f1: 0.068200\n",
      "--- 7.483674049377441 seconds ---\n",
      "Epoch : 2\n",
      "learning_rate: 0.000536096\n",
      "train_loss: 1.467727, valid_loss: 1.149322\n",
      "train_f1: 0.087367, valid_f1: 0.085665\n",
      "--- 7.985216379165649 seconds ---\n",
      "Epoch : 3\n",
      "learning_rate: 0.001063017\n",
      "train_loss: 1.181141, valid_loss: 0.811301\n",
      "train_f1: 0.096293, valid_f1: 0.102193\n",
      "--- 7.776388168334961 seconds ---\n",
      "Epoch : 4\n",
      "learning_rate: 0.001767543\n",
      "train_loss: 0.957974, valid_loss: 0.798491\n",
      "train_f1: 0.115773, valid_f1: 0.042850\n",
      "--- 7.542002439498901 seconds ---\n",
      "Epoch : 5\n",
      "learning_rate: 0.002618290\n",
      "train_loss: 0.811921, valid_loss: 0.719591\n",
      "train_f1: 0.129541, valid_f1: 0.198081\n",
      "--- 7.855655670166016 seconds ---\n",
      "Epoch : 6\n",
      "learning_rate: 0.003577360\n",
      "train_loss: 0.723531, valid_loss: 0.650920\n",
      "train_f1: 0.171305, valid_f1: 0.227191\n",
      "--- 7.357561349868774 seconds ---\n",
      "Epoch : 7\n",
      "learning_rate: 0.004602031\n",
      "train_loss: 0.625464, valid_loss: 0.563762\n",
      "train_f1: 0.238664, valid_f1: 0.270052\n",
      "--- 7.261245965957642 seconds ---\n",
      "Epoch : 8\n",
      "learning_rate: 0.005646657\n",
      "train_loss: 0.528164, valid_loss: 0.504135\n",
      "train_f1: 0.284128, valid_f1: 0.301016\n",
      "--- 7.524554014205933 seconds ---\n",
      "Epoch : 9\n",
      "learning_rate: 0.006664704\n",
      "train_loss: 0.460148, valid_loss: 0.424128\n",
      "train_f1: 0.334995, valid_f1: 0.433858\n",
      "--- 7.246013641357422 seconds ---\n",
      "Epoch : 10\n",
      "learning_rate: 0.007610822\n",
      "train_loss: 0.386829, valid_loss: 0.349567\n",
      "train_f1: 0.408816, valid_f1: 0.430384\n",
      "--- 7.275419235229492 seconds ---\n",
      "Epoch : 11\n",
      "learning_rate: 0.008442866\n",
      "train_loss: 0.343117, valid_loss: 0.284377\n",
      "train_f1: 0.460686, valid_f1: 0.628067\n",
      "--- 7.281579256057739 seconds ---\n",
      "Epoch : 12\n",
      "learning_rate: 0.009123770\n",
      "train_loss: 0.286840, valid_loss: 0.237803\n",
      "train_f1: 0.530074, valid_f1: 0.725170\n",
      "--- 7.296616315841675 seconds ---\n",
      "Epoch : 13\n",
      "learning_rate: 0.009623204\n",
      "train_loss: 0.243911, valid_loss: 0.203733\n",
      "train_f1: 0.576141, valid_f1: 0.771107\n",
      "--- 7.27152419090271 seconds ---\n",
      "Epoch : 14\n",
      "learning_rate: 0.009918919\n",
      "train_loss: 0.213658, valid_loss: 0.176140\n",
      "train_f1: 0.625319, valid_f1: 0.786675\n",
      "--- 7.568755388259888 seconds ---\n",
      "Epoch : 15\n",
      "learning_rate: 0.009999972\n",
      "train_loss: 0.192451, valid_loss: 0.159938\n",
      "train_f1: 0.661267, valid_f1: 0.800640\n",
      "--- 7.536473512649536 seconds ---\n",
      "Epoch : 16\n",
      "learning_rate: 0.009998232\n",
      "train_loss: 0.176405, valid_loss: 0.154090\n",
      "train_f1: 0.694287, valid_f1: 0.806561\n",
      "--- 7.453617095947266 seconds ---\n",
      "Epoch : 17\n",
      "learning_rate: 0.009993785\n",
      "train_loss: 0.175075, valid_loss: 0.155261\n",
      "train_f1: 0.699184, valid_f1: 0.734869\n",
      "--- 7.388005971908569 seconds ---\n",
      "Epoch : 18\n",
      "learning_rate: 0.009986633\n",
      "train_loss: 0.160698, valid_loss: 0.130324\n",
      "train_f1: 0.720292, valid_f1: 0.834266\n",
      "--- 7.663015365600586 seconds ---\n",
      "Epoch : 19\n",
      "learning_rate: 0.009976781\n",
      "train_loss: 0.146766, valid_loss: 0.117204\n",
      "train_f1: 0.751480, valid_f1: 0.828512\n",
      "--- 7.813688278198242 seconds ---\n",
      "Epoch : 20\n",
      "learning_rate: 0.009964235\n",
      "train_loss: 0.136930, valid_loss: 0.106846\n",
      "train_f1: 0.766147, valid_f1: 0.840819\n",
      "--- 7.696380853652954 seconds ---\n",
      "Epoch : 21\n",
      "learning_rate: 0.009949000\n",
      "train_loss: 0.128331, valid_loss: 0.102670\n",
      "train_f1: 0.779704, valid_f1: 0.843365\n",
      "--- 7.722490310668945 seconds ---\n",
      "Epoch : 22\n",
      "learning_rate: 0.009931085\n",
      "train_loss: 0.123613, valid_loss: 0.099813\n",
      "train_f1: 0.787834, valid_f1: 0.842577\n",
      "--- 7.521744728088379 seconds ---\n",
      "Epoch : 23\n",
      "learning_rate: 0.009910499\n",
      "train_loss: 0.116586, valid_loss: 0.096207\n",
      "train_f1: 0.799229, valid_f1: 0.842668\n",
      "--- 7.499093055725098 seconds ---\n",
      "Epoch : 24\n",
      "learning_rate: 0.009887255\n",
      "train_loss: 0.112938, valid_loss: 0.093239\n",
      "train_f1: 0.808247, valid_f1: 0.843444\n",
      "--- 7.290067434310913 seconds ---\n",
      "Epoch : 25\n",
      "learning_rate: 0.009861364\n",
      "train_loss: 0.110376, valid_loss: 0.092358\n",
      "train_f1: 0.811352, valid_f1: 0.845629\n",
      "--- 7.340039253234863 seconds ---\n",
      "Epoch : 26\n",
      "learning_rate: 0.009832841\n",
      "train_loss: 0.116204, valid_loss: 0.118648\n",
      "train_f1: 0.797211, valid_f1: 0.831502\n",
      "--- 7.57330584526062 seconds ---\n",
      "Epoch : 27\n",
      "learning_rate: 0.009801700\n",
      "train_loss: 0.113600, valid_loss: 0.106238\n",
      "train_f1: 0.803575, valid_f1: 0.829441\n",
      "--- 7.564897775650024 seconds ---\n",
      "Epoch : 28\n",
      "learning_rate: 0.009767960\n",
      "train_loss: 0.109082, valid_loss: 0.093424\n",
      "train_f1: 0.812626, valid_f1: 0.843743\n",
      "--- 7.365329027175903 seconds ---\n",
      "Epoch : 29\n",
      "learning_rate: 0.009731637\n",
      "train_loss: 0.101338, valid_loss: 0.089362\n",
      "train_f1: 0.822078, valid_f1: 0.845818\n",
      "--- 7.563511371612549 seconds ---\n",
      "Epoch : 30\n",
      "learning_rate: 0.009692752\n",
      "train_loss: 0.098654, valid_loss: 0.086965\n",
      "train_f1: 0.828218, valid_f1: 0.847374\n",
      "--- 7.275484561920166 seconds ---\n",
      "Epoch : 31\n",
      "learning_rate: 0.009651326\n",
      "train_loss: 0.096522, valid_loss: 0.086834\n",
      "train_f1: 0.829040, valid_f1: 0.846570\n",
      "--- 7.745167016983032 seconds ---\n",
      "Epoch : 32\n",
      "learning_rate: 0.009607381\n",
      "train_loss: 0.092760, valid_loss: 0.085497\n",
      "train_f1: 0.829265, valid_f1: 0.847075\n",
      "--- 7.767734527587891 seconds ---\n",
      "Epoch : 33\n",
      "learning_rate: 0.009560942\n",
      "train_loss: 0.092853, valid_loss: 0.084979\n",
      "train_f1: 0.831085, valid_f1: 0.847073\n",
      "--- 7.268486738204956 seconds ---\n",
      "Epoch : 34\n",
      "learning_rate: 0.009512032\n",
      "train_loss: 0.092094, valid_loss: 0.085202\n",
      "train_f1: 0.833929, valid_f1: 0.845187\n",
      "--- 7.333827972412109 seconds ---\n",
      "Epoch : 35\n",
      "learning_rate: 0.009460679\n",
      "train_loss: 0.089008, valid_loss: 0.084054\n",
      "train_f1: 0.839824, valid_f1: 0.847171\n",
      "--- 7.2916600704193115 seconds ---\n",
      "Epoch : 36\n",
      "learning_rate: 0.009406911\n",
      "train_loss: 0.089059, valid_loss: 0.083149\n",
      "train_f1: 0.840473, valid_f1: 0.847463\n",
      "--- 7.282289981842041 seconds ---\n",
      "Epoch : 37\n",
      "learning_rate: 0.009350756\n",
      "train_loss: 0.089021, valid_loss: 0.083445\n",
      "train_f1: 0.843191, valid_f1: 0.846986\n",
      "--- 7.719496726989746 seconds ---\n",
      "Epoch : 38\n",
      "learning_rate: 0.009292245\n",
      "train_loss: 0.087395, valid_loss: 0.082112\n",
      "train_f1: 0.845400, valid_f1: 0.847623\n",
      "--- 8.225181818008423 seconds ---\n",
      "Epoch : 39\n",
      "learning_rate: 0.009231409\n",
      "train_loss: 0.085231, valid_loss: 0.082047\n",
      "train_f1: 0.849932, valid_f1: 0.847142\n",
      "--- 7.655306100845337 seconds ---\n",
      "Epoch : 40\n",
      "learning_rate: 0.009168283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.086663, valid_loss: 0.082111\n",
      "train_f1: 0.853074, valid_f1: 0.847145\n",
      "--- 7.262159585952759 seconds ---\n",
      "Epoch : 41\n",
      "learning_rate: 0.009102899\n",
      "train_loss: 0.084007, valid_loss: 0.082207\n",
      "train_f1: 0.854581, valid_f1: 0.844205\n",
      "--- 7.2578349113464355 seconds ---\n",
      "Epoch : 42\n",
      "learning_rate: 0.009035293\n",
      "train_loss: 0.085239, valid_loss: 0.080514\n",
      "train_f1: 0.859700, valid_f1: 0.856836\n",
      "--- 7.251209259033203 seconds ---\n",
      "Epoch : 43\n",
      "learning_rate: 0.008965503\n",
      "train_loss: 0.085915, valid_loss: 0.083742\n",
      "train_f1: 0.861927, valid_f1: 0.842855\n",
      "--- 7.32746148109436 seconds ---\n",
      "Epoch : 44\n",
      "learning_rate: 0.008893564\n",
      "train_loss: 0.083060, valid_loss: 0.078721\n",
      "train_f1: 0.864516, valid_f1: 0.906312\n",
      "--- 7.254142761230469 seconds ---\n",
      "Epoch : 45\n",
      "learning_rate: 0.008819518\n",
      "train_loss: 0.081665, valid_loss: 0.081218\n",
      "train_f1: 0.869630, valid_f1: 0.876332\n",
      "--- 7.262022018432617 seconds ---\n",
      "Epoch : 46\n",
      "learning_rate: 0.008743403\n",
      "train_loss: 0.082322, valid_loss: 0.077850\n",
      "train_f1: 0.871456, valid_f1: 0.912359\n",
      "--- 7.2384302616119385 seconds ---\n",
      "Epoch : 47\n",
      "learning_rate: 0.008665261\n",
      "train_loss: 0.081986, valid_loss: 0.077294\n",
      "train_f1: 0.874620, valid_f1: 0.921554\n",
      "--- 7.252835035324097 seconds ---\n",
      "Epoch : 48\n",
      "learning_rate: 0.008585134\n",
      "train_loss: 0.079683, valid_loss: 0.076944\n",
      "train_f1: 0.876991, valid_f1: 0.927515\n",
      "--- 7.237938404083252 seconds ---\n",
      "Epoch : 49\n",
      "learning_rate: 0.008503066\n",
      "train_loss: 0.079806, valid_loss: 0.076346\n",
      "train_f1: 0.880399, valid_f1: 0.928236\n",
      "--- 7.236986875534058 seconds ---\n",
      "Epoch : 50\n",
      "learning_rate: 0.008419100\n",
      "train_loss: 0.077752, valid_loss: 0.080214\n",
      "train_f1: 0.881612, valid_f1: 0.909303\n",
      "--- 7.25420880317688 seconds ---\n",
      "Epoch : 51\n",
      "learning_rate: 0.008333284\n",
      "train_loss: 0.085114, valid_loss: 0.081320\n",
      "train_f1: 0.871078, valid_f1: 0.896148\n",
      "--- 7.2486891746521 seconds ---\n",
      "Epoch : 52\n",
      "learning_rate: 0.008245662\n",
      "train_loss: 0.080382, valid_loss: 0.083141\n",
      "train_f1: 0.876414, valid_f1: 0.900950\n",
      "--- 7.217292785644531 seconds ---\n",
      "Epoch : 53\n",
      "learning_rate: 0.008156282\n",
      "train_loss: 0.080474, valid_loss: 0.082725\n",
      "train_f1: 0.876943, valid_f1: 0.890182\n",
      "--- 7.227304935455322 seconds ---\n",
      "Epoch : 54\n",
      "learning_rate: 0.008065194\n",
      "train_loss: 0.078705, valid_loss: 0.079083\n",
      "train_f1: 0.881849, valid_f1: 0.915742\n",
      "--- 7.256877899169922 seconds ---\n",
      "Epoch : 55\n",
      "learning_rate: 0.007972445\n",
      "train_loss: 0.077719, valid_loss: 0.075473\n",
      "train_f1: 0.885368, valid_f1: 0.929707\n",
      "--- 7.254874229431152 seconds ---\n",
      "Epoch : 56\n",
      "learning_rate: 0.007878087\n",
      "train_loss: 0.076596, valid_loss: 0.074574\n",
      "train_f1: 0.887817, valid_f1: 0.932761\n",
      "--- 7.2386016845703125 seconds ---\n",
      "Epoch : 57\n",
      "learning_rate: 0.007782171\n",
      "train_loss: 0.076980, valid_loss: 0.074386\n",
      "train_f1: 0.889617, valid_f1: 0.933648\n",
      "--- 7.2555766105651855 seconds ---\n",
      "Epoch : 58\n",
      "learning_rate: 0.007684748\n",
      "train_loss: 0.075831, valid_loss: 0.073584\n",
      "train_f1: 0.891351, valid_f1: 0.935114\n",
      "--- 7.234506845474243 seconds ---\n",
      "Epoch : 59\n",
      "learning_rate: 0.007585871\n",
      "train_loss: 0.075501, valid_loss: 0.073874\n",
      "train_f1: 0.892333, valid_f1: 0.933906\n",
      "--- 7.326417684555054 seconds ---\n",
      "Epoch : 60\n",
      "learning_rate: 0.007485593\n",
      "train_loss: 0.074724, valid_loss: 0.073499\n",
      "train_f1: 0.893808, valid_f1: 0.935057\n",
      "--- 7.232980728149414 seconds ---\n",
      "Epoch : 61\n",
      "learning_rate: 0.007383970\n",
      "train_loss: 0.076535, valid_loss: 0.073693\n",
      "train_f1: 0.893810, valid_f1: 0.933877\n",
      "--- 7.240512847900391 seconds ---\n",
      "Epoch : 62\n",
      "learning_rate: 0.007281056\n",
      "train_loss: 0.074821, valid_loss: 0.073443\n",
      "train_f1: 0.895134, valid_f1: 0.934473\n",
      "--- 7.2442946434021 seconds ---\n",
      "Epoch : 63\n",
      "learning_rate: 0.007176907\n",
      "train_loss: 0.074995, valid_loss: 0.073088\n",
      "train_f1: 0.895438, valid_f1: 0.935140\n",
      "--- 7.236821413040161 seconds ---\n",
      "Epoch : 64\n",
      "learning_rate: 0.007071578\n",
      "train_loss: 0.073849, valid_loss: 0.073306\n",
      "train_f1: 0.896053, valid_f1: 0.934632\n",
      "--- 7.288182973861694 seconds ---\n",
      "Epoch : 65\n",
      "learning_rate: 0.006965128\n",
      "train_loss: 0.073518, valid_loss: 0.073152\n",
      "train_f1: 0.897349, valid_f1: 0.933588\n",
      "--- 7.217116117477417 seconds ---\n",
      "Epoch : 66\n",
      "learning_rate: 0.006857614\n",
      "train_loss: 0.074291, valid_loss: 0.072941\n",
      "train_f1: 0.897387, valid_f1: 0.934486\n",
      "--- 7.254117965698242 seconds ---\n",
      "Epoch : 67\n",
      "learning_rate: 0.006749094\n",
      "train_loss: 0.074343, valid_loss: 0.072638\n",
      "train_f1: 0.898598, valid_f1: 0.934882\n",
      "--- 7.355829477310181 seconds ---\n",
      "Epoch : 68\n",
      "learning_rate: 0.006639626\n",
      "train_loss: 0.072770, valid_loss: 0.072389\n",
      "train_f1: 0.899460, valid_f1: 0.935148\n",
      "--- 7.256814002990723 seconds ---\n",
      "Epoch : 69\n",
      "learning_rate: 0.006529271\n",
      "train_loss: 0.072005, valid_loss: 0.072210\n",
      "train_f1: 0.899351, valid_f1: 0.934956\n",
      "--- 7.6696813106536865 seconds ---\n",
      "Epoch : 70\n",
      "learning_rate: 0.006418088\n",
      "train_loss: 0.072400, valid_loss: 0.071956\n",
      "train_f1: 0.899628, valid_f1: 0.935492\n",
      "--- 7.426842451095581 seconds ---\n",
      "Epoch : 71\n",
      "learning_rate: 0.006306137\n",
      "train_loss: 0.072217, valid_loss: 0.072223\n",
      "train_f1: 0.900458, valid_f1: 0.934940\n",
      "--- 7.277483940124512 seconds ---\n",
      "Epoch : 72\n",
      "learning_rate: 0.006193478\n",
      "train_loss: 0.073361, valid_loss: 0.073059\n",
      "train_f1: 0.902081, valid_f1: 0.933468\n",
      "--- 8.037644624710083 seconds ---\n",
      "Epoch : 73\n",
      "learning_rate: 0.006080173\n",
      "train_loss: 0.071916, valid_loss: 0.071712\n",
      "train_f1: 0.901511, valid_f1: 0.935197\n",
      "--- 8.125288724899292 seconds ---\n",
      "Epoch : 74\n",
      "learning_rate: 0.005966284\n",
      "train_loss: 0.072166, valid_loss: 0.071489\n",
      "train_f1: 0.902345, valid_f1: 0.935748\n",
      "--- 7.747486352920532 seconds ---\n",
      "Epoch : 75\n",
      "learning_rate: 0.005851871\n",
      "train_loss: 0.070991, valid_loss: 0.071622\n",
      "train_f1: 0.902760, valid_f1: 0.935537\n",
      "--- 7.6176416873931885 seconds ---\n",
      "Epoch : 76\n",
      "learning_rate: 0.005736996\n",
      "train_loss: 0.072255, valid_loss: 0.072143\n",
      "train_f1: 0.903261, valid_f1: 0.934688\n",
      "--- 7.426236152648926 seconds ---\n",
      "Epoch : 77\n",
      "learning_rate: 0.005621723\n",
      "train_loss: 0.071631, valid_loss: 0.071873\n",
      "train_f1: 0.903859, valid_f1: 0.934853\n",
      "--- 7.3276002407073975 seconds ---\n",
      "Epoch : 78\n",
      "learning_rate: 0.005506113\n",
      "train_loss: 0.069919, valid_loss: 0.071485\n",
      "train_f1: 0.904159, valid_f1: 0.935215\n",
      "--- 7.278956890106201 seconds ---\n",
      "Epoch : 79\n",
      "learning_rate: 0.005390229\n",
      "train_loss: 0.070221, valid_loss: 0.071771\n",
      "train_f1: 0.904807, valid_f1: 0.934740\n",
      "--- 8.018994092941284 seconds ---\n",
      "Epoch : 80\n",
      "learning_rate: 0.005274133\n",
      "train_loss: 0.069697, valid_loss: 0.071027\n",
      "train_f1: 0.904975, valid_f1: 0.935890\n",
      "--- 8.25630259513855 seconds ---\n",
      "Epoch : 81\n",
      "learning_rate: 0.005157889\n",
      "train_loss: 0.069379, valid_loss: 0.070928\n",
      "train_f1: 0.905639, valid_f1: 0.936040\n",
      "--- 7.275944709777832 seconds ---\n",
      "Epoch : 82\n",
      "learning_rate: 0.005041560\n",
      "train_loss: 0.071061, valid_loss: 0.071053\n",
      "train_f1: 0.905385, valid_f1: 0.935819\n",
      "--- 7.239562511444092 seconds ---\n",
      "Epoch : 83\n",
      "learning_rate: 0.004925208\n",
      "train_loss: 0.071300, valid_loss: 0.071630\n",
      "train_f1: 0.906425, valid_f1: 0.934743\n",
      "--- 7.371397972106934 seconds ---\n",
      "Epoch : 84\n",
      "learning_rate: 0.004808897\n",
      "train_loss: 0.069833, valid_loss: 0.070590\n",
      "train_f1: 0.906467, valid_f1: 0.936005\n",
      "--- 7.598788261413574 seconds ---\n",
      "Epoch : 85\n",
      "learning_rate: 0.004692689\n",
      "train_loss: 0.070184, valid_loss: 0.070713\n",
      "train_f1: 0.906638, valid_f1: 0.936224\n",
      "--- 8.01378870010376 seconds ---\n",
      "Epoch : 86\n",
      "learning_rate: 0.004576647\n",
      "train_loss: 0.070356, valid_loss: 0.071638\n",
      "train_f1: 0.906526, valid_f1: 0.933912\n",
      "--- 7.271402597427368 seconds ---\n",
      "Epoch : 87\n",
      "learning_rate: 0.004460835\n",
      "train_loss: 0.069509, valid_loss: 0.070513\n",
      "train_f1: 0.907616, valid_f1: 0.936394\n",
      "--- 7.639849424362183 seconds ---\n",
      "Epoch : 88\n",
      "learning_rate: 0.004345315\n",
      "train_loss: 0.069189, valid_loss: 0.071351\n",
      "train_f1: 0.906967, valid_f1: 0.933786\n",
      "--- 7.262594223022461 seconds ---\n",
      "Epoch : 89\n",
      "learning_rate: 0.004230149\n",
      "train_loss: 0.069611, valid_loss: 0.070461\n",
      "train_f1: 0.907453, valid_f1: 0.936260\n",
      "--- 7.4923694133758545 seconds ---\n",
      "Epoch : 90\n",
      "learning_rate: 0.004115400\n",
      "train_loss: 0.069504, valid_loss: 0.071237\n",
      "train_f1: 0.908125, valid_f1: 0.934336\n",
      "--- 7.4505226612091064 seconds ---\n",
      "Epoch : 91\n",
      "learning_rate: 0.004001130\n",
      "train_loss: 0.068624, valid_loss: 0.070395\n",
      "train_f1: 0.908141, valid_f1: 0.936017\n",
      "--- 7.2500245571136475 seconds ---\n",
      "Epoch : 92\n",
      "learning_rate: 0.003887401\n",
      "train_loss: 0.069221, valid_loss: 0.070650\n",
      "train_f1: 0.908358, valid_f1: 0.936081\n",
      "--- 7.25938868522644 seconds ---\n",
      "Epoch : 93\n",
      "learning_rate: 0.003774275\n",
      "train_loss: 0.068801, valid_loss: 0.070698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_f1: 0.908350, valid_f1: 0.935779\n",
      "--- 7.2628333568573 seconds ---\n",
      "Epoch : 94\n",
      "learning_rate: 0.003661812\n",
      "train_loss: 0.069989, valid_loss: 0.070301\n",
      "train_f1: 0.908834, valid_f1: 0.936300\n",
      "--- 7.398880243301392 seconds ---\n",
      "Epoch : 95\n",
      "learning_rate: 0.003550074\n",
      "train_loss: 0.067946, valid_loss: 0.070921\n",
      "train_f1: 0.908894, valid_f1: 0.935368\n",
      "--- 7.397958755493164 seconds ---\n",
      "Epoch : 96\n",
      "learning_rate: 0.003439122\n",
      "train_loss: 0.069828, valid_loss: 0.070431\n",
      "train_f1: 0.909078, valid_f1: 0.935767\n",
      "--- 7.279065132141113 seconds ---\n",
      "Epoch : 97\n",
      "learning_rate: 0.003329014\n",
      "train_loss: 0.067742, valid_loss: 0.070244\n",
      "train_f1: 0.908979, valid_f1: 0.936201\n",
      "--- 7.250555038452148 seconds ---\n",
      "Epoch : 98\n",
      "learning_rate: 0.003219811\n",
      "train_loss: 0.068912, valid_loss: 0.070144\n",
      "train_f1: 0.909395, valid_f1: 0.936552\n",
      "--- 7.242939710617065 seconds ---\n",
      "Epoch : 99\n",
      "learning_rate: 0.003111572\n",
      "train_loss: 0.069162, valid_loss: 0.070692\n",
      "train_f1: 0.909683, valid_f1: 0.935542\n",
      "--- 7.261530637741089 seconds ---\n",
      "Epoch : 100\n",
      "learning_rate: 0.003004356\n",
      "train_loss: 0.067438, valid_loss: 0.070645\n",
      "train_f1: 0.909707, valid_f1: 0.935165\n",
      "--- 7.281340837478638 seconds ---\n",
      "Epoch : 101\n",
      "learning_rate: 0.002898221\n",
      "train_loss: 0.067412, valid_loss: 0.070630\n",
      "train_f1: 0.909347, valid_f1: 0.935688\n",
      "--- 7.281400918960571 seconds ---\n",
      "Epoch : 102\n",
      "learning_rate: 0.002793224\n",
      "train_loss: 0.067647, valid_loss: 0.069961\n",
      "train_f1: 0.909941, valid_f1: 0.936711\n",
      "--- 7.313048601150513 seconds ---\n",
      "Epoch : 103\n",
      "learning_rate: 0.002689421\n",
      "train_loss: 0.067985, valid_loss: 0.069901\n",
      "train_f1: 0.910265, valid_f1: 0.936690\n",
      "--- 7.8013551235198975 seconds ---\n",
      "Epoch : 104\n",
      "learning_rate: 0.002586870\n",
      "train_loss: 0.068603, valid_loss: 0.069888\n",
      "train_f1: 0.910000, valid_f1: 0.936662\n",
      "--- 7.770157337188721 seconds ---\n",
      "Epoch : 105\n",
      "learning_rate: 0.002485626\n",
      "train_loss: 0.067369, valid_loss: 0.069806\n",
      "train_f1: 0.909818, valid_f1: 0.936947\n",
      "--- 7.5074098110198975 seconds ---\n",
      "Epoch : 106\n",
      "learning_rate: 0.002385743\n",
      "train_loss: 0.067038, valid_loss: 0.069754\n",
      "train_f1: 0.911080, valid_f1: 0.936690\n",
      "--- 7.394233465194702 seconds ---\n",
      "Epoch : 107\n",
      "learning_rate: 0.002287276\n",
      "train_loss: 0.068494, valid_loss: 0.069978\n",
      "train_f1: 0.910167, valid_f1: 0.936522\n",
      "--- 7.3640477657318115 seconds ---\n",
      "Epoch : 108\n",
      "learning_rate: 0.002190278\n",
      "train_loss: 0.068214, valid_loss: 0.070046\n",
      "train_f1: 0.910379, valid_f1: 0.936812\n",
      "--- 7.59947943687439 seconds ---\n",
      "Epoch : 109\n",
      "learning_rate: 0.002094802\n",
      "train_loss: 0.066459, valid_loss: 0.069892\n",
      "train_f1: 0.910976, valid_f1: 0.936598\n",
      "--- 7.816577196121216 seconds ---\n",
      "Epoch : 110\n",
      "learning_rate: 0.002000899\n",
      "train_loss: 0.067849, valid_loss: 0.069823\n",
      "train_f1: 0.910866, valid_f1: 0.936769\n",
      "--- 7.358220338821411 seconds ---\n",
      "Epoch : 111\n",
      "learning_rate: 0.001908619\n",
      "train_loss: 0.067415, valid_loss: 0.069890\n",
      "train_f1: 0.910826, valid_f1: 0.936694\n",
      "--- 7.312389373779297 seconds ---\n",
      "Epoch : 112\n",
      "learning_rate: 0.001818014\n",
      "train_loss: 0.068041, valid_loss: 0.070281\n",
      "train_f1: 0.910930, valid_f1: 0.935590\n",
      "--- 7.500960350036621 seconds ---\n",
      "Epoch : 113\n",
      "learning_rate: 0.001729132\n",
      "train_loss: 0.068669, valid_loss: 0.070293\n",
      "train_f1: 0.910647, valid_f1: 0.935723\n",
      "--- 7.42107081413269 seconds ---\n",
      "Epoch : 114\n",
      "learning_rate: 0.001642021\n",
      "train_loss: 0.067347, valid_loss: 0.070277\n",
      "train_f1: 0.911118, valid_f1: 0.935900\n",
      "--- 7.4356560707092285 seconds ---\n",
      "Epoch : 115\n",
      "learning_rate: 0.001556729\n",
      "train_loss: 0.067296, valid_loss: 0.070184\n",
      "train_f1: 0.911334, valid_f1: 0.936153\n",
      "--- 7.270654678344727 seconds ---\n",
      "Epoch : 116\n",
      "learning_rate: 0.001473301\n",
      "train_loss: 0.068659, valid_loss: 0.069951\n",
      "train_f1: 0.911273, valid_f1: 0.936541\n",
      "--- 7.450126647949219 seconds ---\n",
      "Epoch : 117\n",
      "learning_rate: 0.001391783\n",
      "train_loss: 0.067068, valid_loss: 0.069929\n",
      "train_f1: 0.911353, valid_f1: 0.936482\n",
      "--- 7.641054153442383 seconds ---\n",
      "Epoch : 118\n",
      "learning_rate: 0.001312219\n",
      "train_loss: 0.067905, valid_loss: 0.070201\n",
      "train_f1: 0.911810, valid_f1: 0.936003\n",
      "--- 7.358217716217041 seconds ---\n",
      "Epoch : 119\n",
      "learning_rate: 0.001234651\n",
      "train_loss: 0.066748, valid_loss: 0.070210\n",
      "train_f1: 0.911535, valid_f1: 0.935827\n",
      "--- 7.318067312240601 seconds ---\n",
      "Epoch : 120\n",
      "learning_rate: 0.001159123\n",
      "train_loss: 0.066988, valid_loss: 0.069972\n",
      "train_f1: 0.911882, valid_f1: 0.936400\n",
      "--- 7.470422029495239 seconds ---\n",
      "Epoch : 121\n",
      "learning_rate: 0.001085675\n",
      "train_loss: 0.067266, valid_loss: 0.070266\n",
      "train_f1: 0.911910, valid_f1: 0.935710\n",
      "--- 7.364160060882568 seconds ---\n",
      "Epoch : 122\n",
      "learning_rate: 0.001014346\n",
      "train_loss: 0.067715, valid_loss: 0.069779\n",
      "train_f1: 0.911283, valid_f1: 0.936604\n",
      "--- 7.938971281051636 seconds ---\n",
      "Epoch : 123\n",
      "learning_rate: 0.000945176\n",
      "train_loss: 0.067072, valid_loss: 0.070172\n",
      "train_f1: 0.911873, valid_f1: 0.936146\n",
      "--- 7.941859245300293 seconds ---\n",
      "Epoch : 124\n",
      "learning_rate: 0.000878202\n",
      "train_loss: 0.067564, valid_loss: 0.070064\n",
      "train_f1: 0.911644, valid_f1: 0.936095\n",
      "--- 7.523086786270142 seconds ---\n",
      "Epoch : 125\n",
      "learning_rate: 0.000813459\n",
      "train_loss: 0.068124, valid_loss: 0.069940\n",
      "train_f1: 0.911887, valid_f1: 0.936380\n",
      "Early Stopping...\n",
      "Best Val Score: 0.936947\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./models\"):\n",
    "            os.makedirs(\"./models\")\n",
    "for index, (train_index, val_index ) in enumerate(new_splits[0:], start=0):\n",
    "    print(\"Fold : {}\".format(index))\n",
    "    \n",
    "    batchsize = 128\n",
    "    train_dataset = IonDataset(trainval[train_index],  trainval_y[train_index], flip=False, noise_level=0.0, class_split=0.0)\n",
    "    train_dataloader = DataLoader(train_dataset, batchsize, shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    valid_dataset = IonDataset(trainval[val_index],  trainval_y[val_index], flip=False)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batchsize, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    test_dataset = IonDataset(test,  test_y, flip=False, noise_level=0.0, class_split=0.0)\n",
    "    test_dataloader = DataLoader(test_dataset, batchsize, shuffle=False, num_workers=16, pin_memory=True)\n",
    "    test_preds_iter = np.zeros((2000000, 11))\n",
    "\n",
    "    for it in range(1):\n",
    "        device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        model=Seq2SeqRnn(input_size=trainval.shape[1], seq_len=4000, hidden_size=64, output_size=11, num_layers=2, hidden_layers=[64,64,64],\n",
    "                         bidirectional=True).to(device)\n",
    "        \n",
    "        no_of_epochs = 150\n",
    "        early_stopping = EarlyStopping(patience=20, is_maximize=True, checkpoint_path=\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it))\n",
    "        criterion = L.FocalLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        schedular = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e2, max_lr=0.01, epochs=no_of_epochs,\n",
    "                                                steps_per_epoch=len(train_dataloader))\n",
    "        avg_train_losses, avg_valid_losses = [], [] \n",
    "    \n",
    "    \n",
    "        for epoch in range(no_of_epochs):\n",
    "            start_time = time.time()\n",
    "    \n",
    "            print(\"Epoch : {}\".format(epoch))\n",
    "            print( \"learning_rate: {:0.9f}\".format(schedular.get_lr()[0]))\n",
    "            train_losses, valid_losses = [], []\n",
    "    \n",
    "            model.train() # prep model for training\n",
    "            train_preds, train_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "    \n",
    "            for x, y in train_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(x[:, :trainval.shape[1], :])\n",
    "    \n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                y_ = y.view(-1)\n",
    "    \n",
    "                loss = criterion(predictions_, y_)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                schedular.step()\n",
    "                # record training lossa\n",
    "                train_losses.append(loss.item())\n",
    "    \n",
    "                train_true = torch.cat([train_true, y_], 0)\n",
    "                train_preds = torch.cat([train_preds, predictions_], 0)\n",
    "\n",
    "            model.eval() # prep model for evaluation\n",
    "            val_preds, val_true = torch.Tensor([]).to(device), torch.LongTensor([]).to(device)\n",
    "            with torch.no_grad():\n",
    "                for x, y in valid_dataloader:\n",
    "                    x = x.to(device)\n",
    "                    y = y.to(device)\n",
    "    \n",
    "                    predictions = model(x[:,:trainval.shape[1],:])\n",
    "                    predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "                    y_ = y.view(-1)\n",
    "    \n",
    "                    loss = criterion(predictions_, y_)\n",
    "                    valid_losses.append(loss.item())\n",
    "        \n",
    "                    val_true = torch.cat([val_true, y_], 0)\n",
    "                    val_preds = torch.cat([val_preds, predictions_], 0)\n",
    "\n",
    "            # calculate average loss over an epoch\n",
    "            train_loss = np.average(train_losses)\n",
    "            valid_loss = np.average(valid_losses)\n",
    "            avg_train_losses.append(train_loss)\n",
    "            avg_valid_losses.append(valid_loss)\n",
    "            \n",
    "            print( \"train_loss: {:0.6f}, valid_loss: {:0.6f}\".format(train_loss, valid_loss))\n",
    "\n",
    "            train_score = f1_score(train_true.cpu().detach().numpy(), train_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            val_score = f1_score(val_true.cpu().detach().numpy(), val_preds.cpu().detach().numpy().argmax(1), labels=list(range(11)), average='macro')\n",
    "            print( \"train_f1: {:0.6f}, valid_f1: {:0.6f}\".format(train_score, val_score))\n",
    "    \n",
    "            if early_stopping(val_score, model):\n",
    "                print(\"Early Stopping...\")\n",
    "                print(\"Best Val Score: {:0.6f}\".format(early_stopping.best_score))\n",
    "                break\n",
    "    \n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        model.load_state_dict(torch.load(\"./models/gru_clean_checkpoint_fold_{}_iter_{}.pt\".format(index, it)))\n",
    "        with torch.no_grad():\n",
    "            pred_list = []\n",
    "            for x, y in test_dataloader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                predictions = model(x[:,:trainval.shape[1],:])\n",
    "                predictions_ = predictions.view(-1, predictions.shape[-1]) \n",
    "\n",
    "                pred_list.append(F.softmax(predictions_, dim=1).cpu().numpy())\n",
    "            test_preds = np.vstack(pred_list)\n",
    "       \n",
    "        test_preds_iter += test_preds\n",
    "        test_preds_all += test_preds\n",
    "        if not os.path.exists(\"./predictions/test\"):\n",
    "            os.makedirs(\"./predictions/test\")\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_iter_{}_raw.npy'.format(index, it), arr=test_preds_iter)\n",
    "        np.save('./predictions/test/gru_clean_fold_{}_raw.npy'.format(index), arr=test_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:14:30.143223Z",
     "start_time": "2020-04-11T00:14:27.588049Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Best Val Score: 0.936947\n",
    "\n",
    "test_preds_all = test_preds_all/np.sum(test_preds_all, axis=1)[:, None]\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str),\n",
    "                                'open_channels': np.argmax(test_preds_all, axis=1)})\n",
    "test_pred_frame.to_csv(\"../submissions/gru_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T01:33:34.944556Z",
     "start_time": "2020-04-15T01:33:34.940249Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T01:41:04.166737Z",
     "start_time": "2020-04-15T01:41:04.160955Z"
    }
   },
   "outputs": [],
   "source": [
    "LOG_DATE = \"2020_04_14\"\n",
    "NOTE = \"baseline\"\n",
    "FILE = \"./logs/\" + str(LOG_NAME) + \"_\" + str(NOTE) + \".log\"\n",
    "if not os.path.exists(FILE):\n",
    "    os.mknod(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T01:40:18.472538Z",
     "start_time": "2020-04-15T01:40:18.470275Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
